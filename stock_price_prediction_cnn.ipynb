{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8612863,
          "sourceType": "datasetVersion",
          "datasetId": 5154589
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SauryanPandey/Stock-Price-Prediction-CNN/blob/main/stock_price_prediction_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:39.147001Z",
          "iopub.execute_input": "2024-06-19T18:08:39.147502Z",
          "iopub.status.idle": "2024-06-19T18:08:39.544333Z",
          "shell.execute_reply.started": "2024-06-19T18:08:39.147460Z",
          "shell.execute_reply": "2024-06-19T18:08:39.543502Z"
        },
        "trusted": true,
        "id": "wLqDq7msMoD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/suzlon-stock-price-data-10y/SUZLON.NS_stock_data_10y.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:39.545900Z",
          "iopub.execute_input": "2024-06-19T18:08:39.546322Z",
          "iopub.status.idle": "2024-06-19T18:08:39.571001Z",
          "shell.execute_reply.started": "2024-06-19T18:08:39.546296Z",
          "shell.execute_reply": "2024-06-19T18:08:39.569900Z"
        },
        "trusted": true,
        "id": "XC4u8Ca9MoD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by = \"Date\", ascending = True, inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:39.572023Z",
          "iopub.execute_input": "2024-06-19T18:08:39.572270Z",
          "iopub.status.idle": "2024-06-19T18:08:39.583103Z",
          "shell.execute_reply.started": "2024-06-19T18:08:39.572248Z",
          "shell.execute_reply": "2024-06-19T18:08:39.582182Z"
        },
        "trusted": true,
        "id": "wXYIoLUbMoD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:39.584973Z",
          "iopub.execute_input": "2024-06-19T18:08:39.585273Z",
          "iopub.status.idle": "2024-06-19T18:08:39.613876Z",
          "shell.execute_reply.started": "2024-06-19T18:08:39.585249Z",
          "shell.execute_reply": "2024-06-19T18:08:39.612977Z"
        },
        "trusted": true,
        "id": "qiCSL191MoD8",
        "outputId": "9a7da76e-913b-4e53-a84d-9a4be59ffb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date       Open       High        Low      Close  Adj Close  \\\n0     2014-06-05  26.582294  27.408688  26.444563  27.408688  27.408688   \n1     2014-06-06  28.418722  28.740097  27.730061  28.740097  28.740097   \n2     2014-06-09  29.841953  30.163328  29.612400  30.163328  30.163328   \n3     2014-06-10  31.632471  31.632471  30.760166  31.632471  31.632471   \n4     2014-06-11  33.193436  33.193436  33.193436  33.193436  33.193436   \n...          ...        ...        ...        ...        ...        ...   \n2460  2024-05-30  46.299999  46.900002  44.500000  45.400002  45.400002   \n2461  2024-05-31  45.700001  47.650002  44.299999  47.650002  47.650002   \n2462  2024-06-03  50.000000  50.000000  50.000000  50.000000  50.000000   \n2463  2024-06-04  52.099998  52.099998  47.500000  47.500000  47.500000   \n2464  2024-06-05  45.150002  49.500000  45.150002  48.200001  48.200001   \n\n           Volume  \n0      48152360.0  \n1      46588034.0  \n2      18229895.0  \n3      27163910.0  \n4       5797435.0  \n...           ...  \n2460   31288700.0  \n2461  115665511.0  \n2462   62876628.0  \n2463  123854100.0  \n2464   60341072.0  \n\n[2465 rows x 7 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-06-05</td>\n      <td>26.582294</td>\n      <td>27.408688</td>\n      <td>26.444563</td>\n      <td>27.408688</td>\n      <td>27.408688</td>\n      <td>48152360.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-06-06</td>\n      <td>28.418722</td>\n      <td>28.740097</td>\n      <td>27.730061</td>\n      <td>28.740097</td>\n      <td>28.740097</td>\n      <td>46588034.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-06-09</td>\n      <td>29.841953</td>\n      <td>30.163328</td>\n      <td>29.612400</td>\n      <td>30.163328</td>\n      <td>30.163328</td>\n      <td>18229895.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-06-10</td>\n      <td>31.632471</td>\n      <td>31.632471</td>\n      <td>30.760166</td>\n      <td>31.632471</td>\n      <td>31.632471</td>\n      <td>27163910.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-06-11</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>5797435.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>2024-05-30</td>\n      <td>46.299999</td>\n      <td>46.900002</td>\n      <td>44.500000</td>\n      <td>45.400002</td>\n      <td>45.400002</td>\n      <td>31288700.0</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>2024-05-31</td>\n      <td>45.700001</td>\n      <td>47.650002</td>\n      <td>44.299999</td>\n      <td>47.650002</td>\n      <td>47.650002</td>\n      <td>115665511.0</td>\n    </tr>\n    <tr>\n      <th>2462</th>\n      <td>2024-06-03</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>62876628.0</td>\n    </tr>\n    <tr>\n      <th>2463</th>\n      <td>2024-06-04</td>\n      <td>52.099998</td>\n      <td>52.099998</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>123854100.0</td>\n    </tr>\n    <tr>\n      <th>2464</th>\n      <td>2024-06-05</td>\n      <td>45.150002</td>\n      <td>49.500000</td>\n      <td>45.150002</td>\n      <td>48.200001</td>\n      <td>48.200001</td>\n      <td>60341072.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2465 rows × 7 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:39.614909Z",
          "iopub.execute_input": "2024-06-19T18:08:39.615207Z",
          "iopub.status.idle": "2024-06-19T18:08:55.309726Z",
          "shell.execute_reply.started": "2024-06-19T18:08:39.615181Z",
          "shell.execute_reply": "2024-06-19T18:08:55.308727Z"
        },
        "trusted": true,
        "id": "lLPLeNEGMoD9",
        "outputId": "9ce8ddf8-35c1-4a8c-86e7-3a743e08251e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting ta\n  Downloading ta-0.11.0.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ta) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ta) (2.2.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->ta) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\nBuilding wheels for collected packages: ta\n  Building wheel for ta (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29413 sha256=1c9783f398d1b12668c247c5931aedcd9863fc6586073baf4b86b2df04ac2d1e\n  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\nSuccessfully built ta\nInstalling collected packages: ta\nSuccessfully installed ta-0.11.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculating Indicator Values"
      ],
      "metadata": {
        "id": "n_SmnXLeMoD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ta\n",
        "# Calculate Simple Moving Average (SMA)\n",
        "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "# Calculate Exponential Moving Average (EMA)\n",
        "df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
        "\n",
        "# Calculate MACD (Moving Average Convergence Divergence)\n",
        "df['MACD'] = ta.trend.macd(df['Close'])\n",
        "df['MACD_Signal'] = ta.trend.macd_signal(df['Close'])\n",
        "df['MACD_Hist'] = ta.trend.macd_diff(df['Close'])\n",
        "\n",
        "# Calculate RSI (Relative Strength Index)\n",
        "df['RSI_14'] = ta.momentum.rsi(df['Close'], window=14)\n",
        "\n",
        "# Calculate CCI (Commodity Channel Index)\n",
        "df['CCI_20'] = ta.trend.cci(high=df['High'], low=df['Low'], close=df['Close'], window=20)\n",
        "\n",
        "# Calculate TRIX (Triple Exponential Average)\n",
        "df['TRIX_10'] = ta.trend.trix(df['Close'], window=10)\n",
        "\n",
        "# Calculate Rate of Change (ROC)\n",
        "df['ROC_10'] = ta.momentum.roc(df['Close'], window=10)\n",
        "\n",
        "# Calculate Stochastic Oscillator (KDJ / KDJk)\n",
        "df['KDJk'] = ta.momentum.stoch(high=df['High'], low=df['Low'], close=df['Close'], window=14, smooth_window=3)\n",
        "\n",
        "# Calculate Bollinger Bands\n",
        "df['BB_High'], df['BB_Low'] = ta.volatility.BollingerBands(df['Close']).bollinger_hband(), ta.volatility.BollingerBands(df['Close']).bollinger_lband()\n",
        "\n",
        "df['Ease_of_Movement'] = ta.volume.ease_of_movement(df['High'], df['Low'], df['Volume'], window=14)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.311064Z",
          "iopub.execute_input": "2024-06-19T18:08:55.311373Z",
          "iopub.status.idle": "2024-06-19T18:08:55.409903Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.311344Z",
          "shell.execute_reply": "2024-06-19T18:08:55.409145Z"
        },
        "trusted": true,
        "id": "AD8R78WqMoD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.411296Z",
          "iopub.execute_input": "2024-06-19T18:08:55.411980Z",
          "iopub.status.idle": "2024-06-19T18:08:55.439463Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.411941Z",
          "shell.execute_reply": "2024-06-19T18:08:55.438611Z"
        },
        "trusted": true,
        "id": "lOrH4TwJMoD-",
        "outputId": "0f9302ff-e846-47b4-a0a0-1f0d2bb825e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date       Open       High        Low      Close  Adj Close  \\\n0     2014-06-05  26.582294  27.408688  26.444563  27.408688  27.408688   \n1     2014-06-06  28.418722  28.740097  27.730061  28.740097  28.740097   \n2     2014-06-09  29.841953  30.163328  29.612400  30.163328  30.163328   \n3     2014-06-10  31.632471  31.632471  30.760166  31.632471  31.632471   \n4     2014-06-11  33.193436  33.193436  33.193436  33.193436  33.193436   \n...          ...        ...        ...        ...        ...        ...   \n2460  2024-05-30  46.299999  46.900002  44.500000  45.400002  45.400002   \n2461  2024-05-31  45.700001  47.650002  44.299999  47.650002  47.650002   \n2462  2024-06-03  50.000000  50.000000  50.000000  50.000000  50.000000   \n2463  2024-06-04  52.099998  52.099998  47.500000  47.500000  47.500000   \n2464  2024-06-05  45.150002  49.500000  45.150002  48.200001  48.200001   \n\n           Volume   SMA_20     EMA_20      MACD  MACD_Signal  MACD_Hist  \\\n0      48152360.0      NaN  27.408688       NaN          NaN        NaN   \n1      46588034.0      NaN  27.535489       NaN          NaN        NaN   \n2      18229895.0      NaN  27.785759       NaN          NaN        NaN   \n3      27163910.0      NaN  28.152113       NaN          NaN        NaN   \n4       5797435.0      NaN  28.632239       NaN          NaN        NaN   \n...           ...      ...        ...       ...          ...        ...   \n2460   31288700.0  42.7400  43.566326  1.263158     0.941713   0.321446   \n2461  115665511.0  43.0375  43.955248  1.427539     1.038878   0.388661   \n2462   62876628.0  43.4700  44.530939  1.727523     1.176607   0.550916   \n2463  123854100.0  43.8050  44.813706  1.743436     1.289973   0.453463   \n2464   60341072.0  44.2275  45.136211  1.791876     1.390353   0.401522   \n\n         RSI_14      CCI_20   TRIX_10     ROC_10        KDJk    BB_High  \\\n0           NaN         NaN       NaN        NaN         NaN        NaN   \n1           NaN         NaN       NaN        NaN         NaN        NaN   \n2           NaN         NaN       NaN        NaN         NaN        NaN   \n3           NaN         NaN       NaN        NaN         NaN        NaN   \n4           NaN         NaN       NaN        NaN         NaN        NaN   \n...         ...         ...       ...        ...         ...        ...   \n2460  58.074512   87.307440  0.606329   7.582941   67.567580  48.062086   \n2461  63.790562  100.025055  0.634858  11.331783   87.837854  48.745028   \n2462  68.605023  163.677027  0.698822  17.370898  100.000000  49.869485   \n2463  59.535959  122.867528  0.735911   7.832012   61.825740  50.310913   \n2464  61.087073   82.334242  0.760003   4.782611   62.318862  50.722689   \n\n         BB_Low  Ease_of_Movement  \n0           NaN               NaN  \n1           NaN          2.836748  \n2           NaN          4.994903  \n3           NaN          4.201793  \n4           NaN          0.000000  \n...         ...               ...  \n2460  37.417914          6.711713  \n2461  37.329972          0.796477  \n2462  37.070516          0.000000  \n2463  37.299087         -0.742813  \n2464  37.732312        -17.842302  \n\n[2465 rows x 20 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>SMA_20</th>\n      <th>EMA_20</th>\n      <th>MACD</th>\n      <th>MACD_Signal</th>\n      <th>MACD_Hist</th>\n      <th>RSI_14</th>\n      <th>CCI_20</th>\n      <th>TRIX_10</th>\n      <th>ROC_10</th>\n      <th>KDJk</th>\n      <th>BB_High</th>\n      <th>BB_Low</th>\n      <th>Ease_of_Movement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-06-05</td>\n      <td>26.582294</td>\n      <td>27.408688</td>\n      <td>26.444563</td>\n      <td>27.408688</td>\n      <td>27.408688</td>\n      <td>48152360.0</td>\n      <td>NaN</td>\n      <td>27.408688</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-06-06</td>\n      <td>28.418722</td>\n      <td>28.740097</td>\n      <td>27.730061</td>\n      <td>28.740097</td>\n      <td>28.740097</td>\n      <td>46588034.0</td>\n      <td>NaN</td>\n      <td>27.535489</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.836748</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-06-09</td>\n      <td>29.841953</td>\n      <td>30.163328</td>\n      <td>29.612400</td>\n      <td>30.163328</td>\n      <td>30.163328</td>\n      <td>18229895.0</td>\n      <td>NaN</td>\n      <td>27.785759</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.994903</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-06-10</td>\n      <td>31.632471</td>\n      <td>31.632471</td>\n      <td>30.760166</td>\n      <td>31.632471</td>\n      <td>31.632471</td>\n      <td>27163910.0</td>\n      <td>NaN</td>\n      <td>28.152113</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.201793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-06-11</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>33.193436</td>\n      <td>5797435.0</td>\n      <td>NaN</td>\n      <td>28.632239</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>2024-05-30</td>\n      <td>46.299999</td>\n      <td>46.900002</td>\n      <td>44.500000</td>\n      <td>45.400002</td>\n      <td>45.400002</td>\n      <td>31288700.0</td>\n      <td>42.7400</td>\n      <td>43.566326</td>\n      <td>1.263158</td>\n      <td>0.941713</td>\n      <td>0.321446</td>\n      <td>58.074512</td>\n      <td>87.307440</td>\n      <td>0.606329</td>\n      <td>7.582941</td>\n      <td>67.567580</td>\n      <td>48.062086</td>\n      <td>37.417914</td>\n      <td>6.711713</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>2024-05-31</td>\n      <td>45.700001</td>\n      <td>47.650002</td>\n      <td>44.299999</td>\n      <td>47.650002</td>\n      <td>47.650002</td>\n      <td>115665511.0</td>\n      <td>43.0375</td>\n      <td>43.955248</td>\n      <td>1.427539</td>\n      <td>1.038878</td>\n      <td>0.388661</td>\n      <td>63.790562</td>\n      <td>100.025055</td>\n      <td>0.634858</td>\n      <td>11.331783</td>\n      <td>87.837854</td>\n      <td>48.745028</td>\n      <td>37.329972</td>\n      <td>0.796477</td>\n    </tr>\n    <tr>\n      <th>2462</th>\n      <td>2024-06-03</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>62876628.0</td>\n      <td>43.4700</td>\n      <td>44.530939</td>\n      <td>1.727523</td>\n      <td>1.176607</td>\n      <td>0.550916</td>\n      <td>68.605023</td>\n      <td>163.677027</td>\n      <td>0.698822</td>\n      <td>17.370898</td>\n      <td>100.000000</td>\n      <td>49.869485</td>\n      <td>37.070516</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2463</th>\n      <td>2024-06-04</td>\n      <td>52.099998</td>\n      <td>52.099998</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>123854100.0</td>\n      <td>43.8050</td>\n      <td>44.813706</td>\n      <td>1.743436</td>\n      <td>1.289973</td>\n      <td>0.453463</td>\n      <td>59.535959</td>\n      <td>122.867528</td>\n      <td>0.735911</td>\n      <td>7.832012</td>\n      <td>61.825740</td>\n      <td>50.310913</td>\n      <td>37.299087</td>\n      <td>-0.742813</td>\n    </tr>\n    <tr>\n      <th>2464</th>\n      <td>2024-06-05</td>\n      <td>45.150002</td>\n      <td>49.500000</td>\n      <td>45.150002</td>\n      <td>48.200001</td>\n      <td>48.200001</td>\n      <td>60341072.0</td>\n      <td>44.2275</td>\n      <td>45.136211</td>\n      <td>1.791876</td>\n      <td>1.390353</td>\n      <td>0.401522</td>\n      <td>61.087073</td>\n      <td>82.334242</td>\n      <td>0.760003</td>\n      <td>4.782611</td>\n      <td>62.318862</td>\n      <td>50.722689</td>\n      <td>37.732312</td>\n      <td>-17.842302</td>\n    </tr>\n  </tbody>\n</table>\n<p>2465 rows × 20 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace = True)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.440752Z",
          "iopub.execute_input": "2024-06-19T18:08:55.441148Z",
          "iopub.status.idle": "2024-06-19T18:08:55.473893Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.441094Z",
          "shell.execute_reply": "2024-06-19T18:08:55.473053Z"
        },
        "trusted": true,
        "id": "ywPPCouhMoD-",
        "outputId": "de2c5f65-4d5b-432d-aed8-6608dd9c3e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date       Open       High        Low      Close  Adj Close  \\\n33    2014-07-22  24.057205  24.057205  22.633974  22.817617  22.817617   \n34    2014-07-23  22.496243  22.955349  21.853493  22.725796  22.725796   \n35    2014-07-24  22.863527  22.863527  21.945313  22.174868  22.174868   \n36    2014-07-25  22.128956  22.174868  21.164831  21.578028  21.578028   \n37    2014-07-28  21.532118  21.532118  20.522081  20.659815  20.659815   \n...          ...        ...        ...        ...        ...        ...   \n2460  2024-05-30  46.299999  46.900002  44.500000  45.400002  45.400002   \n2461  2024-05-31  45.700001  47.650002  44.299999  47.650002  47.650002   \n2462  2024-06-03  50.000000  50.000000  50.000000  50.000000  50.000000   \n2463  2024-06-04  52.099998  52.099998  47.500000  47.500000  47.500000   \n2464  2024-06-05  45.150002  49.500000  45.150002  48.200001  48.200001   \n\n           Volume     SMA_20     EMA_20      MACD  MACD_Signal  MACD_Hist  \\\n33      4383188.0  24.098525  23.948220 -1.265075    -1.347207   0.082131   \n34      3836074.0  23.864381  23.831798 -1.207001    -1.319165   0.112165   \n35      2219868.0  23.657783  23.673996 -1.191695    -1.293671   0.101977   \n36      3167298.0  23.451184  23.474380 -1.213733    -1.277684   0.063951   \n37      4411813.0  23.182607  23.206326 -1.290416    -1.280230  -0.010186   \n...           ...        ...        ...       ...          ...        ...   \n2460   31288700.0  42.740000  43.566326  1.263158     0.941713   0.321446   \n2461  115665511.0  43.037500  43.955248  1.427539     1.038878   0.388661   \n2462   62876628.0  43.470000  44.530939  1.727523     1.176607   0.550916   \n2463  123854100.0  43.805000  44.813706  1.743436     1.289973   0.453463   \n2464   60341072.0  44.227500  45.136211  1.791876     1.390353   0.401522   \n\n         RSI_14      CCI_20   TRIX_10     ROC_10        KDJk    BB_High  \\\n33    41.006585  -38.482846 -0.970601  -6.226415   43.382372  27.802458   \n34    40.610105  -57.600808 -0.907881  -1.785713   41.911790  27.282752   \n35    38.222183  -59.919117 -0.855878  -5.294110   33.088266  26.958133   \n36    35.768416  -83.166668 -0.824189  -3.092777   24.615395  26.729042   \n37    32.329746 -107.373113 -0.824901  -2.386109   13.186854  26.451046   \n...         ...         ...       ...        ...         ...        ...   \n2460  58.074512   87.307440  0.606329   7.582941   67.567580  48.062086   \n2461  63.790562  100.025055  0.634858  11.331783   87.837854  48.745028   \n2462  68.605023  163.677027  0.698822  17.370898  100.000000  49.869485   \n2463  59.535959  122.867528  0.735911   7.832012   61.825740  50.310913   \n2464  61.087073   82.334242  0.760003   4.782611   62.318862  50.722689   \n\n         BB_Low  Ease_of_Movement  \n33    20.394592         -8.944378  \n34    20.446009        -27.033685  \n35    20.357432         -0.000041  \n36    20.173327        -23.425121  \n37    19.914168        -14.715068  \n...         ...               ...  \n2460  37.417914          6.711713  \n2461  37.329972          0.796477  \n2462  37.070516          0.000000  \n2463  37.299087         -0.742813  \n2464  37.732312        -17.842302  \n\n[2411 rows x 20 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>SMA_20</th>\n      <th>EMA_20</th>\n      <th>MACD</th>\n      <th>MACD_Signal</th>\n      <th>MACD_Hist</th>\n      <th>RSI_14</th>\n      <th>CCI_20</th>\n      <th>TRIX_10</th>\n      <th>ROC_10</th>\n      <th>KDJk</th>\n      <th>BB_High</th>\n      <th>BB_Low</th>\n      <th>Ease_of_Movement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>2014-07-22</td>\n      <td>24.057205</td>\n      <td>24.057205</td>\n      <td>22.633974</td>\n      <td>22.817617</td>\n      <td>22.817617</td>\n      <td>4383188.0</td>\n      <td>24.098525</td>\n      <td>23.948220</td>\n      <td>-1.265075</td>\n      <td>-1.347207</td>\n      <td>0.082131</td>\n      <td>41.006585</td>\n      <td>-38.482846</td>\n      <td>-0.970601</td>\n      <td>-6.226415</td>\n      <td>43.382372</td>\n      <td>27.802458</td>\n      <td>20.394592</td>\n      <td>-8.944378</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2014-07-23</td>\n      <td>22.496243</td>\n      <td>22.955349</td>\n      <td>21.853493</td>\n      <td>22.725796</td>\n      <td>22.725796</td>\n      <td>3836074.0</td>\n      <td>23.864381</td>\n      <td>23.831798</td>\n      <td>-1.207001</td>\n      <td>-1.319165</td>\n      <td>0.112165</td>\n      <td>40.610105</td>\n      <td>-57.600808</td>\n      <td>-0.907881</td>\n      <td>-1.785713</td>\n      <td>41.911790</td>\n      <td>27.282752</td>\n      <td>20.446009</td>\n      <td>-27.033685</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2014-07-24</td>\n      <td>22.863527</td>\n      <td>22.863527</td>\n      <td>21.945313</td>\n      <td>22.174868</td>\n      <td>22.174868</td>\n      <td>2219868.0</td>\n      <td>23.657783</td>\n      <td>23.673996</td>\n      <td>-1.191695</td>\n      <td>-1.293671</td>\n      <td>0.101977</td>\n      <td>38.222183</td>\n      <td>-59.919117</td>\n      <td>-0.855878</td>\n      <td>-5.294110</td>\n      <td>33.088266</td>\n      <td>26.958133</td>\n      <td>20.357432</td>\n      <td>-0.000041</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2014-07-25</td>\n      <td>22.128956</td>\n      <td>22.174868</td>\n      <td>21.164831</td>\n      <td>21.578028</td>\n      <td>21.578028</td>\n      <td>3167298.0</td>\n      <td>23.451184</td>\n      <td>23.474380</td>\n      <td>-1.213733</td>\n      <td>-1.277684</td>\n      <td>0.063951</td>\n      <td>35.768416</td>\n      <td>-83.166668</td>\n      <td>-0.824189</td>\n      <td>-3.092777</td>\n      <td>24.615395</td>\n      <td>26.729042</td>\n      <td>20.173327</td>\n      <td>-23.425121</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2014-07-28</td>\n      <td>21.532118</td>\n      <td>21.532118</td>\n      <td>20.522081</td>\n      <td>20.659815</td>\n      <td>20.659815</td>\n      <td>4411813.0</td>\n      <td>23.182607</td>\n      <td>23.206326</td>\n      <td>-1.290416</td>\n      <td>-1.280230</td>\n      <td>-0.010186</td>\n      <td>32.329746</td>\n      <td>-107.373113</td>\n      <td>-0.824901</td>\n      <td>-2.386109</td>\n      <td>13.186854</td>\n      <td>26.451046</td>\n      <td>19.914168</td>\n      <td>-14.715068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>2024-05-30</td>\n      <td>46.299999</td>\n      <td>46.900002</td>\n      <td>44.500000</td>\n      <td>45.400002</td>\n      <td>45.400002</td>\n      <td>31288700.0</td>\n      <td>42.740000</td>\n      <td>43.566326</td>\n      <td>1.263158</td>\n      <td>0.941713</td>\n      <td>0.321446</td>\n      <td>58.074512</td>\n      <td>87.307440</td>\n      <td>0.606329</td>\n      <td>7.582941</td>\n      <td>67.567580</td>\n      <td>48.062086</td>\n      <td>37.417914</td>\n      <td>6.711713</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>2024-05-31</td>\n      <td>45.700001</td>\n      <td>47.650002</td>\n      <td>44.299999</td>\n      <td>47.650002</td>\n      <td>47.650002</td>\n      <td>115665511.0</td>\n      <td>43.037500</td>\n      <td>43.955248</td>\n      <td>1.427539</td>\n      <td>1.038878</td>\n      <td>0.388661</td>\n      <td>63.790562</td>\n      <td>100.025055</td>\n      <td>0.634858</td>\n      <td>11.331783</td>\n      <td>87.837854</td>\n      <td>48.745028</td>\n      <td>37.329972</td>\n      <td>0.796477</td>\n    </tr>\n    <tr>\n      <th>2462</th>\n      <td>2024-06-03</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>62876628.0</td>\n      <td>43.470000</td>\n      <td>44.530939</td>\n      <td>1.727523</td>\n      <td>1.176607</td>\n      <td>0.550916</td>\n      <td>68.605023</td>\n      <td>163.677027</td>\n      <td>0.698822</td>\n      <td>17.370898</td>\n      <td>100.000000</td>\n      <td>49.869485</td>\n      <td>37.070516</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2463</th>\n      <td>2024-06-04</td>\n      <td>52.099998</td>\n      <td>52.099998</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>47.500000</td>\n      <td>123854100.0</td>\n      <td>43.805000</td>\n      <td>44.813706</td>\n      <td>1.743436</td>\n      <td>1.289973</td>\n      <td>0.453463</td>\n      <td>59.535959</td>\n      <td>122.867528</td>\n      <td>0.735911</td>\n      <td>7.832012</td>\n      <td>61.825740</td>\n      <td>50.310913</td>\n      <td>37.299087</td>\n      <td>-0.742813</td>\n    </tr>\n    <tr>\n      <th>2464</th>\n      <td>2024-06-05</td>\n      <td>45.150002</td>\n      <td>49.500000</td>\n      <td>45.150002</td>\n      <td>48.200001</td>\n      <td>48.200001</td>\n      <td>60341072.0</td>\n      <td>44.227500</td>\n      <td>45.136211</td>\n      <td>1.791876</td>\n      <td>1.390353</td>\n      <td>0.401522</td>\n      <td>61.087073</td>\n      <td>82.334242</td>\n      <td>0.760003</td>\n      <td>4.782611</td>\n      <td>62.318862</td>\n      <td>50.722689</td>\n      <td>37.732312</td>\n      <td>-17.842302</td>\n    </tr>\n  </tbody>\n</table>\n<p>2411 rows × 20 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:11, [4]].to_numpy().reshape(1, -1)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.474805Z",
          "iopub.execute_input": "2024-06-19T18:08:55.475058Z",
          "iopub.status.idle": "2024-06-19T18:08:55.483012Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.475035Z",
          "shell.execute_reply": "2024-06-19T18:08:55.482058Z"
        },
        "trusted": true,
        "id": "cDDv28AwMoD-",
        "outputId": "f877c433-7403-443d-fb49-c0fb84eb69c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([22.817617, 22.725796, 22.174868, 21.578028, 20.659815, 19.7416  ,\n       19.925243, 19.052938, 19.971153, 20.935278, 21.945313])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.487073Z",
          "iopub.execute_input": "2024-06-19T18:08:55.487361Z",
          "iopub.status.idle": "2024-06-19T18:08:55.493509Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.487337Z",
          "shell.execute_reply": "2024-06-19T18:08:55.492708Z"
        },
        "trusted": true,
        "id": "FniFdNtKMoD-",
        "outputId": "a4b50e5f-f17d-49b5-cda1-cfdac42289d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "2411"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data labeling (Buy:1, Sell:0, Hold: 2)"
      ],
      "metadata": {
        "id": "QMmdiQsFMoD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Buy:1, Sell:0, Hold: 2\n",
        "def label_data(df, window_size = 11):\n",
        "\n",
        "    mid_idx = window_size // 2\n",
        "\n",
        "    i = 0\n",
        "    idx = []\n",
        "    labels = []\n",
        "    while(i <= df.shape[0] - window_size + 1):\n",
        "        temp_arr = df.iloc[i : i + window_size, [4]].to_numpy().reshape(1, -1)[0]\n",
        "\n",
        "        if(temp_arr[mid_idx] == min(temp_arr)):\n",
        "            labels.append(1)\n",
        "        elif(temp_arr[mid_idx] == max(temp_arr)):\n",
        "            labels.append(0)\n",
        "        else:\n",
        "            labels.append(2)\n",
        "\n",
        "        idx.append(i + mid_idx)\n",
        "        i += 1\n",
        "\n",
        "    return idx, labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.494754Z",
          "iopub.execute_input": "2024-06-19T18:08:55.495075Z",
          "iopub.status.idle": "2024-06-19T18:08:55.503021Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.495044Z",
          "shell.execute_reply": "2024-06-19T18:08:55.502171Z"
        },
        "trusted": true,
        "id": "29ihlehiMoD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx, labels = label_data(df, 11)\n",
        "df = df.iloc[idx[0] : idx[-1] + 1]\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:55.504037Z",
          "iopub.execute_input": "2024-06-19T18:08:55.504299Z",
          "iopub.status.idle": "2024-06-19T18:08:56.076202Z",
          "shell.execute_reply.started": "2024-06-19T18:08:55.504276Z",
          "shell.execute_reply": "2024-06-19T18:08:56.075250Z"
        },
        "trusted": true,
        "id": "BAZ9y5fEMoD_",
        "outputId": "33949d13-09e6-4746-e4d6-033524865497"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date       Open       High        Low      Close  Adj Close  \\\n38    2014-07-30  20.384350  20.430260  19.649778  19.741600  19.741600   \n39    2014-07-31  19.649778  20.430260  18.777475  19.925243  19.925243   \n40    2014-08-01  19.557957  20.062975  18.961119  19.052938  19.052938   \n41    2014-08-04  19.971153  19.971153  19.649778  19.971153  19.971153   \n42    2014-08-05  20.108885  20.935278  19.971153  20.935278  20.935278   \n...          ...        ...        ...        ...        ...        ...   \n2456  2024-05-24  49.000000  49.000000  45.900002  45.950001  45.950001   \n2457  2024-05-27  45.250000  46.700001  45.000000  45.200001  45.200001   \n2458  2024-05-28  45.500000  45.849998  43.400002  43.950001  43.950001   \n2459  2024-05-29  43.900002  46.099998  43.549999  46.099998  46.099998   \n2460  2024-05-30  46.299999  46.900002  44.500000  45.400002  45.400002   \n\n          Volume     SMA_20     EMA_20      MACD  MACD_Signal  MACD_Hist  \\\n38     2806440.0  22.900256  22.876352 -1.409037    -1.305991  -0.103046   \n39     4137131.0  22.604132  22.595294 -1.471267    -1.339047  -0.132220   \n40     4161710.0  22.291939  22.257927 -1.572842    -1.385806  -0.187036   \n41     5602735.0  22.002702  22.040139 -1.561251    -1.420895  -0.140356   \n42     4193975.0  21.770853  21.934914 -1.457467    -1.428209  -0.029258   \n...          ...        ...        ...       ...          ...        ...   \n2456  53070069.0  42.057500  42.763304  1.232165     0.505080   0.727086   \n2457  38521150.0  42.210000  42.995371  1.264421     0.656948   0.607473   \n2458  26264263.0  42.325000  43.086288  1.175568     0.760672   0.414896   \n2459  30979346.0  42.550000  43.373308  1.264067     0.861351   0.402716   \n2460  31288700.0  42.740000  43.566326  1.263158     0.941713   0.321446   \n\n         RSI_14      CCI_20   TRIX_10     ROC_10       KDJk    BB_High  \\\n38    29.296598 -137.743354 -0.862484  -6.113539   1.980211  26.329340   \n39    30.697017 -138.732288 -0.908798  -9.583329  21.739142  25.986511   \n40    27.872925 -143.379847 -0.973938 -13.179921   5.217369  25.773711   \n41    34.684671 -109.458439 -1.016083 -12.121217  22.608694  25.237745   \n42    40.986743  -64.995821 -1.011579 -11.969107  40.869571  24.586882   \n...         ...         ...       ...        ...        ...        ...   \n2456  63.032913  204.778427  0.445245  16.035362  72.522527  46.759869   \n2457  59.762934  125.166463  0.530732  13.283205  65.765769  47.108224   \n2458  54.672230   71.933050  0.564561  12.692310  54.504505  47.272979   \n2459  60.849490   88.167967  0.594775  14.676609  73.873851  47.748557   \n2460  58.074512   87.307440  0.606329   7.582941  67.567580  48.062086   \n\n         BB_Low  Ease_of_Movement  \n38    19.471172        -27.451097  \n39    19.221753        -17.424265  \n40    18.810167         -2.431043  \n41    18.767658          1.711740  \n42    18.954823         14.775752  \n...         ...               ...  \n2456  37.355131          2.628604  \n2457  37.311776         -7.061062  \n2458  37.377020        -11.427110  \n2459  37.351443          1.646245  \n2460  37.417914          6.711713  \n\n[2402 rows x 20 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>SMA_20</th>\n      <th>EMA_20</th>\n      <th>MACD</th>\n      <th>MACD_Signal</th>\n      <th>MACD_Hist</th>\n      <th>RSI_14</th>\n      <th>CCI_20</th>\n      <th>TRIX_10</th>\n      <th>ROC_10</th>\n      <th>KDJk</th>\n      <th>BB_High</th>\n      <th>BB_Low</th>\n      <th>Ease_of_Movement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>2014-07-30</td>\n      <td>20.384350</td>\n      <td>20.430260</td>\n      <td>19.649778</td>\n      <td>19.741600</td>\n      <td>19.741600</td>\n      <td>2806440.0</td>\n      <td>22.900256</td>\n      <td>22.876352</td>\n      <td>-1.409037</td>\n      <td>-1.305991</td>\n      <td>-0.103046</td>\n      <td>29.296598</td>\n      <td>-137.743354</td>\n      <td>-0.862484</td>\n      <td>-6.113539</td>\n      <td>1.980211</td>\n      <td>26.329340</td>\n      <td>19.471172</td>\n      <td>-27.451097</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2014-07-31</td>\n      <td>19.649778</td>\n      <td>20.430260</td>\n      <td>18.777475</td>\n      <td>19.925243</td>\n      <td>19.925243</td>\n      <td>4137131.0</td>\n      <td>22.604132</td>\n      <td>22.595294</td>\n      <td>-1.471267</td>\n      <td>-1.339047</td>\n      <td>-0.132220</td>\n      <td>30.697017</td>\n      <td>-138.732288</td>\n      <td>-0.908798</td>\n      <td>-9.583329</td>\n      <td>21.739142</td>\n      <td>25.986511</td>\n      <td>19.221753</td>\n      <td>-17.424265</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2014-08-01</td>\n      <td>19.557957</td>\n      <td>20.062975</td>\n      <td>18.961119</td>\n      <td>19.052938</td>\n      <td>19.052938</td>\n      <td>4161710.0</td>\n      <td>22.291939</td>\n      <td>22.257927</td>\n      <td>-1.572842</td>\n      <td>-1.385806</td>\n      <td>-0.187036</td>\n      <td>27.872925</td>\n      <td>-143.379847</td>\n      <td>-0.973938</td>\n      <td>-13.179921</td>\n      <td>5.217369</td>\n      <td>25.773711</td>\n      <td>18.810167</td>\n      <td>-2.431043</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2014-08-04</td>\n      <td>19.971153</td>\n      <td>19.971153</td>\n      <td>19.649778</td>\n      <td>19.971153</td>\n      <td>19.971153</td>\n      <td>5602735.0</td>\n      <td>22.002702</td>\n      <td>22.040139</td>\n      <td>-1.561251</td>\n      <td>-1.420895</td>\n      <td>-0.140356</td>\n      <td>34.684671</td>\n      <td>-109.458439</td>\n      <td>-1.016083</td>\n      <td>-12.121217</td>\n      <td>22.608694</td>\n      <td>25.237745</td>\n      <td>18.767658</td>\n      <td>1.711740</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2014-08-05</td>\n      <td>20.108885</td>\n      <td>20.935278</td>\n      <td>19.971153</td>\n      <td>20.935278</td>\n      <td>20.935278</td>\n      <td>4193975.0</td>\n      <td>21.770853</td>\n      <td>21.934914</td>\n      <td>-1.457467</td>\n      <td>-1.428209</td>\n      <td>-0.029258</td>\n      <td>40.986743</td>\n      <td>-64.995821</td>\n      <td>-1.011579</td>\n      <td>-11.969107</td>\n      <td>40.869571</td>\n      <td>24.586882</td>\n      <td>18.954823</td>\n      <td>14.775752</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2456</th>\n      <td>2024-05-24</td>\n      <td>49.000000</td>\n      <td>49.000000</td>\n      <td>45.900002</td>\n      <td>45.950001</td>\n      <td>45.950001</td>\n      <td>53070069.0</td>\n      <td>42.057500</td>\n      <td>42.763304</td>\n      <td>1.232165</td>\n      <td>0.505080</td>\n      <td>0.727086</td>\n      <td>63.032913</td>\n      <td>204.778427</td>\n      <td>0.445245</td>\n      <td>16.035362</td>\n      <td>72.522527</td>\n      <td>46.759869</td>\n      <td>37.355131</td>\n      <td>2.628604</td>\n    </tr>\n    <tr>\n      <th>2457</th>\n      <td>2024-05-27</td>\n      <td>45.250000</td>\n      <td>46.700001</td>\n      <td>45.000000</td>\n      <td>45.200001</td>\n      <td>45.200001</td>\n      <td>38521150.0</td>\n      <td>42.210000</td>\n      <td>42.995371</td>\n      <td>1.264421</td>\n      <td>0.656948</td>\n      <td>0.607473</td>\n      <td>59.762934</td>\n      <td>125.166463</td>\n      <td>0.530732</td>\n      <td>13.283205</td>\n      <td>65.765769</td>\n      <td>47.108224</td>\n      <td>37.311776</td>\n      <td>-7.061062</td>\n    </tr>\n    <tr>\n      <th>2458</th>\n      <td>2024-05-28</td>\n      <td>45.500000</td>\n      <td>45.849998</td>\n      <td>43.400002</td>\n      <td>43.950001</td>\n      <td>43.950001</td>\n      <td>26264263.0</td>\n      <td>42.325000</td>\n      <td>43.086288</td>\n      <td>1.175568</td>\n      <td>0.760672</td>\n      <td>0.414896</td>\n      <td>54.672230</td>\n      <td>71.933050</td>\n      <td>0.564561</td>\n      <td>12.692310</td>\n      <td>54.504505</td>\n      <td>47.272979</td>\n      <td>37.377020</td>\n      <td>-11.427110</td>\n    </tr>\n    <tr>\n      <th>2459</th>\n      <td>2024-05-29</td>\n      <td>43.900002</td>\n      <td>46.099998</td>\n      <td>43.549999</td>\n      <td>46.099998</td>\n      <td>46.099998</td>\n      <td>30979346.0</td>\n      <td>42.550000</td>\n      <td>43.373308</td>\n      <td>1.264067</td>\n      <td>0.861351</td>\n      <td>0.402716</td>\n      <td>60.849490</td>\n      <td>88.167967</td>\n      <td>0.594775</td>\n      <td>14.676609</td>\n      <td>73.873851</td>\n      <td>47.748557</td>\n      <td>37.351443</td>\n      <td>1.646245</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>2024-05-30</td>\n      <td>46.299999</td>\n      <td>46.900002</td>\n      <td>44.500000</td>\n      <td>45.400002</td>\n      <td>45.400002</td>\n      <td>31288700.0</td>\n      <td>42.740000</td>\n      <td>43.566326</td>\n      <td>1.263158</td>\n      <td>0.941713</td>\n      <td>0.321446</td>\n      <td>58.074512</td>\n      <td>87.307440</td>\n      <td>0.606329</td>\n      <td>7.582941</td>\n      <td>67.567580</td>\n      <td>48.062086</td>\n      <td>37.417914</td>\n      <td>6.711713</td>\n    </tr>\n  </tbody>\n</table>\n<p>2402 rows × 20 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[-30:])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.077429Z",
          "iopub.execute_input": "2024-06-19T18:08:56.077767Z",
          "iopub.status.idle": "2024-06-19T18:08:56.083036Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.077734Z",
          "shell.execute_reply": "2024-06-19T18:08:56.082089Z"
        },
        "trusted": true,
        "id": "wiVGRgP7MoD_",
        "outputId": "787089b2-a227-4ed7-db63-99c0bdc7ab1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 2]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Labels\"] = labels\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.084221Z",
          "iopub.execute_input": "2024-06-19T18:08:56.084557Z",
          "iopub.status.idle": "2024-06-19T18:08:56.125926Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.084524Z",
          "shell.execute_reply": "2024-06-19T18:08:56.125046Z"
        },
        "trusted": true,
        "id": "x5E40g2EMoEC",
        "outputId": "53959794-56cd-4f12-99fd-71c9eed35856"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/1982047890.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"Labels\"] = labels\n",
          "output_type": "stream"
        },
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Date       Open       High        Low      Close  Adj Close  \\\n38    2014-07-30  20.384350  20.430260  19.649778  19.741600  19.741600   \n39    2014-07-31  19.649778  20.430260  18.777475  19.925243  19.925243   \n40    2014-08-01  19.557957  20.062975  18.961119  19.052938  19.052938   \n41    2014-08-04  19.971153  19.971153  19.649778  19.971153  19.971153   \n42    2014-08-05  20.108885  20.935278  19.971153  20.935278  20.935278   \n...          ...        ...        ...        ...        ...        ...   \n2456  2024-05-24  49.000000  49.000000  45.900002  45.950001  45.950001   \n2457  2024-05-27  45.250000  46.700001  45.000000  45.200001  45.200001   \n2458  2024-05-28  45.500000  45.849998  43.400002  43.950001  43.950001   \n2459  2024-05-29  43.900002  46.099998  43.549999  46.099998  46.099998   \n2460  2024-05-30  46.299999  46.900002  44.500000  45.400002  45.400002   \n\n          Volume     SMA_20     EMA_20      MACD  ...  MACD_Hist     RSI_14  \\\n38     2806440.0  22.900256  22.876352 -1.409037  ...  -0.103046  29.296598   \n39     4137131.0  22.604132  22.595294 -1.471267  ...  -0.132220  30.697017   \n40     4161710.0  22.291939  22.257927 -1.572842  ...  -0.187036  27.872925   \n41     5602735.0  22.002702  22.040139 -1.561251  ...  -0.140356  34.684671   \n42     4193975.0  21.770853  21.934914 -1.457467  ...  -0.029258  40.986743   \n...          ...        ...        ...       ...  ...        ...        ...   \n2456  53070069.0  42.057500  42.763304  1.232165  ...   0.727086  63.032913   \n2457  38521150.0  42.210000  42.995371  1.264421  ...   0.607473  59.762934   \n2458  26264263.0  42.325000  43.086288  1.175568  ...   0.414896  54.672230   \n2459  30979346.0  42.550000  43.373308  1.264067  ...   0.402716  60.849490   \n2460  31288700.0  42.740000  43.566326  1.263158  ...   0.321446  58.074512   \n\n          CCI_20   TRIX_10     ROC_10       KDJk    BB_High     BB_Low  \\\n38   -137.743354 -0.862484  -6.113539   1.980211  26.329340  19.471172   \n39   -138.732288 -0.908798  -9.583329  21.739142  25.986511  19.221753   \n40   -143.379847 -0.973938 -13.179921   5.217369  25.773711  18.810167   \n41   -109.458439 -1.016083 -12.121217  22.608694  25.237745  18.767658   \n42    -64.995821 -1.011579 -11.969107  40.869571  24.586882  18.954823   \n...          ...       ...        ...        ...        ...        ...   \n2456  204.778427  0.445245  16.035362  72.522527  46.759869  37.355131   \n2457  125.166463  0.530732  13.283205  65.765769  47.108224  37.311776   \n2458   71.933050  0.564561  12.692310  54.504505  47.272979  37.377020   \n2459   88.167967  0.594775  14.676609  73.873851  47.748557  37.351443   \n2460   87.307440  0.606329   7.582941  67.567580  48.062086  37.417914   \n\n      Ease_of_Movement  Labels  \n38          -27.451097       2  \n39          -17.424265       2  \n40           -2.431043       1  \n41            1.711740       2  \n42           14.775752       2  \n...                ...     ...  \n2456          2.628604       2  \n2457         -7.061062       2  \n2458        -11.427110       1  \n2459          1.646245       2  \n2460          6.711713       2  \n\n[2402 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>SMA_20</th>\n      <th>EMA_20</th>\n      <th>MACD</th>\n      <th>...</th>\n      <th>MACD_Hist</th>\n      <th>RSI_14</th>\n      <th>CCI_20</th>\n      <th>TRIX_10</th>\n      <th>ROC_10</th>\n      <th>KDJk</th>\n      <th>BB_High</th>\n      <th>BB_Low</th>\n      <th>Ease_of_Movement</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>2014-07-30</td>\n      <td>20.384350</td>\n      <td>20.430260</td>\n      <td>19.649778</td>\n      <td>19.741600</td>\n      <td>19.741600</td>\n      <td>2806440.0</td>\n      <td>22.900256</td>\n      <td>22.876352</td>\n      <td>-1.409037</td>\n      <td>...</td>\n      <td>-0.103046</td>\n      <td>29.296598</td>\n      <td>-137.743354</td>\n      <td>-0.862484</td>\n      <td>-6.113539</td>\n      <td>1.980211</td>\n      <td>26.329340</td>\n      <td>19.471172</td>\n      <td>-27.451097</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2014-07-31</td>\n      <td>19.649778</td>\n      <td>20.430260</td>\n      <td>18.777475</td>\n      <td>19.925243</td>\n      <td>19.925243</td>\n      <td>4137131.0</td>\n      <td>22.604132</td>\n      <td>22.595294</td>\n      <td>-1.471267</td>\n      <td>...</td>\n      <td>-0.132220</td>\n      <td>30.697017</td>\n      <td>-138.732288</td>\n      <td>-0.908798</td>\n      <td>-9.583329</td>\n      <td>21.739142</td>\n      <td>25.986511</td>\n      <td>19.221753</td>\n      <td>-17.424265</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2014-08-01</td>\n      <td>19.557957</td>\n      <td>20.062975</td>\n      <td>18.961119</td>\n      <td>19.052938</td>\n      <td>19.052938</td>\n      <td>4161710.0</td>\n      <td>22.291939</td>\n      <td>22.257927</td>\n      <td>-1.572842</td>\n      <td>...</td>\n      <td>-0.187036</td>\n      <td>27.872925</td>\n      <td>-143.379847</td>\n      <td>-0.973938</td>\n      <td>-13.179921</td>\n      <td>5.217369</td>\n      <td>25.773711</td>\n      <td>18.810167</td>\n      <td>-2.431043</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2014-08-04</td>\n      <td>19.971153</td>\n      <td>19.971153</td>\n      <td>19.649778</td>\n      <td>19.971153</td>\n      <td>19.971153</td>\n      <td>5602735.0</td>\n      <td>22.002702</td>\n      <td>22.040139</td>\n      <td>-1.561251</td>\n      <td>...</td>\n      <td>-0.140356</td>\n      <td>34.684671</td>\n      <td>-109.458439</td>\n      <td>-1.016083</td>\n      <td>-12.121217</td>\n      <td>22.608694</td>\n      <td>25.237745</td>\n      <td>18.767658</td>\n      <td>1.711740</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2014-08-05</td>\n      <td>20.108885</td>\n      <td>20.935278</td>\n      <td>19.971153</td>\n      <td>20.935278</td>\n      <td>20.935278</td>\n      <td>4193975.0</td>\n      <td>21.770853</td>\n      <td>21.934914</td>\n      <td>-1.457467</td>\n      <td>...</td>\n      <td>-0.029258</td>\n      <td>40.986743</td>\n      <td>-64.995821</td>\n      <td>-1.011579</td>\n      <td>-11.969107</td>\n      <td>40.869571</td>\n      <td>24.586882</td>\n      <td>18.954823</td>\n      <td>14.775752</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2456</th>\n      <td>2024-05-24</td>\n      <td>49.000000</td>\n      <td>49.000000</td>\n      <td>45.900002</td>\n      <td>45.950001</td>\n      <td>45.950001</td>\n      <td>53070069.0</td>\n      <td>42.057500</td>\n      <td>42.763304</td>\n      <td>1.232165</td>\n      <td>...</td>\n      <td>0.727086</td>\n      <td>63.032913</td>\n      <td>204.778427</td>\n      <td>0.445245</td>\n      <td>16.035362</td>\n      <td>72.522527</td>\n      <td>46.759869</td>\n      <td>37.355131</td>\n      <td>2.628604</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2457</th>\n      <td>2024-05-27</td>\n      <td>45.250000</td>\n      <td>46.700001</td>\n      <td>45.000000</td>\n      <td>45.200001</td>\n      <td>45.200001</td>\n      <td>38521150.0</td>\n      <td>42.210000</td>\n      <td>42.995371</td>\n      <td>1.264421</td>\n      <td>...</td>\n      <td>0.607473</td>\n      <td>59.762934</td>\n      <td>125.166463</td>\n      <td>0.530732</td>\n      <td>13.283205</td>\n      <td>65.765769</td>\n      <td>47.108224</td>\n      <td>37.311776</td>\n      <td>-7.061062</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2458</th>\n      <td>2024-05-28</td>\n      <td>45.500000</td>\n      <td>45.849998</td>\n      <td>43.400002</td>\n      <td>43.950001</td>\n      <td>43.950001</td>\n      <td>26264263.0</td>\n      <td>42.325000</td>\n      <td>43.086288</td>\n      <td>1.175568</td>\n      <td>...</td>\n      <td>0.414896</td>\n      <td>54.672230</td>\n      <td>71.933050</td>\n      <td>0.564561</td>\n      <td>12.692310</td>\n      <td>54.504505</td>\n      <td>47.272979</td>\n      <td>37.377020</td>\n      <td>-11.427110</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2459</th>\n      <td>2024-05-29</td>\n      <td>43.900002</td>\n      <td>46.099998</td>\n      <td>43.549999</td>\n      <td>46.099998</td>\n      <td>46.099998</td>\n      <td>30979346.0</td>\n      <td>42.550000</td>\n      <td>43.373308</td>\n      <td>1.264067</td>\n      <td>...</td>\n      <td>0.402716</td>\n      <td>60.849490</td>\n      <td>88.167967</td>\n      <td>0.594775</td>\n      <td>14.676609</td>\n      <td>73.873851</td>\n      <td>47.748557</td>\n      <td>37.351443</td>\n      <td>1.646245</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>2024-05-30</td>\n      <td>46.299999</td>\n      <td>46.900002</td>\n      <td>44.500000</td>\n      <td>45.400002</td>\n      <td>45.400002</td>\n      <td>31288700.0</td>\n      <td>42.740000</td>\n      <td>43.566326</td>\n      <td>1.263158</td>\n      <td>...</td>\n      <td>0.321446</td>\n      <td>58.074512</td>\n      <td>87.307440</td>\n      <td>0.606329</td>\n      <td>7.582941</td>\n      <td>67.567580</td>\n      <td>48.062086</td>\n      <td>37.417914</td>\n      <td>6.711713</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2402 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[4]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.127095Z",
          "iopub.execute_input": "2024-06-19T18:08:56.127419Z",
          "iopub.status.idle": "2024-06-19T18:08:56.133388Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.127394Z",
          "shell.execute_reply": "2024-06-19T18:08:56.132471Z"
        },
        "trusted": true,
        "id": "g3cDhTCMMoED",
        "outputId": "e97c8a55-9317-48da-ce4d-3fcfc89cd747"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Close'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[df.columns[1:20]].to_numpy()\n",
        "Y = df[\"Labels\"].to_numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.134545Z",
          "iopub.execute_input": "2024-06-19T18:08:56.135173Z",
          "iopub.status.idle": "2024-06-19T18:08:56.142518Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.135121Z",
          "shell.execute_reply": "2024-06-19T18:08:56.141601Z"
        },
        "trusted": true,
        "id": "xO_X64afMoED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizing of data"
      ],
      "metadata": {
        "id": "I4f32vfyMoED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "print(X_normalized[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.143681Z",
          "iopub.execute_input": "2024-06-19T18:08:56.144119Z",
          "iopub.status.idle": "2024-06-19T18:08:56.153535Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.144089Z",
          "shell.execute_reply": "2024-06-19T18:08:56.152703Z"
        },
        "trusted": true,
        "id": "M_vBPI72MoED",
        "outputId": "c1153477-bcbb-4289-a542-6488bb0c3200"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[  0.83146645   0.79373916   0.80606565   0.76993698   0.76993698\n  -0.71271245   1.13842252   1.13700301  -2.35639905  -2.30278075\n  -0.63011019  -1.50895033  -1.15887896  -1.0681514   -0.51532257\n  -1.4951163    1.23713835   1.00759959 -15.21974706]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.154594Z",
          "iopub.execute_input": "2024-06-19T18:08:56.155082Z",
          "iopub.status.idle": "2024-06-19T18:08:56.162672Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.155058Z",
          "shell.execute_reply": "2024-06-19T18:08:56.161830Z"
        },
        "trusted": true,
        "id": "lCcdNFOlMoED",
        "outputId": "da1609b9-e4eb-429a-b297-fa634310b6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([2, 2, 1, ..., 1, 2, 2])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Random Forest for important features selection"
      ],
      "metadata": {
        "id": "65dMD8s7MoED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf.fit(X_normalized, Y)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "print(np.array(importances))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:56.163760Z",
          "iopub.execute_input": "2024-06-19T18:08:56.165646Z",
          "iopub.status.idle": "2024-06-19T18:08:57.106499Z",
          "shell.execute_reply.started": "2024-06-19T18:08:56.165621Z",
          "shell.execute_reply": "2024-06-19T18:08:57.105189Z"
        },
        "trusted": true,
        "id": "h46lOc7dMoED",
        "outputId": "d4b12eeb-13ef-43c9-f6e3-8773832ff543"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[0.03428351 0.03417007 0.03569863 0.03614762 0.03559593 0.06160987\n 0.03767782 0.03781259 0.05159663 0.04949245 0.06060495 0.07950543\n 0.07751408 0.06073212 0.0615957  0.08372466 0.04078255 0.04164792\n 0.07980747]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_idx = np.argsort(importances) + np.ones(len(importances))\n",
        "features = []\n",
        "imp = []\n",
        "i = len(features_idx) - 1\n",
        "for i in np.flip(features_idx).astype(int):\n",
        "    features.append(df.columns[i])\n",
        "    imp.append(importances[i - 1])\n",
        "print(imp)\n",
        "print(features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.107761Z",
          "iopub.execute_input": "2024-06-19T18:08:57.108021Z",
          "iopub.status.idle": "2024-06-19T18:08:57.114901Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.107998Z",
          "shell.execute_reply": "2024-06-19T18:08:57.113946Z"
        },
        "trusted": true,
        "id": "OBjxnAltMoED",
        "outputId": "a79ccf8f-0dfd-45b5-a770-374e824e218b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[0.08372466091027676, 0.07980747150761025, 0.0795054293289301, 0.07751408448781495, 0.061609871703398905, 0.06159569528604486, 0.06073211879370061, 0.06060494534058805, 0.05159663059207276, 0.04949244611714781, 0.04164791707567941, 0.04078255182792074, 0.037812586530566454, 0.03767782122083246, 0.036147617414848184, 0.03569863352363239, 0.03559593279835648, 0.03428351431817974, 0.03417007122239896]\n['KDJk', 'Ease_of_Movement', 'RSI_14', 'CCI_20', 'Volume', 'ROC_10', 'TRIX_10', 'MACD_Hist', 'MACD', 'MACD_Signal', 'BB_Low', 'BB_High', 'EMA_20', 'SMA_20', 'Close', 'Low', 'Adj Close', 'Open', 'High']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(features, imp)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances from Random Forest Classifier')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.116293Z",
          "iopub.execute_input": "2024-06-19T18:08:57.117035Z",
          "iopub.status.idle": "2024-06-19T18:08:57.532931Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.116994Z",
          "shell.execute_reply": "2024-06-19T18:08:57.532018Z"
        },
        "trusted": true,
        "id": "Mw7QWqdbMoEE",
        "outputId": "0e102f65-0668-441f-c15a-3780c7e41de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = df[features[:16]]\n",
        "updated_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.534114Z",
          "iopub.execute_input": "2024-06-19T18:08:57.534434Z",
          "iopub.status.idle": "2024-06-19T18:08:57.561898Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.534409Z",
          "shell.execute_reply": "2024-06-19T18:08:57.560847Z"
        },
        "trusted": true,
        "id": "Lcd9g34mMoEE",
        "outputId": "028c194a-06a7-4573-af51-79351d979983"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           KDJk  Ease_of_Movement     RSI_14      CCI_20      Volume  \\\n38     1.980211        -27.451097  29.296598 -137.743354   2806440.0   \n39    21.739142        -17.424265  30.697017 -138.732288   4137131.0   \n40     5.217369         -2.431043  27.872925 -143.379847   4161710.0   \n41    22.608694          1.711740  34.684671 -109.458439   5602735.0   \n42    40.869571         14.775752  40.986743  -64.995821   4193975.0   \n...         ...               ...        ...         ...         ...   \n2456  72.522527          2.628604  63.032913  204.778427  53070069.0   \n2457  65.765769         -7.061062  59.762934  125.166463  38521150.0   \n2458  54.504505        -11.427110  54.672230   71.933050  26264263.0   \n2459  73.873851          1.646245  60.849490   88.167967  30979346.0   \n2460  67.567580          6.711713  58.074512   87.307440  31288700.0   \n\n         ROC_10   TRIX_10  MACD_Hist      MACD  MACD_Signal     BB_Low  \\\n38    -6.113539 -0.862484  -0.103046 -1.409037    -1.305991  19.471172   \n39    -9.583329 -0.908798  -0.132220 -1.471267    -1.339047  19.221753   \n40   -13.179921 -0.973938  -0.187036 -1.572842    -1.385806  18.810167   \n41   -12.121217 -1.016083  -0.140356 -1.561251    -1.420895  18.767658   \n42   -11.969107 -1.011579  -0.029258 -1.457467    -1.428209  18.954823   \n...         ...       ...        ...       ...          ...        ...   \n2456  16.035362  0.445245   0.727086  1.232165     0.505080  37.355131   \n2457  13.283205  0.530732   0.607473  1.264421     0.656948  37.311776   \n2458  12.692310  0.564561   0.414896  1.175568     0.760672  37.377020   \n2459  14.676609  0.594775   0.402716  1.264067     0.861351  37.351443   \n2460   7.582941  0.606329   0.321446  1.263158     0.941713  37.417914   \n\n        BB_High     EMA_20     SMA_20      Close        Low  \n38    26.329340  22.876352  22.900256  19.741600  19.649778  \n39    25.986511  22.595294  22.604132  19.925243  18.777475  \n40    25.773711  22.257927  22.291939  19.052938  18.961119  \n41    25.237745  22.040139  22.002702  19.971153  19.649778  \n42    24.586882  21.934914  21.770853  20.935278  19.971153  \n...         ...        ...        ...        ...        ...  \n2456  46.759869  42.763304  42.057500  45.950001  45.900002  \n2457  47.108224  42.995371  42.210000  45.200001  45.000000  \n2458  47.272979  43.086288  42.325000  43.950001  43.400002  \n2459  47.748557  43.373308  42.550000  46.099998  43.549999  \n2460  48.062086  43.566326  42.740000  45.400002  44.500000  \n\n[2402 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KDJk</th>\n      <th>Ease_of_Movement</th>\n      <th>RSI_14</th>\n      <th>CCI_20</th>\n      <th>Volume</th>\n      <th>ROC_10</th>\n      <th>TRIX_10</th>\n      <th>MACD_Hist</th>\n      <th>MACD</th>\n      <th>MACD_Signal</th>\n      <th>BB_Low</th>\n      <th>BB_High</th>\n      <th>EMA_20</th>\n      <th>SMA_20</th>\n      <th>Close</th>\n      <th>Low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>1.980211</td>\n      <td>-27.451097</td>\n      <td>29.296598</td>\n      <td>-137.743354</td>\n      <td>2806440.0</td>\n      <td>-6.113539</td>\n      <td>-0.862484</td>\n      <td>-0.103046</td>\n      <td>-1.409037</td>\n      <td>-1.305991</td>\n      <td>19.471172</td>\n      <td>26.329340</td>\n      <td>22.876352</td>\n      <td>22.900256</td>\n      <td>19.741600</td>\n      <td>19.649778</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>21.739142</td>\n      <td>-17.424265</td>\n      <td>30.697017</td>\n      <td>-138.732288</td>\n      <td>4137131.0</td>\n      <td>-9.583329</td>\n      <td>-0.908798</td>\n      <td>-0.132220</td>\n      <td>-1.471267</td>\n      <td>-1.339047</td>\n      <td>19.221753</td>\n      <td>25.986511</td>\n      <td>22.595294</td>\n      <td>22.604132</td>\n      <td>19.925243</td>\n      <td>18.777475</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>5.217369</td>\n      <td>-2.431043</td>\n      <td>27.872925</td>\n      <td>-143.379847</td>\n      <td>4161710.0</td>\n      <td>-13.179921</td>\n      <td>-0.973938</td>\n      <td>-0.187036</td>\n      <td>-1.572842</td>\n      <td>-1.385806</td>\n      <td>18.810167</td>\n      <td>25.773711</td>\n      <td>22.257927</td>\n      <td>22.291939</td>\n      <td>19.052938</td>\n      <td>18.961119</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>22.608694</td>\n      <td>1.711740</td>\n      <td>34.684671</td>\n      <td>-109.458439</td>\n      <td>5602735.0</td>\n      <td>-12.121217</td>\n      <td>-1.016083</td>\n      <td>-0.140356</td>\n      <td>-1.561251</td>\n      <td>-1.420895</td>\n      <td>18.767658</td>\n      <td>25.237745</td>\n      <td>22.040139</td>\n      <td>22.002702</td>\n      <td>19.971153</td>\n      <td>19.649778</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>40.869571</td>\n      <td>14.775752</td>\n      <td>40.986743</td>\n      <td>-64.995821</td>\n      <td>4193975.0</td>\n      <td>-11.969107</td>\n      <td>-1.011579</td>\n      <td>-0.029258</td>\n      <td>-1.457467</td>\n      <td>-1.428209</td>\n      <td>18.954823</td>\n      <td>24.586882</td>\n      <td>21.934914</td>\n      <td>21.770853</td>\n      <td>20.935278</td>\n      <td>19.971153</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2456</th>\n      <td>72.522527</td>\n      <td>2.628604</td>\n      <td>63.032913</td>\n      <td>204.778427</td>\n      <td>53070069.0</td>\n      <td>16.035362</td>\n      <td>0.445245</td>\n      <td>0.727086</td>\n      <td>1.232165</td>\n      <td>0.505080</td>\n      <td>37.355131</td>\n      <td>46.759869</td>\n      <td>42.763304</td>\n      <td>42.057500</td>\n      <td>45.950001</td>\n      <td>45.900002</td>\n    </tr>\n    <tr>\n      <th>2457</th>\n      <td>65.765769</td>\n      <td>-7.061062</td>\n      <td>59.762934</td>\n      <td>125.166463</td>\n      <td>38521150.0</td>\n      <td>13.283205</td>\n      <td>0.530732</td>\n      <td>0.607473</td>\n      <td>1.264421</td>\n      <td>0.656948</td>\n      <td>37.311776</td>\n      <td>47.108224</td>\n      <td>42.995371</td>\n      <td>42.210000</td>\n      <td>45.200001</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>2458</th>\n      <td>54.504505</td>\n      <td>-11.427110</td>\n      <td>54.672230</td>\n      <td>71.933050</td>\n      <td>26264263.0</td>\n      <td>12.692310</td>\n      <td>0.564561</td>\n      <td>0.414896</td>\n      <td>1.175568</td>\n      <td>0.760672</td>\n      <td>37.377020</td>\n      <td>47.272979</td>\n      <td>43.086288</td>\n      <td>42.325000</td>\n      <td>43.950001</td>\n      <td>43.400002</td>\n    </tr>\n    <tr>\n      <th>2459</th>\n      <td>73.873851</td>\n      <td>1.646245</td>\n      <td>60.849490</td>\n      <td>88.167967</td>\n      <td>30979346.0</td>\n      <td>14.676609</td>\n      <td>0.594775</td>\n      <td>0.402716</td>\n      <td>1.264067</td>\n      <td>0.861351</td>\n      <td>37.351443</td>\n      <td>47.748557</td>\n      <td>43.373308</td>\n      <td>42.550000</td>\n      <td>46.099998</td>\n      <td>43.549999</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>67.567580</td>\n      <td>6.711713</td>\n      <td>58.074512</td>\n      <td>87.307440</td>\n      <td>31288700.0</td>\n      <td>7.582941</td>\n      <td>0.606329</td>\n      <td>0.321446</td>\n      <td>1.263158</td>\n      <td>0.941713</td>\n      <td>37.417914</td>\n      <td>48.062086</td>\n      <td>43.566326</td>\n      <td>42.740000</td>\n      <td>45.400002</td>\n      <td>44.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2402 rows × 16 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_X = updated_df.to_numpy()\n",
        "reduced_X = scaler.fit_transform(updated_X)\n",
        "reduced_X.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.562982Z",
          "iopub.execute_input": "2024-06-19T18:08:57.563279Z",
          "iopub.status.idle": "2024-06-19T18:08:57.571691Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.563257Z",
          "shell.execute_reply": "2024-06-19T18:08:57.570735Z"
        },
        "trusted": true,
        "id": "vNP28vwBMoEE",
        "outputId": "d60fb7fa-f1be-442c-cba4-43e287beae1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2402, 16)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.572932Z",
          "iopub.execute_input": "2024-06-19T18:08:57.573278Z",
          "iopub.status.idle": "2024-06-19T18:08:57.579872Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.573246Z",
          "shell.execute_reply": "2024-06-19T18:08:57.578867Z"
        },
        "trusted": true,
        "id": "a-csobkNMoEE",
        "outputId": "a8902125-5697-4de4-f817-a6856f70fa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2402,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.580954Z",
          "iopub.execute_input": "2024-06-19T18:08:57.581249Z",
          "iopub.status.idle": "2024-06-19T18:08:57.590935Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.581225Z",
          "shell.execute_reply": "2024-06-19T18:08:57.590116Z"
        },
        "trusted": true,
        "id": "bvQbQiHQMoEE",
        "outputId": "b954630d-c4a4-42a0-b2a1-13264a7e36cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ -1.4951163 , -15.21974706,  -1.50895033, ...,   1.13842252,\n          0.76993698,   0.80606565],\n       [ -0.80898933,  -9.64443646,  -1.40331271, ...,   1.10639754,\n          0.78932356,   0.71184352],\n       [ -1.3827063 ,  -1.30761927,  -1.61634209, ...,   1.07263475,\n          0.6972372 ,   0.73167989],\n       ...,\n       [  0.32878478,  -6.30978425,   0.40520678, ...,   3.23915442,\n          3.3255381 ,   3.37145474],\n       [  1.00138345,   0.95951243,   0.8711753 , ...,   3.26348755,\n          3.5525062 ,   3.38765672],\n       [  0.78239878,   3.77611057,   0.66185074, ...,   3.28403554,\n          3.47860993,   3.49027143]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image Conversion"
      ],
      "metadata": {
        "id": "OXJjtO2dMoEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_X = reduced_X.reshape(2402, 4, 4)\n",
        "img_X.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.592058Z",
          "iopub.execute_input": "2024-06-19T18:08:57.592354Z",
          "iopub.status.idle": "2024-06-19T18:08:57.600779Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.592329Z",
          "shell.execute_reply": "2024-06-19T18:08:57.599918Z"
        },
        "trusted": true,
        "id": "LJvT2hNYMoEE",
        "outputId": "a84bab8f-d144-4a1d-dd57-34b7521db0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2402, 4, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_X[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.601911Z",
          "iopub.execute_input": "2024-06-19T18:08:57.602258Z",
          "iopub.status.idle": "2024-06-19T18:08:57.610988Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.602225Z",
          "shell.execute_reply": "2024-06-19T18:08:57.610186Z"
        },
        "trusted": true,
        "id": "R9qfKAauMoEE",
        "outputId": "d83d4a20-7839-41da-9c1c-a8eeb0b12322"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ -1.4951163 , -15.21974706,  -1.50895033,  -1.15887896],\n       [ -0.71271245,  -0.51532257,  -1.0681514 ,  -0.63011019],\n       [ -2.35639905,  -2.30278075,   1.00759959,   1.23713835],\n       [  1.13700301,   1.13842252,   0.76993698,   0.80606565]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:08:57.616228Z",
          "iopub.execute_input": "2024-06-19T18:08:57.616562Z",
          "iopub.status.idle": "2024-06-19T18:09:09.909707Z",
          "shell.execute_reply.started": "2024-06-19T18:08:57.616540Z",
          "shell.execute_reply": "2024-06-19T18:09:09.908573Z"
        },
        "trusted": true,
        "id": "LWaO6HV9MoEF",
        "outputId": "53b78bd4-b19e-41f6-b3d0-b6ed4fb21a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "normalized_array = ((img_X[200] - img_X[200].min()) / (img_X[200].max() - img_X[200].min()) * 255).astype(np.uint8)\n",
        "print(normalized_array)\n",
        "image = Image.fromarray(normalized_array)\n",
        "plt.imshow(image, cmap = 'gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "print(f\"Label: {Y[200]}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:09.911397Z",
          "iopub.execute_input": "2024-06-19T18:09:09.911804Z",
          "iopub.status.idle": "2024-06-19T18:09:10.002831Z",
          "shell.execute_reply.started": "2024-06-19T18:09:09.911766Z",
          "shell.execute_reply": "2024-06-19T18:09:10.001581Z"
        },
        "trusted": true,
        "id": "9V1xc44wMoEF",
        "outputId": "c6bd6a70-e267-4a28-bc4f-5c67809c3b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[113 116  63 131]\n [ 74 118  99 255]\n [ 43   0 243 237]\n [249 240 236 241]]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Label: 2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Y)):\n",
        "    img_X[i] = ((img_X[i] - img_X[i].min()) / (img_X[i].max() - img_X[i].min()) * 255).astype(np.uint8)\n",
        "print(img_X)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:10.008605Z",
          "iopub.execute_input": "2024-06-19T18:09:10.009077Z",
          "iopub.status.idle": "2024-06-19T18:09:10.119914Z",
          "shell.execute_reply.started": "2024-06-19T18:09:10.009036Z",
          "shell.execute_reply": "2024-06-19T18:09:10.119047Z"
        },
        "trusted": true,
        "id": "q_PyIsojMoEF",
        "outputId": "2a61c4ef-899b-485e-9824-e755ffd6177c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[[212.   0. 212. 217.]\n  [224. 227. 219. 226.]\n  [199. 200. 251. 255.]\n  [253. 253. 247. 248.]]\n\n [[207.   0. 193. 199.]\n  [210. 208. 200. 207.]\n  [168. 171. 249. 255.]\n  [252. 252. 245. 243.]]\n\n [[ 83.  88.  67.  94.]\n  [129. 107.  95. 100.]\n  [  0.  12. 238. 255.]\n  [247. 247. 222. 224.]]\n\n ...\n\n [[174.   0. 176. 183.]\n  [156. 187. 183. 229.]\n  [215. 199. 248. 253.]\n  [253. 251. 253. 255.]]\n\n [[ 86.  83.  78.  73.]\n  [  0.  83.  66. 173.]\n  [152. 114. 227. 241.]\n  [242. 235. 255. 244.]]\n\n [[ 68. 255.  60.  68.]\n  [  0.  47.  63. 134.]\n  [144. 116. 215. 229.]\n  [230. 224. 236. 237.]]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Model Building"
      ],
      "metadata": {
        "id": "KH3YZRxtMoEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:10.120995Z",
          "iopub.execute_input": "2024-06-19T18:09:10.121303Z",
          "iopub.status.idle": "2024-06-19T18:09:14.770677Z",
          "shell.execute_reply.started": "2024-06-19T18:09:10.121276Z",
          "shell.execute_reply": "2024-06-19T18:09:14.769879Z"
        },
        "trusted": true,
        "id": "Fu3TTji5MoEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_X_tensor = torch.from_numpy(img_X).unsqueeze(1) #For adding a channel dimension which is 1 here\n",
        "Y_tensor = torch.from_numpy(Y)\n",
        "print(img_X_tensor.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.771948Z",
          "iopub.execute_input": "2024-06-19T18:09:14.772783Z",
          "iopub.status.idle": "2024-06-19T18:09:14.790797Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.772747Z",
          "shell.execute_reply": "2024-06-19T18:09:14.789995Z"
        },
        "trusted": true,
        "id": "x2Dav2DUMoEF",
        "outputId": "23db84de-8151-4757-d470-44a183314788"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([2402, 1, 4, 4])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((255/2), (255/2))\n",
        "])\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomImageDataset(img_X_tensor, Y_tensor, transform=transform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.791783Z",
          "iopub.execute_input": "2024-06-19T18:09:14.792092Z",
          "iopub.status.idle": "2024-06-19T18:09:14.799506Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.792067Z",
          "shell.execute_reply": "2024-06-19T18:09:14.798710Z"
        },
        "trusted": true,
        "id": "KcktiAykMoEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab = dataset.__getitem__(200)\n",
        "print(img, lab)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.800532Z",
          "iopub.execute_input": "2024-06-19T18:09:14.800795Z",
          "iopub.status.idle": "2024-06-19T18:09:14.875702Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.800773Z",
          "shell.execute_reply": "2024-06-19T18:09:14.874905Z"
        },
        "trusted": true,
        "id": "P9-A40CzMoEJ",
        "outputId": "bf9d9949-478a-42b6-8c1d-2a6e02f78924"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[-0.1137, -0.0902, -0.5059,  0.0275],\n         [-0.4196, -0.0745, -0.2235,  1.0000],\n         [-0.6627, -1.0000,  0.9059,  0.8588],\n         [ 0.9529,  0.8824,  0.8510,  0.8902]]], dtype=torch.float64) tensor(2)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "print(train_dataset.__len__())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.877080Z",
          "iopub.execute_input": "2024-06-19T18:09:14.877422Z",
          "iopub.status.idle": "2024-06-19T18:09:14.884721Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.877391Z",
          "shell.execute_reply": "2024-06-19T18:09:14.883846Z"
        },
        "trusted": true,
        "id": "RNJLtjrrMoEJ",
        "outputId": "68d56ae5-df0a-4098-e414-a3df0a2dc52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1921\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[1920]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.885800Z",
          "iopub.execute_input": "2024-06-19T18:09:14.886384Z",
          "iopub.status.idle": "2024-06-19T18:09:14.900668Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.886358Z",
          "shell.execute_reply": "2024-06-19T18:09:14.899825Z"
        },
        "trusted": true,
        "id": "j6KD0LbUMoEJ",
        "outputId": "918fcc9b-a899-418b-b156-510f72e28f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([[[-0.2941,  0.2784, -0.3961, -0.1373],\n          [ 0.7255, -0.7804, -0.5216, -0.7882],\n          [-1.0000, -0.6784,  0.6863,  1.0000],\n          [ 0.8275,  0.8588,  0.5843,  0.5922]]], dtype=torch.float64),\n tensor(1))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.901749Z",
          "iopub.execute_input": "2024-06-19T18:09:14.902007Z",
          "iopub.status.idle": "2024-06-19T18:09:14.909898Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.901979Z",
          "shell.execute_reply": "2024-06-19T18:09:14.909169Z"
        },
        "trusted": true,
        "id": "cYnPWePKMoEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1, stride = 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1, stride = 1)\n",
        "        self.fc1 = nn.Linear(32 * 6 * 6, 128)\n",
        "        self.dropout = nn.Dropout(0.1)  #Prevents overfitting by randomly disabling 10% of neurons.\n",
        "        self.fc2 = nn.Linear(128, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, padding=1, stride=1)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, padding=1, stride=1)\n",
        "        x = x.view(-1, 32 * 6 * 6)     #Flattening\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.softmax(self.fc3(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.910851Z",
          "iopub.execute_input": "2024-06-19T18:09:14.911151Z",
          "iopub.status.idle": "2024-06-19T18:09:14.920461Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.911114Z",
          "shell.execute_reply": "2024-06-19T18:09:14.919662Z"
        },
        "trusted": true,
        "id": "8QNxPqj5MoEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = model_CNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:14.921407Z",
          "iopub.execute_input": "2024-06-19T18:09:14.921663Z",
          "iopub.status.idle": "2024-06-19T18:09:15.167316Z",
          "shell.execute_reply.started": "2024-06-19T18:09:14.921641Z",
          "shell.execute_reply": "2024-06-19T18:09:15.166390Z"
        },
        "trusted": true,
        "id": "6YhQ7PnHMoEJ",
        "outputId": "acb51820-511d-4db9-ec13-66c542ec8342"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "model_CNN(\n  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (fc1): Linear(in_features=1152, out_features=128, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (fc2): Linear(in_features=128, out_features=32, bias=True)\n  (fc3): Linear(in_features=32, out_features=3, bias=True)\n)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.float().to(device), y.long().to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.float().to(device), y.long().to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:35:44.013603Z",
          "iopub.execute_input": "2024-06-19T18:35:44.014011Z",
          "iopub.status.idle": "2024-06-19T18:35:44.024356Z",
          "shell.execute_reply.started": "2024-06-19T18:35:44.013974Z",
          "shell.execute_reply": "2024-06-19T18:35:44.023419Z"
        },
        "trusted": true,
        "id": "4BoaSvuRMoEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model"
      ],
      "metadata": {
        "id": "TsnJ8OKHMoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    test_loop(test_loader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:51:35.267288Z",
          "iopub.execute_input": "2024-06-19T18:51:35.267671Z",
          "iopub.status.idle": "2024-06-19T18:51:44.207429Z",
          "shell.execute_reply.started": "2024-06-19T18:51:35.267639Z",
          "shell.execute_reply": "2024-06-19T18:51:44.206522Z"
        },
        "trusted": true,
        "id": "umyCWRZSMoEK",
        "outputId": "18ee7fe4-8736-4e91-a0bc-110d395bb652"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1\n-------------------------------\nloss: 0.990870  [   16/ 1921]\nloss: 0.676489  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698645 \n\nEpoch 2\n-------------------------------\nloss: 0.738949  [   16/ 1921]\nloss: 0.676108  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698651 \n\nEpoch 3\n-------------------------------\nloss: 0.614132  [   16/ 1921]\nloss: 0.676477  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698649 \n\nEpoch 4\n-------------------------------\nloss: 0.614171  [   16/ 1921]\nloss: 0.739216  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698644 \n\nEpoch 5\n-------------------------------\nloss: 0.552140  [   16/ 1921]\nloss: 0.676469  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698647 \n\nEpoch 6\n-------------------------------\nloss: 0.614059  [   16/ 1921]\nloss: 0.676476  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698650 \n\nEpoch 7\n-------------------------------\nloss: 0.551453  [   16/ 1921]\nloss: 0.676447  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698672 \n\nEpoch 8\n-------------------------------\nloss: 0.738938  [   16/ 1921]\nloss: 0.613952  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698682 \n\nEpoch 9\n-------------------------------\nloss: 0.677929  [   16/ 1921]\nloss: 0.801407  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698680 \n\nEpoch 10\n-------------------------------\nloss: 0.676451  [   16/ 1921]\nloss: 0.613946  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698685 \n\nEpoch 11\n-------------------------------\nloss: 0.675065  [   16/ 1921]\nloss: 0.551527  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698688 \n\nEpoch 12\n-------------------------------\nloss: 0.676448  [   16/ 1921]\nloss: 0.676445  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698706 \n\nEpoch 13\n-------------------------------\nloss: 0.551446  [   16/ 1921]\nloss: 0.801706  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698733 \n\nEpoch 14\n-------------------------------\nloss: 0.614069  [   16/ 1921]\nloss: 0.693423  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.699112 \n\nEpoch 15\n-------------------------------\nloss: 0.738936  [   16/ 1921]\nloss: 0.676550  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698884 \n\nEpoch 16\n-------------------------------\nloss: 0.739275  [   16/ 1921]\nloss: 0.801434  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.698974 \n\nEpoch 17\n-------------------------------\nloss: 0.613952  [   16/ 1921]\nloss: 0.798325  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.699274 \n\nEpoch 18\n-------------------------------\nloss: 0.685092  [   16/ 1921]\nloss: 0.676524  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.700339 \n\nEpoch 19\n-------------------------------\nloss: 0.636579  [   16/ 1921]\nloss: 0.801441  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.699117 \n\nEpoch 20\n-------------------------------\nloss: 1.181090  [   16/ 1921]\nloss: 0.676586  [ 1616/ 1921]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.699112 \n\nDone!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "YHqL2dhOMoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output)\n",
        "\n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:24.941014Z",
          "iopub.execute_input": "2024-06-19T18:09:24.941291Z",
          "iopub.status.idle": "2024-06-19T18:09:25.021742Z",
          "shell.execute_reply.started": "2024-06-19T18:09:24.941266Z",
          "shell.execute_reply": "2024-06-19T18:09:25.021052Z"
        },
        "trusted": true,
        "id": "Hs6G_jDCMoEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = (0, 1, 2)\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "cmd = ConfusionMatrixDisplay(cf_matrix)\n",
        "cmd.plot()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:25.022701Z",
          "iopub.execute_input": "2024-06-19T18:09:25.022937Z",
          "iopub.status.idle": "2024-06-19T18:09:25.453604Z",
          "shell.execute_reply.started": "2024-06-19T18:09:25.022915Z",
          "shell.execute_reply": "2024-06-19T18:09:25.452657Z"
        },
        "trusted": true,
        "id": "hbp8Vx7aMoEK",
        "outputId": "083b7943-3d88-4a18-8973-4de2d0adcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Imbalance in Dataset"
      ],
      "metadata": {
        "id": "ky7oE-8vMoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.countplot(df, x = \"Labels\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:25.454831Z",
          "iopub.execute_input": "2024-06-19T18:09:25.455246Z",
          "iopub.status.idle": "2024-06-19T18:09:25.745667Z",
          "shell.execute_reply.started": "2024-06-19T18:09:25.455208Z",
          "shell.execute_reply": "2024-06-19T18:09:25.744778Z"
        },
        "trusted": true,
        "id": "2H6q57YlMoEK",
        "outputId": "bd6c2435-4528-4bd3-bcdf-ce1694dc1787"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Axes: xlabel='Labels', ylabel='count'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Labels\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:09:25.746957Z",
          "iopub.execute_input": "2024-06-19T18:09:25.747395Z",
          "iopub.status.idle": "2024-06-19T18:09:25.756766Z",
          "shell.execute_reply.started": "2024-06-19T18:09:25.747360Z",
          "shell.execute_reply": "2024-06-19T18:09:25.755894Z"
        },
        "trusted": true,
        "id": "40xWmwd6MoEL",
        "outputId": "06d52d01-cdf4-41ef-803d-eb56cb454db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Labels\n2    2046\n1     187\n0     169\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state = 42)\n",
        "reduced_X_res, Y_res = ros.fit_resample(reduced_X, Y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:19:02.322406Z",
          "iopub.execute_input": "2024-06-19T18:19:02.322789Z",
          "iopub.status.idle": "2024-06-19T18:19:02.332838Z",
          "shell.execute_reply.started": "2024-06-19T18:19:02.322759Z",
          "shell.execute_reply": "2024-06-19T18:19:02.331702Z"
        },
        "trusted": true,
        "id": "L7bZ5Cg_MoEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_X_res.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:19:10.952335Z",
          "iopub.execute_input": "2024-06-19T18:19:10.952721Z",
          "iopub.status.idle": "2024-06-19T18:19:10.959158Z",
          "shell.execute_reply.started": "2024-06-19T18:19:10.952690Z",
          "shell.execute_reply": "2024-06-19T18:19:10.958130Z"
        },
        "trusted": true,
        "id": "d8esOzECMoEL",
        "outputId": "09a50c6f-5e72-4f90-a864-797767f4427b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 58,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6138, 16)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_res.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:19:26.518838Z",
          "iopub.execute_input": "2024-06-19T18:19:26.519205Z",
          "iopub.status.idle": "2024-06-19T18:19:26.525112Z",
          "shell.execute_reply.started": "2024-06-19T18:19:26.519175Z",
          "shell.execute_reply": "2024-06-19T18:19:26.524239Z"
        },
        "trusted": true,
        "id": "UgPaHT9eMoEL",
        "outputId": "8997754d-2465-4c74-af5f-d333689784ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 60,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6138,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_X_res = reduced_X_res.reshape(6138, 4, 4)\n",
        "img_X_res.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:21:20.150695Z",
          "iopub.execute_input": "2024-06-19T18:21:20.151058Z",
          "iopub.status.idle": "2024-06-19T18:21:20.157824Z",
          "shell.execute_reply.started": "2024-06-19T18:21:20.151027Z",
          "shell.execute_reply": "2024-06-19T18:21:20.156649Z"
        },
        "trusted": true,
        "id": "c98VsoMWMoEL",
        "outputId": "847d1854-c9da-490b-c3de-b1028e9d732d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 63,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(6138, 4, 4)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(Y_res)):\n",
        "    img_X_res[i] = ((img_X_res[i] - img_X_res[i].min()) / (img_X_res[i].max() - img_X_res[i].min()) * 255).astype(np.uint8)\n",
        "print(img_X_res)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:23:01.361690Z",
          "iopub.execute_input": "2024-06-19T18:23:01.362386Z",
          "iopub.status.idle": "2024-06-19T18:23:01.491480Z",
          "shell.execute_reply.started": "2024-06-19T18:23:01.362351Z",
          "shell.execute_reply": "2024-06-19T18:23:01.490559Z"
        },
        "trusted": true,
        "id": "C1Eijy3yMoEL",
        "outputId": "05c525e3-b1e9-4975-b5ba-a62305a5642a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[[212.   0. 212. 217.]\n  [224. 227. 219. 226.]\n  [199. 200. 251. 255.]\n  [253. 253. 247. 248.]]\n\n [[207.   0. 193. 199.]\n  [210. 208. 200. 207.]\n  [168. 171. 249. 255.]\n  [252. 252. 245. 243.]]\n\n [[ 83.  88.  67.  94.]\n  [129. 107.  95. 100.]\n  [  0.  12. 238. 255.]\n  [247. 247. 222. 224.]]\n\n ...\n\n [[202.   0. 208. 211.]\n  [206. 213. 214. 248.]\n  [191. 183. 255. 251.]\n  [254. 253. 250. 250.]]\n\n [[116. 218. 113. 171.]\n  [175. 220.  54. 255.]\n  [ 22.   0. 205. 242.]\n  [226. 225. 213. 215.]]\n\n [[131. 255.   0.  44.]\n  [203. 139. 146. 163.]\n  [127. 143. 233. 232.]\n  [231. 232. 214. 216.]]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_X_res_tensor = torch.from_numpy(img_X_res).unsqueeze(1) #For adding a channel dimension which is 1 here\n",
        "Y_res_tensor = torch.from_numpy(Y_res)\n",
        "print(img_X_res_tensor.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:27:59.624346Z",
          "iopub.execute_input": "2024-06-19T18:27:59.625110Z",
          "iopub.status.idle": "2024-06-19T18:27:59.630557Z",
          "shell.execute_reply.started": "2024-06-19T18:27:59.625077Z",
          "shell.execute_reply": "2024-06-19T18:27:59.629612Z"
        },
        "trusted": true,
        "id": "ixvO01YxMoEM",
        "outputId": "0fd47e66-876d-4f87-da13-23a3b5883973"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([6138, 1, 4, 4])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_dataset = CustomImageDataset(img_X_res_tensor, Y_res_tensor, transform=transform)\n",
        "res_train_size = int(0.8 * len(res_dataset))\n",
        "res_test_size = len(res_dataset) - res_train_size\n",
        "res_train_dataset, res_test_dataset = random_split(res_dataset, [res_train_size, res_test_size])\n",
        "print(res_train_dataset.__len__())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:31:36.726759Z",
          "iopub.execute_input": "2024-06-19T18:31:36.727152Z",
          "iopub.status.idle": "2024-06-19T18:31:36.733813Z",
          "shell.execute_reply.started": "2024-06-19T18:31:36.727109Z",
          "shell.execute_reply": "2024-06-19T18:31:36.732792Z"
        },
        "trusted": true,
        "id": "BAtRkekeMoEM",
        "outputId": "6517a774-e660-4a9c-a938-1b8bf4643c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "4910\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(Y_res)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:55:06.582023Z",
          "iopub.execute_input": "2024-06-19T18:55:06.582876Z",
          "iopub.status.idle": "2024-06-19T18:55:06.590549Z",
          "shell.execute_reply.started": "2024-06-19T18:55:06.582842Z",
          "shell.execute_reply": "2024-06-19T18:55:06.589553Z"
        },
        "trusted": true,
        "id": "YQZVj17hMoEM",
        "outputId": "b36fc520-cca2-4620-961a-4ad787777f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 75,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Counter({2: 2046, 1: 2046, 0: 2046})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "res_train_loader = DataLoader(res_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "res_test_loader = DataLoader(res_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:33:10.896602Z",
          "iopub.execute_input": "2024-06-19T18:33:10.896977Z",
          "iopub.status.idle": "2024-06-19T18:33:10.902004Z",
          "shell.execute_reply.started": "2024-06-19T18:33:10.896946Z",
          "shell.execute_reply": "2024-06-19T18:33:10.901085Z"
        },
        "trusted": true,
        "id": "uxWksJ1FMoEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model after Resampling"
      ],
      "metadata": {
        "id": "4FQWQsG8MoEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)\n",
        "\n",
        "epochs = 1000\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(res_train_loader, model, loss_fn, optimizer)\n",
        "    test_loop(res_test_loader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T18:55:42.492637Z",
          "iopub.execute_input": "2024-06-19T18:55:42.492999Z",
          "iopub.status.idle": "2024-06-19T19:14:18.340371Z",
          "shell.execute_reply.started": "2024-06-19T18:55:42.492968Z",
          "shell.execute_reply": "2024-06-19T19:14:18.339143Z"
        },
        "trusted": true,
        "id": "EMdZC0_DMoEM",
        "outputId": "46728eef-9619-4419-d5a7-a195200ebc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1\n-------------------------------\nloss: 1.176094  [   16/ 4910]\nloss: 0.968659  [ 1616/ 4910]\nloss: 0.860654  [ 3216/ 4910]\nloss: 0.865959  [ 4816/ 4910]\nTest Error: \n Accuracy: 70.8%, Avg loss: 0.826916 \n\nEpoch 2\n-------------------------------\nloss: 0.861464  [   16/ 4910]\nloss: 0.872167  [ 1616/ 4910]\nloss: 0.980175  [ 3216/ 4910]\nloss: 0.821216  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.4%, Avg loss: 0.814308 \n\nEpoch 3\n-------------------------------\nloss: 0.892984  [   16/ 4910]\nloss: 0.880327  [ 1616/ 4910]\nloss: 0.816517  [ 3216/ 4910]\nloss: 0.697603  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.4%, Avg loss: 0.809907 \n\nEpoch 4\n-------------------------------\nloss: 0.946198  [   16/ 4910]\nloss: 0.763399  [ 1616/ 4910]\nloss: 0.728595  [ 3216/ 4910]\nloss: 0.862540  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.7%, Avg loss: 0.817397 \n\nEpoch 5\n-------------------------------\nloss: 0.754432  [   16/ 4910]\nloss: 0.763350  [ 1616/ 4910]\nloss: 0.741251  [ 3216/ 4910]\nloss: 0.910745  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.6%, Avg loss: 0.808250 \n\nEpoch 6\n-------------------------------\nloss: 0.761052  [   16/ 4910]\nloss: 0.791555  [ 1616/ 4910]\nloss: 0.805400  [ 3216/ 4910]\nloss: 0.873526  [ 4816/ 4910]\nTest Error: \n Accuracy: 68.9%, Avg loss: 0.853196 \n\nEpoch 7\n-------------------------------\nloss: 0.905821  [   16/ 4910]\nloss: 0.739000  [ 1616/ 4910]\nloss: 1.017220  [ 3216/ 4910]\nloss: 0.773085  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.3%, Avg loss: 0.809386 \n\nEpoch 8\n-------------------------------\nloss: 0.728435  [   16/ 4910]\nloss: 0.777264  [ 1616/ 4910]\nloss: 0.611635  [ 3216/ 4910]\nloss: 0.702249  [ 4816/ 4910]\nTest Error: \n Accuracy: 74.3%, Avg loss: 0.807932 \n\nEpoch 9\n-------------------------------\nloss: 0.871492  [   16/ 4910]\nloss: 0.884296  [ 1616/ 4910]\nloss: 0.879140  [ 3216/ 4910]\nloss: 0.812642  [ 4816/ 4910]\nTest Error: \n Accuracy: 75.4%, Avg loss: 0.797395 \n\nEpoch 10\n-------------------------------\nloss: 0.695362  [   16/ 4910]\nloss: 0.747742  [ 1616/ 4910]\nloss: 1.013825  [ 3216/ 4910]\nloss: 0.586379  [ 4816/ 4910]\nTest Error: \n Accuracy: 74.3%, Avg loss: 0.807677 \n\nEpoch 11\n-------------------------------\nloss: 0.827606  [   16/ 4910]\nloss: 0.887581  [ 1616/ 4910]\nloss: 0.810122  [ 3216/ 4910]\nloss: 0.678386  [ 4816/ 4910]\nTest Error: \n Accuracy: 75.1%, Avg loss: 0.800965 \n\nEpoch 12\n-------------------------------\nloss: 0.585218  [   16/ 4910]\nloss: 0.748161  [ 1616/ 4910]\nloss: 0.763601  [ 3216/ 4910]\nloss: 0.803372  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.4%, Avg loss: 0.811925 \n\nEpoch 13\n-------------------------------\nloss: 0.860570  [   16/ 4910]\nloss: 0.856597  [ 1616/ 4910]\nloss: 0.774152  [ 3216/ 4910]\nloss: 0.708874  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.1%, Avg loss: 0.795551 \n\nEpoch 14\n-------------------------------\nloss: 0.780375  [   16/ 4910]\nloss: 0.923057  [ 1616/ 4910]\nloss: 0.880522  [ 3216/ 4910]\nloss: 0.701291  [ 4816/ 4910]\nTest Error: \n Accuracy: 72.1%, Avg loss: 0.823374 \n\nEpoch 15\n-------------------------------\nloss: 0.742333  [   16/ 4910]\nloss: 0.626622  [ 1616/ 4910]\nloss: 0.620770  [ 3216/ 4910]\nloss: 1.064605  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.1%, Avg loss: 0.788561 \n\nEpoch 16\n-------------------------------\nloss: 1.062872  [   16/ 4910]\nloss: 0.813488  [ 1616/ 4910]\nloss: 0.805797  [ 3216/ 4910]\nloss: 0.946382  [ 4816/ 4910]\nTest Error: \n Accuracy: 73.5%, Avg loss: 0.805895 \n\nEpoch 17\n-------------------------------\nloss: 0.837029  [   16/ 4910]\nloss: 0.644425  [ 1616/ 4910]\nloss: 0.684366  [ 3216/ 4910]\nloss: 0.769601  [ 4816/ 4910]\nTest Error: \n Accuracy: 75.2%, Avg loss: 0.795892 \n\nEpoch 18\n-------------------------------\nloss: 0.737882  [   16/ 4910]\nloss: 0.744749  [ 1616/ 4910]\nloss: 0.853772  [ 3216/ 4910]\nloss: 0.822449  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.6%, Avg loss: 0.784504 \n\nEpoch 19\n-------------------------------\nloss: 0.897905  [   16/ 4910]\nloss: 0.847604  [ 1616/ 4910]\nloss: 0.745669  [ 3216/ 4910]\nloss: 0.969580  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.7%, Avg loss: 0.786921 \n\nEpoch 20\n-------------------------------\nloss: 0.626724  [   16/ 4910]\nloss: 0.923083  [ 1616/ 4910]\nloss: 0.705945  [ 3216/ 4910]\nloss: 0.702184  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.8%, Avg loss: 0.786308 \n\nEpoch 21\n-------------------------------\nloss: 0.868018  [   16/ 4910]\nloss: 0.820746  [ 1616/ 4910]\nloss: 0.695863  [ 3216/ 4910]\nloss: 0.779083  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.9%, Avg loss: 0.784015 \n\nEpoch 22\n-------------------------------\nloss: 0.907032  [   16/ 4910]\nloss: 0.656444  [ 1616/ 4910]\nloss: 0.825011  [ 3216/ 4910]\nloss: 0.902278  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.9%, Avg loss: 0.785345 \n\nEpoch 23\n-------------------------------\nloss: 0.773431  [   16/ 4910]\nloss: 0.693052  [ 1616/ 4910]\nloss: 0.808491  [ 3216/ 4910]\nloss: 0.747268  [ 4816/ 4910]\nTest Error: \n Accuracy: 77.9%, Avg loss: 0.777648 \n\nEpoch 24\n-------------------------------\nloss: 0.766087  [   16/ 4910]\nloss: 0.894933  [ 1616/ 4910]\nloss: 0.798750  [ 3216/ 4910]\nloss: 0.729232  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.1%, Avg loss: 0.787738 \n\nEpoch 25\n-------------------------------\nloss: 0.648958  [   16/ 4910]\nloss: 0.818519  [ 1616/ 4910]\nloss: 0.706182  [ 3216/ 4910]\nloss: 0.615109  [ 4816/ 4910]\nTest Error: \n Accuracy: 77.1%, Avg loss: 0.780091 \n\nEpoch 26\n-------------------------------\nloss: 0.840850  [   16/ 4910]\nloss: 0.793693  [ 1616/ 4910]\nloss: 0.704086  [ 3216/ 4910]\nloss: 1.006158  [ 4816/ 4910]\nTest Error: \n Accuracy: 78.2%, Avg loss: 0.782143 \n\nEpoch 27\n-------------------------------\nloss: 0.735436  [   16/ 4910]\nloss: 0.881433  [ 1616/ 4910]\nloss: 0.677626  [ 3216/ 4910]\nloss: 0.817429  [ 4816/ 4910]\nTest Error: \n Accuracy: 77.8%, Avg loss: 0.770936 \n\nEpoch 28\n-------------------------------\nloss: 0.881970  [   16/ 4910]\nloss: 0.740889  [ 1616/ 4910]\nloss: 0.719574  [ 3216/ 4910]\nloss: 0.872988  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.1%, Avg loss: 0.768459 \n\nEpoch 29\n-------------------------------\nloss: 0.757642  [   16/ 4910]\nloss: 0.787109  [ 1616/ 4910]\nloss: 0.796368  [ 3216/ 4910]\nloss: 0.831622  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.3%, Avg loss: 0.778746 \n\nEpoch 30\n-------------------------------\nloss: 0.737425  [   16/ 4910]\nloss: 0.634995  [ 1616/ 4910]\nloss: 0.793055  [ 3216/ 4910]\nloss: 0.681105  [ 4816/ 4910]\nTest Error: \n Accuracy: 76.5%, Avg loss: 0.792239 \n\nEpoch 31\n-------------------------------\nloss: 0.671439  [   16/ 4910]\nloss: 0.860047  [ 1616/ 4910]\nloss: 0.791477  [ 3216/ 4910]\nloss: 0.797826  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.0%, Avg loss: 0.768262 \n\nEpoch 32\n-------------------------------\nloss: 0.890972  [   16/ 4910]\nloss: 0.732254  [ 1616/ 4910]\nloss: 0.634240  [ 3216/ 4910]\nloss: 0.638981  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.0%, Avg loss: 0.763967 \n\nEpoch 33\n-------------------------------\nloss: 0.726731  [   16/ 4910]\nloss: 0.865281  [ 1616/ 4910]\nloss: 0.787796  [ 3216/ 4910]\nloss: 0.912645  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.9%, Avg loss: 0.756965 \n\nEpoch 34\n-------------------------------\nloss: 0.743650  [   16/ 4910]\nloss: 0.656037  [ 1616/ 4910]\nloss: 0.757728  [ 3216/ 4910]\nloss: 0.742336  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.0%, Avg loss: 0.759638 \n\nEpoch 35\n-------------------------------\nloss: 0.690536  [   16/ 4910]\nloss: 0.617201  [ 1616/ 4910]\nloss: 0.693922  [ 3216/ 4910]\nloss: 0.739881  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.6%, Avg loss: 0.757014 \n\nEpoch 36\n-------------------------------\nloss: 0.625355  [   16/ 4910]\nloss: 0.731838  [ 1616/ 4910]\nloss: 0.675669  [ 3216/ 4910]\nloss: 0.742883  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.5%, Avg loss: 0.751793 \n\nEpoch 37\n-------------------------------\nloss: 0.668760  [   16/ 4910]\nloss: 0.738965  [ 1616/ 4910]\nloss: 0.665730  [ 3216/ 4910]\nloss: 0.635312  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.6%, Avg loss: 0.757351 \n\nEpoch 38\n-------------------------------\nloss: 0.725921  [   16/ 4910]\nloss: 0.689594  [ 1616/ 4910]\nloss: 0.882363  [ 3216/ 4910]\nloss: 0.679147  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.6%, Avg loss: 0.751531 \n\nEpoch 39\n-------------------------------\nloss: 0.763831  [   16/ 4910]\nloss: 0.776089  [ 1616/ 4910]\nloss: 0.838228  [ 3216/ 4910]\nloss: 0.880100  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.9%, Avg loss: 0.749228 \n\nEpoch 40\n-------------------------------\nloss: 0.832679  [   16/ 4910]\nloss: 0.833390  [ 1616/ 4910]\nloss: 0.807634  [ 3216/ 4910]\nloss: 0.803522  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.3%, Avg loss: 0.758242 \n\nEpoch 41\n-------------------------------\nloss: 0.765750  [   16/ 4910]\nloss: 1.010306  [ 1616/ 4910]\nloss: 0.705637  [ 3216/ 4910]\nloss: 0.690112  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.1%, Avg loss: 0.772989 \n\nEpoch 42\n-------------------------------\nloss: 0.825992  [   16/ 4910]\nloss: 0.811881  [ 1616/ 4910]\nloss: 0.643799  [ 3216/ 4910]\nloss: 0.728712  [ 4816/ 4910]\nTest Error: \n Accuracy: 77.6%, Avg loss: 0.773389 \n\nEpoch 43\n-------------------------------\nloss: 0.969359  [   16/ 4910]\nloss: 0.690514  [ 1616/ 4910]\nloss: 0.618307  [ 3216/ 4910]\nloss: 0.627149  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.4%, Avg loss: 0.755028 \n\nEpoch 44\n-------------------------------\nloss: 0.670026  [   16/ 4910]\nloss: 0.657319  [ 1616/ 4910]\nloss: 0.694679  [ 3216/ 4910]\nloss: 0.683547  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.1%, Avg loss: 0.747911 \n\nEpoch 45\n-------------------------------\nloss: 0.768347  [   16/ 4910]\nloss: 0.819911  [ 1616/ 4910]\nloss: 0.853872  [ 3216/ 4910]\nloss: 0.622286  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.6%, Avg loss: 0.758906 \n\nEpoch 46\n-------------------------------\nloss: 0.740931  [   16/ 4910]\nloss: 0.851846  [ 1616/ 4910]\nloss: 0.655278  [ 3216/ 4910]\nloss: 0.641087  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.2%, Avg loss: 0.760456 \n\nEpoch 47\n-------------------------------\nloss: 0.678151  [   16/ 4910]\nloss: 0.686862  [ 1616/ 4910]\nloss: 0.683451  [ 3216/ 4910]\nloss: 0.654963  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.5%, Avg loss: 0.742483 \n\nEpoch 48\n-------------------------------\nloss: 0.697360  [   16/ 4910]\nloss: 0.813365  [ 1616/ 4910]\nloss: 0.850941  [ 3216/ 4910]\nloss: 0.741413  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.8%, Avg loss: 0.739149 \n\nEpoch 49\n-------------------------------\nloss: 0.743950  [   16/ 4910]\nloss: 0.777533  [ 1616/ 4910]\nloss: 0.680222  [ 3216/ 4910]\nloss: 0.690436  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.9%, Avg loss: 0.743789 \n\nEpoch 50\n-------------------------------\nloss: 0.726545  [   16/ 4910]\nloss: 0.772476  [ 1616/ 4910]\nloss: 0.576960  [ 3216/ 4910]\nloss: 0.715074  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.6%, Avg loss: 0.747303 \n\nEpoch 51\n-------------------------------\nloss: 0.797539  [   16/ 4910]\nloss: 0.603710  [ 1616/ 4910]\nloss: 0.868022  [ 3216/ 4910]\nloss: 0.683434  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.3%, Avg loss: 0.756025 \n\nEpoch 52\n-------------------------------\nloss: 0.716306  [   16/ 4910]\nloss: 0.673401  [ 1616/ 4910]\nloss: 0.786771  [ 3216/ 4910]\nloss: 0.807814  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.7%, Avg loss: 0.741179 \n\nEpoch 53\n-------------------------------\nloss: 0.746793  [   16/ 4910]\nloss: 0.721047  [ 1616/ 4910]\nloss: 0.677640  [ 3216/ 4910]\nloss: 0.893312  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.2%, Avg loss: 0.744199 \n\nEpoch 54\n-------------------------------\nloss: 0.649103  [   16/ 4910]\nloss: 0.707367  [ 1616/ 4910]\nloss: 0.730857  [ 3216/ 4910]\nloss: 0.772571  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.6%, Avg loss: 0.758957 \n\nEpoch 55\n-------------------------------\nloss: 0.687737  [   16/ 4910]\nloss: 0.763201  [ 1616/ 4910]\nloss: 0.827114  [ 3216/ 4910]\nloss: 0.715351  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.6%, Avg loss: 0.735967 \n\nEpoch 56\n-------------------------------\nloss: 0.647407  [   16/ 4910]\nloss: 0.664935  [ 1616/ 4910]\nloss: 0.866540  [ 3216/ 4910]\nloss: 0.877643  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.1%, Avg loss: 0.730597 \n\nEpoch 57\n-------------------------------\nloss: 0.745760  [   16/ 4910]\nloss: 0.744396  [ 1616/ 4910]\nloss: 0.801988  [ 3216/ 4910]\nloss: 0.814125  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.9%, Avg loss: 0.746462 \n\nEpoch 58\n-------------------------------\nloss: 0.696747  [   16/ 4910]\nloss: 0.786961  [ 1616/ 4910]\nloss: 0.864316  [ 3216/ 4910]\nloss: 0.739693  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.8%, Avg loss: 0.738429 \n\nEpoch 59\n-------------------------------\nloss: 0.557235  [   16/ 4910]\nloss: 0.619804  [ 1616/ 4910]\nloss: 0.679723  [ 3216/ 4910]\nloss: 0.690107  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.9%, Avg loss: 0.737465 \n\nEpoch 60\n-------------------------------\nloss: 0.617595  [   16/ 4910]\nloss: 0.623460  [ 1616/ 4910]\nloss: 0.730015  [ 3216/ 4910]\nloss: 0.565588  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.9%, Avg loss: 0.738877 \n\nEpoch 61\n-------------------------------\nloss: 0.756222  [   16/ 4910]\nloss: 0.677751  [ 1616/ 4910]\nloss: 0.650269  [ 3216/ 4910]\nloss: 0.707264  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.7%, Avg loss: 0.733034 \n\nEpoch 62\n-------------------------------\nloss: 0.553459  [   16/ 4910]\nloss: 0.853645  [ 1616/ 4910]\nloss: 0.766222  [ 3216/ 4910]\nloss: 0.664162  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.7%, Avg loss: 0.732793 \n\nEpoch 63\n-------------------------------\nloss: 0.754542  [   16/ 4910]\nloss: 0.774323  [ 1616/ 4910]\nloss: 1.043685  [ 3216/ 4910]\nloss: 0.912067  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.0%, Avg loss: 0.732673 \n\nEpoch 64\n-------------------------------\nloss: 0.670642  [   16/ 4910]\nloss: 0.854977  [ 1616/ 4910]\nloss: 0.883299  [ 3216/ 4910]\nloss: 0.720484  [ 4816/ 4910]\nTest Error: \n Accuracy: 80.2%, Avg loss: 0.745662 \n\nEpoch 65\n-------------------------------\nloss: 0.821914  [   16/ 4910]\nloss: 0.629252  [ 1616/ 4910]\nloss: 0.681632  [ 3216/ 4910]\nloss: 0.677659  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.4%, Avg loss: 0.732161 \n\nEpoch 66\n-------------------------------\nloss: 0.700081  [   16/ 4910]\nloss: 0.728834  [ 1616/ 4910]\nloss: 0.801082  [ 3216/ 4910]\nloss: 0.683254  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.7%, Avg loss: 0.726767 \n\nEpoch 67\n-------------------------------\nloss: 0.684624  [   16/ 4910]\nloss: 0.771647  [ 1616/ 4910]\nloss: 0.927864  [ 3216/ 4910]\nloss: 0.764024  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.0%, Avg loss: 0.734534 \n\nEpoch 68\n-------------------------------\nloss: 0.749994  [   16/ 4910]\nloss: 0.624220  [ 1616/ 4910]\nloss: 0.731573  [ 3216/ 4910]\nloss: 0.643518  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.2%, Avg loss: 0.754065 \n\nEpoch 69\n-------------------------------\nloss: 0.617932  [   16/ 4910]\nloss: 0.770331  [ 1616/ 4910]\nloss: 0.715750  [ 3216/ 4910]\nloss: 0.621605  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.9%, Avg loss: 0.724298 \n\nEpoch 70\n-------------------------------\nloss: 0.677458  [   16/ 4910]\nloss: 0.731918  [ 1616/ 4910]\nloss: 0.644253  [ 3216/ 4910]\nloss: 0.747350  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.8%, Avg loss: 0.718464 \n\nEpoch 71\n-------------------------------\nloss: 0.619296  [   16/ 4910]\nloss: 0.626624  [ 1616/ 4910]\nloss: 0.871805  [ 3216/ 4910]\nloss: 0.761447  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.4%, Avg loss: 0.717271 \n\nEpoch 72\n-------------------------------\nloss: 0.704026  [   16/ 4910]\nloss: 0.620481  [ 1616/ 4910]\nloss: 0.773849  [ 3216/ 4910]\nloss: 0.734895  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.8%, Avg loss: 0.723449 \n\nEpoch 73\n-------------------------------\nloss: 0.637684  [   16/ 4910]\nloss: 0.864472  [ 1616/ 4910]\nloss: 0.559873  [ 3216/ 4910]\nloss: 0.674213  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.4%, Avg loss: 0.741861 \n\nEpoch 74\n-------------------------------\nloss: 0.772741  [   16/ 4910]\nloss: 0.609472  [ 1616/ 4910]\nloss: 0.611311  [ 3216/ 4910]\nloss: 0.734799  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.3%, Avg loss: 0.730423 \n\nEpoch 75\n-------------------------------\nloss: 0.689413  [   16/ 4910]\nloss: 0.739698  [ 1616/ 4910]\nloss: 0.801507  [ 3216/ 4910]\nloss: 0.744189  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.6%, Avg loss: 0.723029 \n\nEpoch 76\n-------------------------------\nloss: 0.732057  [   16/ 4910]\nloss: 0.742917  [ 1616/ 4910]\nloss: 0.825837  [ 3216/ 4910]\nloss: 0.774716  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.7%, Avg loss: 0.723496 \n\nEpoch 77\n-------------------------------\nloss: 0.701559  [   16/ 4910]\nloss: 0.671322  [ 1616/ 4910]\nloss: 0.618254  [ 3216/ 4910]\nloss: 0.740253  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.7%, Avg loss: 0.725419 \n\nEpoch 78\n-------------------------------\nloss: 0.682836  [   16/ 4910]\nloss: 0.948725  [ 1616/ 4910]\nloss: 0.744398  [ 3216/ 4910]\nloss: 0.678185  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.4%, Avg loss: 0.723131 \n\nEpoch 79\n-------------------------------\nloss: 0.762581  [   16/ 4910]\nloss: 0.685854  [ 1616/ 4910]\nloss: 0.701964  [ 3216/ 4910]\nloss: 0.567687  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.6%, Avg loss: 0.725010 \n\nEpoch 80\n-------------------------------\nloss: 0.762629  [   16/ 4910]\nloss: 0.706519  [ 1616/ 4910]\nloss: 0.742568  [ 3216/ 4910]\nloss: 0.615849  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.6%, Avg loss: 0.723109 \n\nEpoch 81\n-------------------------------\nloss: 0.552079  [   16/ 4910]\nloss: 0.614203  [ 1616/ 4910]\nloss: 0.802827  [ 3216/ 4910]\nloss: 0.681123  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.5%, Avg loss: 0.728589 \n\nEpoch 82\n-------------------------------\nloss: 0.740026  [   16/ 4910]\nloss: 0.738726  [ 1616/ 4910]\nloss: 0.735435  [ 3216/ 4910]\nloss: 0.619017  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.0%, Avg loss: 0.722152 \n\nEpoch 83\n-------------------------------\nloss: 0.616736  [   16/ 4910]\nloss: 0.679660  [ 1616/ 4910]\nloss: 0.617601  [ 3216/ 4910]\nloss: 0.799784  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.0%, Avg loss: 0.716857 \n\nEpoch 84\n-------------------------------\nloss: 0.689862  [   16/ 4910]\nloss: 0.756326  [ 1616/ 4910]\nloss: 0.677274  [ 3216/ 4910]\nloss: 0.799803  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.7%, Avg loss: 0.721649 \n\nEpoch 85\n-------------------------------\nloss: 0.552269  [   16/ 4910]\nloss: 0.628095  [ 1616/ 4910]\nloss: 0.801994  [ 3216/ 4910]\nloss: 0.802961  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.2%, Avg loss: 0.719155 \n\nEpoch 86\n-------------------------------\nloss: 0.649677  [   16/ 4910]\nloss: 0.866367  [ 1616/ 4910]\nloss: 0.743410  [ 3216/ 4910]\nloss: 0.584165  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.6%, Avg loss: 0.715118 \n\nEpoch 87\n-------------------------------\nloss: 0.678429  [   16/ 4910]\nloss: 0.557891  [ 1616/ 4910]\nloss: 0.659158  [ 3216/ 4910]\nloss: 0.781283  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.7%, Avg loss: 0.712293 \n\nEpoch 88\n-------------------------------\nloss: 0.743107  [   16/ 4910]\nloss: 0.706274  [ 1616/ 4910]\nloss: 0.770580  [ 3216/ 4910]\nloss: 0.693882  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.6%, Avg loss: 0.720726 \n\nEpoch 89\n-------------------------------\nloss: 0.759883  [   16/ 4910]\nloss: 0.738660  [ 1616/ 4910]\nloss: 0.805412  [ 3216/ 4910]\nloss: 0.826728  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.2%, Avg loss: 0.719834 \n\nEpoch 90\n-------------------------------\nloss: 0.807921  [   16/ 4910]\nloss: 0.783074  [ 1616/ 4910]\nloss: 0.739591  [ 3216/ 4910]\nloss: 0.615392  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.6%, Avg loss: 0.721842 \n\nEpoch 91\n-------------------------------\nloss: 0.926822  [   16/ 4910]\nloss: 0.671546  [ 1616/ 4910]\nloss: 0.618027  [ 3216/ 4910]\nloss: 0.693258  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.1%, Avg loss: 0.713764 \n\nEpoch 92\n-------------------------------\nloss: 0.748536  [   16/ 4910]\nloss: 0.739088  [ 1616/ 4910]\nloss: 0.742202  [ 3216/ 4910]\nloss: 0.566002  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.9%, Avg loss: 0.713336 \n\nEpoch 93\n-------------------------------\nloss: 0.770950  [   16/ 4910]\nloss: 0.765407  [ 1616/ 4910]\nloss: 0.654349  [ 3216/ 4910]\nloss: 0.678749  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.710349 \n\nEpoch 94\n-------------------------------\nloss: 0.729570  [   16/ 4910]\nloss: 0.632665  [ 1616/ 4910]\nloss: 0.800069  [ 3216/ 4910]\nloss: 0.615583  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.0%, Avg loss: 0.730104 \n\nEpoch 95\n-------------------------------\nloss: 0.615698  [   16/ 4910]\nloss: 0.686524  [ 1616/ 4910]\nloss: 0.616047  [ 3216/ 4910]\nloss: 0.802716  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.3%, Avg loss: 0.719373 \n\nEpoch 96\n-------------------------------\nloss: 0.555342  [   16/ 4910]\nloss: 0.833092  [ 1616/ 4910]\nloss: 0.739463  [ 3216/ 4910]\nloss: 0.740821  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.9%, Avg loss: 0.714607 \n\nEpoch 97\n-------------------------------\nloss: 0.677805  [   16/ 4910]\nloss: 0.705060  [ 1616/ 4910]\nloss: 0.733237  [ 3216/ 4910]\nloss: 0.946639  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.3%, Avg loss: 0.711075 \n\nEpoch 98\n-------------------------------\nloss: 0.680556  [   16/ 4910]\nloss: 0.799850  [ 1616/ 4910]\nloss: 0.623404  [ 3216/ 4910]\nloss: 0.677729  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.4%, Avg loss: 0.733322 \n\nEpoch 99\n-------------------------------\nloss: 0.588524  [   16/ 4910]\nloss: 0.800678  [ 1616/ 4910]\nloss: 0.686158  [ 3216/ 4910]\nloss: 0.743902  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.707355 \n\nEpoch 100\n-------------------------------\nloss: 0.719182  [   16/ 4910]\nloss: 0.863669  [ 1616/ 4910]\nloss: 0.553342  [ 3216/ 4910]\nloss: 0.576706  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.4%, Avg loss: 0.726340 \n\nEpoch 101\n-------------------------------\nloss: 0.602531  [   16/ 4910]\nloss: 0.765106  [ 1616/ 4910]\nloss: 0.682149  [ 3216/ 4910]\nloss: 0.614952  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.2%, Avg loss: 0.710322 \n\nEpoch 102\n-------------------------------\nloss: 0.557897  [   16/ 4910]\nloss: 0.690957  [ 1616/ 4910]\nloss: 0.667080  [ 3216/ 4910]\nloss: 0.676746  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.0%, Avg loss: 0.713484 \n\nEpoch 103\n-------------------------------\nloss: 0.614997  [   16/ 4910]\nloss: 0.749265  [ 1616/ 4910]\nloss: 0.808645  [ 3216/ 4910]\nloss: 0.577997  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.706240 \n\nEpoch 104\n-------------------------------\nloss: 0.801834  [   16/ 4910]\nloss: 0.740934  [ 1616/ 4910]\nloss: 0.740155  [ 3216/ 4910]\nloss: 0.638063  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.0%, Avg loss: 0.714934 \n\nEpoch 105\n-------------------------------\nloss: 0.684986  [   16/ 4910]\nloss: 0.739751  [ 1616/ 4910]\nloss: 0.618260  [ 3216/ 4910]\nloss: 0.676761  [ 4816/ 4910]\nTest Error: \n Accuracy: 79.2%, Avg loss: 0.759320 \n\nEpoch 106\n-------------------------------\nloss: 0.618765  [   16/ 4910]\nloss: 0.636321  [ 1616/ 4910]\nloss: 0.805552  [ 3216/ 4910]\nloss: 0.676519  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.702280 \n\nEpoch 107\n-------------------------------\nloss: 0.613532  [   16/ 4910]\nloss: 0.802602  [ 1616/ 4910]\nloss: 0.668155  [ 3216/ 4910]\nloss: 0.742983  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.1%, Avg loss: 0.711058 \n\nEpoch 108\n-------------------------------\nloss: 0.739978  [   16/ 4910]\nloss: 0.790568  [ 1616/ 4910]\nloss: 0.676023  [ 3216/ 4910]\nloss: 0.808107  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.706086 \n\nEpoch 109\n-------------------------------\nloss: 0.614490  [   16/ 4910]\nloss: 0.674546  [ 1616/ 4910]\nloss: 0.673206  [ 3216/ 4910]\nloss: 0.803625  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.9%, Avg loss: 0.714626 \n\nEpoch 110\n-------------------------------\nloss: 0.693854  [   16/ 4910]\nloss: 0.686500  [ 1616/ 4910]\nloss: 0.890282  [ 3216/ 4910]\nloss: 0.739678  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.1%, Avg loss: 0.737768 \n\nEpoch 111\n-------------------------------\nloss: 0.738948  [   16/ 4910]\nloss: 0.866858  [ 1616/ 4910]\nloss: 0.741782  [ 3216/ 4910]\nloss: 0.569472  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.2%, Avg loss: 0.703245 \n\nEpoch 112\n-------------------------------\nloss: 0.614490  [   16/ 4910]\nloss: 0.563738  [ 1616/ 4910]\nloss: 0.560203  [ 3216/ 4910]\nloss: 0.676814  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.8%, Avg loss: 0.721528 \n\nEpoch 113\n-------------------------------\nloss: 0.641297  [   16/ 4910]\nloss: 0.688131  [ 1616/ 4910]\nloss: 0.617001  [ 3216/ 4910]\nloss: 0.745616  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.704197 \n\nEpoch 114\n-------------------------------\nloss: 0.821889  [   16/ 4910]\nloss: 0.678394  [ 1616/ 4910]\nloss: 0.738990  [ 3216/ 4910]\nloss: 0.678852  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.705154 \n\nEpoch 115\n-------------------------------\nloss: 0.614764  [   16/ 4910]\nloss: 0.676875  [ 1616/ 4910]\nloss: 0.633251  [ 3216/ 4910]\nloss: 0.803459  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.709491 \n\nEpoch 116\n-------------------------------\nloss: 0.592667  [   16/ 4910]\nloss: 0.801647  [ 1616/ 4910]\nloss: 0.798743  [ 3216/ 4910]\nloss: 0.768939  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.2%, Avg loss: 0.739729 \n\nEpoch 117\n-------------------------------\nloss: 0.845593  [   16/ 4910]\nloss: 0.672238  [ 1616/ 4910]\nloss: 0.680155  [ 3216/ 4910]\nloss: 0.802168  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.2%, Avg loss: 0.708745 \n\nEpoch 118\n-------------------------------\nloss: 0.803092  [   16/ 4910]\nloss: 0.565419  [ 1616/ 4910]\nloss: 0.802186  [ 3216/ 4910]\nloss: 0.681195  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.0%, Avg loss: 0.713370 \n\nEpoch 119\n-------------------------------\nloss: 0.677072  [   16/ 4910]\nloss: 0.579216  [ 1616/ 4910]\nloss: 0.614158  [ 3216/ 4910]\nloss: 0.573458  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.0%, Avg loss: 0.701159 \n\nEpoch 120\n-------------------------------\nloss: 0.631505  [   16/ 4910]\nloss: 0.614341  [ 1616/ 4910]\nloss: 0.703635  [ 3216/ 4910]\nloss: 0.555083  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.6%, Avg loss: 0.700256 \n\nEpoch 121\n-------------------------------\nloss: 0.821919  [   16/ 4910]\nloss: 0.794124  [ 1616/ 4910]\nloss: 0.802655  [ 3216/ 4910]\nloss: 0.621237  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.703753 \n\nEpoch 122\n-------------------------------\nloss: 0.552294  [   16/ 4910]\nloss: 0.683734  [ 1616/ 4910]\nloss: 0.675519  [ 3216/ 4910]\nloss: 0.680488  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.7%, Avg loss: 0.703125 \n\nEpoch 123\n-------------------------------\nloss: 0.582824  [   16/ 4910]\nloss: 0.614616  [ 1616/ 4910]\nloss: 0.676668  [ 3216/ 4910]\nloss: 0.678473  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.5%, Avg loss: 0.701083 \n\nEpoch 124\n-------------------------------\nloss: 0.738796  [   16/ 4910]\nloss: 0.680824  [ 1616/ 4910]\nloss: 0.680535  [ 3216/ 4910]\nloss: 0.717451  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.8%, Avg loss: 0.704012 \n\nEpoch 125\n-------------------------------\nloss: 0.738031  [   16/ 4910]\nloss: 0.729557  [ 1616/ 4910]\nloss: 0.553375  [ 3216/ 4910]\nloss: 0.614315  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.706754 \n\nEpoch 126\n-------------------------------\nloss: 0.616909  [   16/ 4910]\nloss: 0.596898  [ 1616/ 4910]\nloss: 0.812998  [ 3216/ 4910]\nloss: 0.555761  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.9%, Avg loss: 0.711734 \n\nEpoch 127\n-------------------------------\nloss: 0.739139  [   16/ 4910]\nloss: 0.625402  [ 1616/ 4910]\nloss: 0.676597  [ 3216/ 4910]\nloss: 0.739376  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.711547 \n\nEpoch 128\n-------------------------------\nloss: 0.569560  [   16/ 4910]\nloss: 0.739134  [ 1616/ 4910]\nloss: 0.572636  [ 3216/ 4910]\nloss: 0.617600  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.0%, Avg loss: 0.703852 \n\nEpoch 129\n-------------------------------\nloss: 0.777066  [   16/ 4910]\nloss: 0.624266  [ 1616/ 4910]\nloss: 0.868495  [ 3216/ 4910]\nloss: 0.695225  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.5%, Avg loss: 0.706879 \n\nEpoch 130\n-------------------------------\nloss: 0.753511  [   16/ 4910]\nloss: 0.739516  [ 1616/ 4910]\nloss: 0.559998  [ 3216/ 4910]\nloss: 0.629757  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.5%, Avg loss: 0.706717 \n\nEpoch 131\n-------------------------------\nloss: 0.614260  [   16/ 4910]\nloss: 0.575311  [ 1616/ 4910]\nloss: 0.678909  [ 3216/ 4910]\nloss: 0.622998  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.704193 \n\nEpoch 132\n-------------------------------\nloss: 0.682046  [   16/ 4910]\nloss: 0.741489  [ 1616/ 4910]\nloss: 0.775350  [ 3216/ 4910]\nloss: 0.764021  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.693239 \n\nEpoch 133\n-------------------------------\nloss: 0.626504  [   16/ 4910]\nloss: 0.625491  [ 1616/ 4910]\nloss: 0.616129  [ 3216/ 4910]\nloss: 0.616225  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.5%, Avg loss: 0.700536 \n\nEpoch 134\n-------------------------------\nloss: 0.734937  [   16/ 4910]\nloss: 0.629806  [ 1616/ 4910]\nloss: 0.802388  [ 3216/ 4910]\nloss: 0.614579  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.707658 \n\nEpoch 135\n-------------------------------\nloss: 0.690602  [   16/ 4910]\nloss: 0.617958  [ 1616/ 4910]\nloss: 0.621287  [ 3216/ 4910]\nloss: 0.740169  [ 4816/ 4910]\nTest Error: \n Accuracy: 82.2%, Avg loss: 0.732189 \n\nEpoch 136\n-------------------------------\nloss: 0.861868  [   16/ 4910]\nloss: 0.654545  [ 1616/ 4910]\nloss: 0.804806  [ 3216/ 4910]\nloss: 0.623144  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.693820 \n\nEpoch 137\n-------------------------------\nloss: 0.740693  [   16/ 4910]\nloss: 0.616833  [ 1616/ 4910]\nloss: 0.652405  [ 3216/ 4910]\nloss: 0.633730  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.696433 \n\nEpoch 138\n-------------------------------\nloss: 0.863232  [   16/ 4910]\nloss: 0.721761  [ 1616/ 4910]\nloss: 0.679823  [ 3216/ 4910]\nloss: 0.686451  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.8%, Avg loss: 0.717348 \n\nEpoch 139\n-------------------------------\nloss: 0.677239  [   16/ 4910]\nloss: 0.733885  [ 1616/ 4910]\nloss: 0.739130  [ 3216/ 4910]\nloss: 0.614926  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.7%, Avg loss: 0.704944 \n\nEpoch 140\n-------------------------------\nloss: 0.676469  [   16/ 4910]\nloss: 0.788198  [ 1616/ 4910]\nloss: 0.636925  [ 3216/ 4910]\nloss: 0.673581  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.0%, Avg loss: 0.721102 \n\nEpoch 141\n-------------------------------\nloss: 0.552192  [   16/ 4910]\nloss: 0.687008  [ 1616/ 4910]\nloss: 0.712389  [ 3216/ 4910]\nloss: 0.659475  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.4%, Avg loss: 0.706715 \n\nEpoch 142\n-------------------------------\nloss: 0.801584  [   16/ 4910]\nloss: 0.749273  [ 1616/ 4910]\nloss: 0.646066  [ 3216/ 4910]\nloss: 0.631909  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.8%, Avg loss: 0.695425 \n\nEpoch 143\n-------------------------------\nloss: 0.704990  [   16/ 4910]\nloss: 0.680820  [ 1616/ 4910]\nloss: 0.807034  [ 3216/ 4910]\nloss: 0.614873  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.707733 \n\nEpoch 144\n-------------------------------\nloss: 0.683610  [   16/ 4910]\nloss: 0.805683  [ 1616/ 4910]\nloss: 0.657416  [ 3216/ 4910]\nloss: 0.739348  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.704684 \n\nEpoch 145\n-------------------------------\nloss: 0.555594  [   16/ 4910]\nloss: 0.553987  [ 1616/ 4910]\nloss: 0.803826  [ 3216/ 4910]\nloss: 0.730806  [ 4816/ 4910]\nTest Error: \n Accuracy: 81.8%, Avg loss: 0.733053 \n\nEpoch 146\n-------------------------------\nloss: 0.679892  [   16/ 4910]\nloss: 0.733534  [ 1616/ 4910]\nloss: 0.677625  [ 3216/ 4910]\nloss: 0.745777  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.0%, Avg loss: 0.698926 \n\nEpoch 147\n-------------------------------\nloss: 0.676441  [   16/ 4910]\nloss: 0.667311  [ 1616/ 4910]\nloss: 0.803392  [ 3216/ 4910]\nloss: 0.593002  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.686323 \n\nEpoch 148\n-------------------------------\nloss: 0.614838  [   16/ 4910]\nloss: 0.677543  [ 1616/ 4910]\nloss: 0.551668  [ 3216/ 4910]\nloss: 0.639969  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.5%, Avg loss: 0.694321 \n\nEpoch 149\n-------------------------------\nloss: 0.763554  [   16/ 4910]\nloss: 0.634006  [ 1616/ 4910]\nloss: 0.698394  [ 3216/ 4910]\nloss: 0.619114  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.691423 \n\nEpoch 150\n-------------------------------\nloss: 0.869693  [   16/ 4910]\nloss: 0.811501  [ 1616/ 4910]\nloss: 0.698147  [ 3216/ 4910]\nloss: 0.680964  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.9%, Avg loss: 0.695424 \n\nEpoch 151\n-------------------------------\nloss: 0.613917  [   16/ 4910]\nloss: 0.613846  [ 1616/ 4910]\nloss: 0.676580  [ 3216/ 4910]\nloss: 0.916520  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.9%, Avg loss: 0.694224 \n\nEpoch 152\n-------------------------------\nloss: 0.738377  [   16/ 4910]\nloss: 0.614558  [ 1616/ 4910]\nloss: 0.679679  [ 3216/ 4910]\nloss: 0.676865  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.5%, Avg loss: 0.706132 \n\nEpoch 153\n-------------------------------\nloss: 0.877002  [   16/ 4910]\nloss: 0.797981  [ 1616/ 4910]\nloss: 0.737647  [ 3216/ 4910]\nloss: 0.740301  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.6%, Avg loss: 0.703768 \n\nEpoch 154\n-------------------------------\nloss: 0.921402  [   16/ 4910]\nloss: 0.615071  [ 1616/ 4910]\nloss: 0.552023  [ 3216/ 4910]\nloss: 0.629694  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.689135 \n\nEpoch 155\n-------------------------------\nloss: 0.616682  [   16/ 4910]\nloss: 0.601080  [ 1616/ 4910]\nloss: 0.616096  [ 3216/ 4910]\nloss: 0.694773  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.1%, Avg loss: 0.699500 \n\nEpoch 156\n-------------------------------\nloss: 0.677483  [   16/ 4910]\nloss: 0.614871  [ 1616/ 4910]\nloss: 0.676709  [ 3216/ 4910]\nloss: 0.551754  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.9%, Avg loss: 0.683691 \n\nEpoch 157\n-------------------------------\nloss: 0.739559  [   16/ 4910]\nloss: 0.614402  [ 1616/ 4910]\nloss: 0.588850  [ 3216/ 4910]\nloss: 0.802390  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.686008 \n\nEpoch 158\n-------------------------------\nloss: 0.616206  [   16/ 4910]\nloss: 0.752862  [ 1616/ 4910]\nloss: 0.744669  [ 3216/ 4910]\nloss: 0.889284  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.697878 \n\nEpoch 159\n-------------------------------\nloss: 0.552135  [   16/ 4910]\nloss: 0.614396  [ 1616/ 4910]\nloss: 0.680832  [ 3216/ 4910]\nloss: 0.800206  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.2%, Avg loss: 0.713813 \n\nEpoch 160\n-------------------------------\nloss: 0.678801  [   16/ 4910]\nloss: 0.739595  [ 1616/ 4910]\nloss: 0.739541  [ 3216/ 4910]\nloss: 0.676767  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.2%, Avg loss: 0.698964 \n\nEpoch 161\n-------------------------------\nloss: 0.803154  [   16/ 4910]\nloss: 0.566772  [ 1616/ 4910]\nloss: 0.679219  [ 3216/ 4910]\nloss: 0.691849  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.685457 \n\nEpoch 162\n-------------------------------\nloss: 0.672590  [   16/ 4910]\nloss: 0.736886  [ 1616/ 4910]\nloss: 0.673254  [ 3216/ 4910]\nloss: 0.651698  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.702386 \n\nEpoch 163\n-------------------------------\nloss: 0.863795  [   16/ 4910]\nloss: 0.614126  [ 1616/ 4910]\nloss: 0.873196  [ 3216/ 4910]\nloss: 0.584039  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.686513 \n\nEpoch 164\n-------------------------------\nloss: 0.676966  [   16/ 4910]\nloss: 0.572526  [ 1616/ 4910]\nloss: 0.552366  [ 3216/ 4910]\nloss: 0.664191  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.0%, Avg loss: 0.697525 \n\nEpoch 165\n-------------------------------\nloss: 0.684059  [   16/ 4910]\nloss: 0.679002  [ 1616/ 4910]\nloss: 0.561135  [ 3216/ 4910]\nloss: 0.639000  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.691725 \n\nEpoch 166\n-------------------------------\nloss: 0.753061  [   16/ 4910]\nloss: 0.739056  [ 1616/ 4910]\nloss: 0.659418  [ 3216/ 4910]\nloss: 0.662583  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.4%, Avg loss: 0.682933 \n\nEpoch 167\n-------------------------------\nloss: 0.595230  [   16/ 4910]\nloss: 0.614190  [ 1616/ 4910]\nloss: 0.554539  [ 3216/ 4910]\nloss: 0.709329  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.697935 \n\nEpoch 168\n-------------------------------\nloss: 0.568734  [   16/ 4910]\nloss: 0.676481  [ 1616/ 4910]\nloss: 0.552059  [ 3216/ 4910]\nloss: 0.573138  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.681897 \n\nEpoch 169\n-------------------------------\nloss: 0.678223  [   16/ 4910]\nloss: 0.750616  [ 1616/ 4910]\nloss: 0.614710  [ 3216/ 4910]\nloss: 0.683260  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.4%, Avg loss: 0.696580 \n\nEpoch 170\n-------------------------------\nloss: 0.862210  [   16/ 4910]\nloss: 0.551459  [ 1616/ 4910]\nloss: 0.614838  [ 3216/ 4910]\nloss: 0.802136  [ 4816/ 4910]\nTest Error: \n Accuracy: 84.9%, Avg loss: 0.697915 \n\nEpoch 171\n-------------------------------\nloss: 0.748243  [   16/ 4910]\nloss: 0.687277  [ 1616/ 4910]\nloss: 0.734106  [ 3216/ 4910]\nloss: 0.616184  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.683854 \n\nEpoch 172\n-------------------------------\nloss: 0.615810  [   16/ 4910]\nloss: 0.554739  [ 1616/ 4910]\nloss: 0.733368  [ 3216/ 4910]\nloss: 0.742118  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.3%, Avg loss: 0.680848 \n\nEpoch 173\n-------------------------------\nloss: 0.739089  [   16/ 4910]\nloss: 0.685469  [ 1616/ 4910]\nloss: 0.622923  [ 3216/ 4910]\nloss: 0.555736  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.687130 \n\nEpoch 174\n-------------------------------\nloss: 0.615197  [   16/ 4910]\nloss: 0.677265  [ 1616/ 4910]\nloss: 0.624141  [ 3216/ 4910]\nloss: 0.627033  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.684986 \n\nEpoch 175\n-------------------------------\nloss: 0.556890  [   16/ 4910]\nloss: 0.616098  [ 1616/ 4910]\nloss: 0.552530  [ 3216/ 4910]\nloss: 0.615613  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.9%, Avg loss: 0.682197 \n\nEpoch 176\n-------------------------------\nloss: 0.551690  [   16/ 4910]\nloss: 0.616684  [ 1616/ 4910]\nloss: 0.608131  [ 3216/ 4910]\nloss: 0.628997  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.684710 \n\nEpoch 177\n-------------------------------\nloss: 0.740608  [   16/ 4910]\nloss: 0.801487  [ 1616/ 4910]\nloss: 0.755929  [ 3216/ 4910]\nloss: 0.615255  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.680936 \n\nEpoch 178\n-------------------------------\nloss: 0.614103  [   16/ 4910]\nloss: 0.700092  [ 1616/ 4910]\nloss: 0.615072  [ 3216/ 4910]\nloss: 0.680561  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.8%, Avg loss: 0.684604 \n\nEpoch 179\n-------------------------------\nloss: 0.782134  [   16/ 4910]\nloss: 0.583507  [ 1616/ 4910]\nloss: 0.622027  [ 3216/ 4910]\nloss: 0.673925  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.685073 \n\nEpoch 180\n-------------------------------\nloss: 0.552151  [   16/ 4910]\nloss: 0.557961  [ 1616/ 4910]\nloss: 0.612265  [ 3216/ 4910]\nloss: 0.617145  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.0%, Avg loss: 0.696470 \n\nEpoch 181\n-------------------------------\nloss: 0.798488  [   16/ 4910]\nloss: 0.672117  [ 1616/ 4910]\nloss: 0.812869  [ 3216/ 4910]\nloss: 0.851120  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.680129 \n\nEpoch 182\n-------------------------------\nloss: 0.800631  [   16/ 4910]\nloss: 0.691814  [ 1616/ 4910]\nloss: 0.621032  [ 3216/ 4910]\nloss: 0.628107  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.3%, Avg loss: 0.691201 \n\nEpoch 183\n-------------------------------\nloss: 0.739289  [   16/ 4910]\nloss: 0.613664  [ 1616/ 4910]\nloss: 0.642248  [ 3216/ 4910]\nloss: 0.681180  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.8%, Avg loss: 0.685109 \n\nEpoch 184\n-------------------------------\nloss: 0.758009  [   16/ 4910]\nloss: 0.552269  [ 1616/ 4910]\nloss: 0.735669  [ 3216/ 4910]\nloss: 0.863043  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.8%, Avg loss: 0.692612 \n\nEpoch 185\n-------------------------------\nloss: 0.742599  [   16/ 4910]\nloss: 0.685138  [ 1616/ 4910]\nloss: 0.616181  [ 3216/ 4910]\nloss: 0.620325  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.680661 \n\nEpoch 186\n-------------------------------\nloss: 0.737924  [   16/ 4910]\nloss: 0.582260  [ 1616/ 4910]\nloss: 0.676250  [ 3216/ 4910]\nloss: 0.744226  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.8%, Avg loss: 0.676336 \n\nEpoch 187\n-------------------------------\nloss: 0.677253  [   16/ 4910]\nloss: 0.620635  [ 1616/ 4910]\nloss: 0.676509  [ 3216/ 4910]\nloss: 0.796612  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.1%, Avg loss: 0.681595 \n\nEpoch 188\n-------------------------------\nloss: 0.739222  [   16/ 4910]\nloss: 0.720709  [ 1616/ 4910]\nloss: 0.622997  [ 3216/ 4910]\nloss: 0.683551  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.680170 \n\nEpoch 189\n-------------------------------\nloss: 0.553950  [   16/ 4910]\nloss: 0.691245  [ 1616/ 4910]\nloss: 0.760902  [ 3216/ 4910]\nloss: 0.585173  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.694880 \n\nEpoch 190\n-------------------------------\nloss: 0.680484  [   16/ 4910]\nloss: 0.552359  [ 1616/ 4910]\nloss: 0.613940  [ 3216/ 4910]\nloss: 0.679913  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.688307 \n\nEpoch 191\n-------------------------------\nloss: 0.793177  [   16/ 4910]\nloss: 0.616979  [ 1616/ 4910]\nloss: 0.876532  [ 3216/ 4910]\nloss: 0.614130  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.0%, Avg loss: 0.690561 \n\nEpoch 192\n-------------------------------\nloss: 0.605042  [   16/ 4910]\nloss: 0.676625  [ 1616/ 4910]\nloss: 0.638101  [ 3216/ 4910]\nloss: 0.676651  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.695145 \n\nEpoch 193\n-------------------------------\nloss: 0.721320  [   16/ 4910]\nloss: 0.618867  [ 1616/ 4910]\nloss: 0.624445  [ 3216/ 4910]\nloss: 0.747366  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.675816 \n\nEpoch 194\n-------------------------------\nloss: 0.675113  [   16/ 4910]\nloss: 0.675795  [ 1616/ 4910]\nloss: 0.659281  [ 3216/ 4910]\nloss: 0.620848  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.8%, Avg loss: 0.684683 \n\nEpoch 195\n-------------------------------\nloss: 0.614345  [   16/ 4910]\nloss: 0.675025  [ 1616/ 4910]\nloss: 0.668639  [ 3216/ 4910]\nloss: 0.723132  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.691793 \n\nEpoch 196\n-------------------------------\nloss: 0.614949  [   16/ 4910]\nloss: 0.677327  [ 1616/ 4910]\nloss: 0.651231  [ 3216/ 4910]\nloss: 0.616203  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.680806 \n\nEpoch 197\n-------------------------------\nloss: 0.738918  [   16/ 4910]\nloss: 0.744476  [ 1616/ 4910]\nloss: 0.782129  [ 3216/ 4910]\nloss: 0.676878  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.692905 \n\nEpoch 198\n-------------------------------\nloss: 0.681285  [   16/ 4910]\nloss: 0.556245  [ 1616/ 4910]\nloss: 0.551829  [ 3216/ 4910]\nloss: 0.677272  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.670943 \n\nEpoch 199\n-------------------------------\nloss: 0.694388  [   16/ 4910]\nloss: 0.745768  [ 1616/ 4910]\nloss: 0.679540  [ 3216/ 4910]\nloss: 0.686620  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.1%, Avg loss: 0.682426 \n\nEpoch 200\n-------------------------------\nloss: 0.676471  [   16/ 4910]\nloss: 0.738554  [ 1616/ 4910]\nloss: 0.616870  [ 3216/ 4910]\nloss: 0.678488  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.677960 \n\nEpoch 201\n-------------------------------\nloss: 0.614221  [   16/ 4910]\nloss: 0.619331  [ 1616/ 4910]\nloss: 0.623181  [ 3216/ 4910]\nloss: 0.717252  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.687618 \n\nEpoch 202\n-------------------------------\nloss: 0.552907  [   16/ 4910]\nloss: 0.676620  [ 1616/ 4910]\nloss: 0.630052  [ 3216/ 4910]\nloss: 0.614560  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.1%, Avg loss: 0.680504 \n\nEpoch 203\n-------------------------------\nloss: 0.552987  [   16/ 4910]\nloss: 0.739427  [ 1616/ 4910]\nloss: 0.568905  [ 3216/ 4910]\nloss: 0.620208  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.672090 \n\nEpoch 204\n-------------------------------\nloss: 0.795959  [   16/ 4910]\nloss: 0.743763  [ 1616/ 4910]\nloss: 0.677746  [ 3216/ 4910]\nloss: 0.568167  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.693259 \n\nEpoch 205\n-------------------------------\nloss: 0.638462  [   16/ 4910]\nloss: 0.678160  [ 1616/ 4910]\nloss: 0.614637  [ 3216/ 4910]\nloss: 0.551619  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.686076 \n\nEpoch 206\n-------------------------------\nloss: 0.676045  [   16/ 4910]\nloss: 0.801925  [ 1616/ 4910]\nloss: 0.676869  [ 3216/ 4910]\nloss: 0.552237  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.3%, Avg loss: 0.679699 \n\nEpoch 207\n-------------------------------\nloss: 0.676478  [   16/ 4910]\nloss: 0.616914  [ 1616/ 4910]\nloss: 0.614978  [ 3216/ 4910]\nloss: 0.682498  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.688505 \n\nEpoch 208\n-------------------------------\nloss: 0.553332  [   16/ 4910]\nloss: 0.568079  [ 1616/ 4910]\nloss: 0.617848  [ 3216/ 4910]\nloss: 0.614460  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.9%, Avg loss: 0.681034 \n\nEpoch 209\n-------------------------------\nloss: 0.683200  [   16/ 4910]\nloss: 0.741537  [ 1616/ 4910]\nloss: 0.739248  [ 3216/ 4910]\nloss: 0.680906  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.672007 \n\nEpoch 210\n-------------------------------\nloss: 0.677100  [   16/ 4910]\nloss: 0.614142  [ 1616/ 4910]\nloss: 0.667791  [ 3216/ 4910]\nloss: 0.801590  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.7%, Avg loss: 0.695034 \n\nEpoch 211\n-------------------------------\nloss: 0.694395  [   16/ 4910]\nloss: 0.614956  [ 1616/ 4910]\nloss: 0.737662  [ 3216/ 4910]\nloss: 0.677533  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.672572 \n\nEpoch 212\n-------------------------------\nloss: 0.675980  [   16/ 4910]\nloss: 0.751264  [ 1616/ 4910]\nloss: 0.887260  [ 3216/ 4910]\nloss: 0.689940  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.5%, Avg loss: 0.685075 \n\nEpoch 213\n-------------------------------\nloss: 0.693928  [   16/ 4910]\nloss: 0.614028  [ 1616/ 4910]\nloss: 0.655989  [ 3216/ 4910]\nloss: 0.621631  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.695931 \n\nEpoch 214\n-------------------------------\nloss: 0.634857  [   16/ 4910]\nloss: 0.614374  [ 1616/ 4910]\nloss: 0.615458  [ 3216/ 4910]\nloss: 0.635244  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.1%, Avg loss: 0.681014 \n\nEpoch 215\n-------------------------------\nloss: 0.614054  [   16/ 4910]\nloss: 0.552511  [ 1616/ 4910]\nloss: 0.620008  [ 3216/ 4910]\nloss: 0.829572  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.6%, Avg loss: 0.678754 \n\nEpoch 216\n-------------------------------\nloss: 0.620382  [   16/ 4910]\nloss: 0.553196  [ 1616/ 4910]\nloss: 0.676887  [ 3216/ 4910]\nloss: 0.554036  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.4%, Avg loss: 0.693272 \n\nEpoch 217\n-------------------------------\nloss: 0.725111  [   16/ 4910]\nloss: 0.686690  [ 1616/ 4910]\nloss: 0.620405  [ 3216/ 4910]\nloss: 0.614011  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.668966 \n\nEpoch 218\n-------------------------------\nloss: 0.551875  [   16/ 4910]\nloss: 0.739041  [ 1616/ 4910]\nloss: 0.674317  [ 3216/ 4910]\nloss: 0.739051  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.8%, Avg loss: 0.686040 \n\nEpoch 219\n-------------------------------\nloss: 0.740506  [   16/ 4910]\nloss: 0.742188  [ 1616/ 4910]\nloss: 0.741779  [ 3216/ 4910]\nloss: 0.678158  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.9%, Avg loss: 0.693189 \n\nEpoch 220\n-------------------------------\nloss: 0.552139  [   16/ 4910]\nloss: 0.625516  [ 1616/ 4910]\nloss: 0.557496  [ 3216/ 4910]\nloss: 0.620403  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.679814 \n\nEpoch 221\n-------------------------------\nloss: 0.614034  [   16/ 4910]\nloss: 0.552749  [ 1616/ 4910]\nloss: 0.739134  [ 3216/ 4910]\nloss: 0.676626  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.671953 \n\nEpoch 222\n-------------------------------\nloss: 0.728481  [   16/ 4910]\nloss: 0.554391  [ 1616/ 4910]\nloss: 0.555830  [ 3216/ 4910]\nloss: 0.612553  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.0%, Avg loss: 0.703341 \n\nEpoch 223\n-------------------------------\nloss: 0.682024  [   16/ 4910]\nloss: 0.553669  [ 1616/ 4910]\nloss: 0.666821  [ 3216/ 4910]\nloss: 0.593804  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.7%, Avg loss: 0.689016 \n\nEpoch 224\n-------------------------------\nloss: 0.740151  [   16/ 4910]\nloss: 0.686998  [ 1616/ 4910]\nloss: 0.645579  [ 3216/ 4910]\nloss: 0.551975  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.685221 \n\nEpoch 225\n-------------------------------\nloss: 0.555089  [   16/ 4910]\nloss: 0.676838  [ 1616/ 4910]\nloss: 0.551661  [ 3216/ 4910]\nloss: 0.614132  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.7%, Avg loss: 0.672178 \n\nEpoch 226\n-------------------------------\nloss: 0.802016  [   16/ 4910]\nloss: 0.729182  [ 1616/ 4910]\nloss: 0.552890  [ 3216/ 4910]\nloss: 0.738654  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.667799 \n\nEpoch 227\n-------------------------------\nloss: 0.559256  [   16/ 4910]\nloss: 0.614153  [ 1616/ 4910]\nloss: 0.579961  [ 3216/ 4910]\nloss: 0.644286  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.670732 \n\nEpoch 228\n-------------------------------\nloss: 0.551521  [   16/ 4910]\nloss: 0.612522  [ 1616/ 4910]\nloss: 0.552096  [ 3216/ 4910]\nloss: 0.740144  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.685422 \n\nEpoch 229\n-------------------------------\nloss: 0.615063  [   16/ 4910]\nloss: 0.615410  [ 1616/ 4910]\nloss: 0.740394  [ 3216/ 4910]\nloss: 0.671318  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.675945 \n\nEpoch 230\n-------------------------------\nloss: 0.675617  [   16/ 4910]\nloss: 0.552140  [ 1616/ 4910]\nloss: 0.551815  [ 3216/ 4910]\nloss: 0.551569  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.4%, Avg loss: 0.697587 \n\nEpoch 231\n-------------------------------\nloss: 0.551584  [   16/ 4910]\nloss: 0.740183  [ 1616/ 4910]\nloss: 0.614473  [ 3216/ 4910]\nloss: 0.660509  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.679443 \n\nEpoch 232\n-------------------------------\nloss: 0.615457  [   16/ 4910]\nloss: 0.647373  [ 1616/ 4910]\nloss: 0.658214  [ 3216/ 4910]\nloss: 0.614417  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.664983 \n\nEpoch 233\n-------------------------------\nloss: 0.680474  [   16/ 4910]\nloss: 0.551975  [ 1616/ 4910]\nloss: 0.801671  [ 3216/ 4910]\nloss: 0.678692  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.676276 \n\nEpoch 234\n-------------------------------\nloss: 0.699921  [   16/ 4910]\nloss: 0.741372  [ 1616/ 4910]\nloss: 0.615332  [ 3216/ 4910]\nloss: 0.691839  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.673883 \n\nEpoch 235\n-------------------------------\nloss: 0.675748  [   16/ 4910]\nloss: 0.622303  [ 1616/ 4910]\nloss: 0.642296  [ 3216/ 4910]\nloss: 0.552622  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.674316 \n\nEpoch 236\n-------------------------------\nloss: 0.645181  [   16/ 4910]\nloss: 0.614295  [ 1616/ 4910]\nloss: 0.724663  [ 3216/ 4910]\nloss: 0.551795  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.3%, Avg loss: 0.677283 \n\nEpoch 237\n-------------------------------\nloss: 0.738406  [   16/ 4910]\nloss: 0.679009  [ 1616/ 4910]\nloss: 0.552804  [ 3216/ 4910]\nloss: 0.778781  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.3%, Avg loss: 0.675266 \n\nEpoch 238\n-------------------------------\nloss: 0.614700  [   16/ 4910]\nloss: 0.678552  [ 1616/ 4910]\nloss: 0.729804  [ 3216/ 4910]\nloss: 0.708416  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.3%, Avg loss: 0.679710 \n\nEpoch 239\n-------------------------------\nloss: 0.615049  [   16/ 4910]\nloss: 0.555356  [ 1616/ 4910]\nloss: 0.736471  [ 3216/ 4910]\nloss: 0.554283  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.671822 \n\nEpoch 240\n-------------------------------\nloss: 0.624188  [   16/ 4910]\nloss: 0.551609  [ 1616/ 4910]\nloss: 0.752257  [ 3216/ 4910]\nloss: 0.683144  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.677127 \n\nEpoch 241\n-------------------------------\nloss: 0.639692  [   16/ 4910]\nloss: 0.739062  [ 1616/ 4910]\nloss: 0.738747  [ 3216/ 4910]\nloss: 0.614677  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.673267 \n\nEpoch 242\n-------------------------------\nloss: 0.551472  [   16/ 4910]\nloss: 0.614586  [ 1616/ 4910]\nloss: 0.669767  [ 3216/ 4910]\nloss: 0.681398  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.675351 \n\nEpoch 243\n-------------------------------\nloss: 0.678585  [   16/ 4910]\nloss: 0.677094  [ 1616/ 4910]\nloss: 0.678275  [ 3216/ 4910]\nloss: 0.586906  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.671337 \n\nEpoch 244\n-------------------------------\nloss: 0.736787  [   16/ 4910]\nloss: 0.617047  [ 1616/ 4910]\nloss: 0.555289  [ 3216/ 4910]\nloss: 0.551481  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.680607 \n\nEpoch 245\n-------------------------------\nloss: 0.693745  [   16/ 4910]\nloss: 0.647750  [ 1616/ 4910]\nloss: 0.552566  [ 3216/ 4910]\nloss: 0.614134  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.669256 \n\nEpoch 246\n-------------------------------\nloss: 0.678503  [   16/ 4910]\nloss: 0.606047  [ 1616/ 4910]\nloss: 0.679001  [ 3216/ 4910]\nloss: 0.554756  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.663361 \n\nEpoch 247\n-------------------------------\nloss: 0.676351  [   16/ 4910]\nloss: 0.676769  [ 1616/ 4910]\nloss: 0.552881  [ 3216/ 4910]\nloss: 0.701240  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.670094 \n\nEpoch 248\n-------------------------------\nloss: 0.614064  [   16/ 4910]\nloss: 0.676627  [ 1616/ 4910]\nloss: 0.556228  [ 3216/ 4910]\nloss: 0.764086  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.687107 \n\nEpoch 249\n-------------------------------\nloss: 0.761645  [   16/ 4910]\nloss: 0.760023  [ 1616/ 4910]\nloss: 0.581596  [ 3216/ 4910]\nloss: 0.614402  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.663661 \n\nEpoch 250\n-------------------------------\nloss: 0.551680  [   16/ 4910]\nloss: 0.612765  [ 1616/ 4910]\nloss: 0.639562  [ 3216/ 4910]\nloss: 0.691320  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.661249 \n\nEpoch 251\n-------------------------------\nloss: 0.553308  [   16/ 4910]\nloss: 0.553812  [ 1616/ 4910]\nloss: 0.732760  [ 3216/ 4910]\nloss: 0.683446  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.660682 \n\nEpoch 252\n-------------------------------\nloss: 0.614980  [   16/ 4910]\nloss: 0.623159  [ 1616/ 4910]\nloss: 0.614361  [ 3216/ 4910]\nloss: 0.648651  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.665246 \n\nEpoch 253\n-------------------------------\nloss: 0.614150  [   16/ 4910]\nloss: 0.551715  [ 1616/ 4910]\nloss: 0.678274  [ 3216/ 4910]\nloss: 0.738789  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.668124 \n\nEpoch 254\n-------------------------------\nloss: 0.566313  [   16/ 4910]\nloss: 0.556039  [ 1616/ 4910]\nloss: 0.802536  [ 3216/ 4910]\nloss: 0.603578  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.666325 \n\nEpoch 255\n-------------------------------\nloss: 0.614275  [   16/ 4910]\nloss: 0.557386  [ 1616/ 4910]\nloss: 0.677778  [ 3216/ 4910]\nloss: 0.614062  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.6%, Avg loss: 0.685626 \n\nEpoch 256\n-------------------------------\nloss: 0.813773  [   16/ 4910]\nloss: 0.675660  [ 1616/ 4910]\nloss: 0.734784  [ 3216/ 4910]\nloss: 0.676585  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.658352 \n\nEpoch 257\n-------------------------------\nloss: 0.608388  [   16/ 4910]\nloss: 0.551648  [ 1616/ 4910]\nloss: 0.614940  [ 3216/ 4910]\nloss: 0.551698  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.668242 \n\nEpoch 258\n-------------------------------\nloss: 0.617221  [   16/ 4910]\nloss: 0.614177  [ 1616/ 4910]\nloss: 0.677072  [ 3216/ 4910]\nloss: 0.631376  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.1%, Avg loss: 0.698953 \n\nEpoch 259\n-------------------------------\nloss: 0.635005  [   16/ 4910]\nloss: 0.676852  [ 1616/ 4910]\nloss: 0.553421  [ 3216/ 4910]\nloss: 0.567235  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659935 \n\nEpoch 260\n-------------------------------\nloss: 0.676830  [   16/ 4910]\nloss: 0.613968  [ 1616/ 4910]\nloss: 0.551636  [ 3216/ 4910]\nloss: 0.552631  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.657630 \n\nEpoch 261\n-------------------------------\nloss: 0.616718  [   16/ 4910]\nloss: 0.740596  [ 1616/ 4910]\nloss: 0.739795  [ 3216/ 4910]\nloss: 0.676461  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.673266 \n\nEpoch 262\n-------------------------------\nloss: 0.613978  [   16/ 4910]\nloss: 0.614496  [ 1616/ 4910]\nloss: 0.738938  [ 3216/ 4910]\nloss: 0.614088  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.666838 \n\nEpoch 263\n-------------------------------\nloss: 0.739051  [   16/ 4910]\nloss: 0.627728  [ 1616/ 4910]\nloss: 0.787588  [ 3216/ 4910]\nloss: 0.614112  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.670268 \n\nEpoch 264\n-------------------------------\nloss: 0.554702  [   16/ 4910]\nloss: 0.615456  [ 1616/ 4910]\nloss: 0.678981  [ 3216/ 4910]\nloss: 0.614214  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.662706 \n\nEpoch 265\n-------------------------------\nloss: 0.551666  [   16/ 4910]\nloss: 0.632133  [ 1616/ 4910]\nloss: 0.681015  [ 3216/ 4910]\nloss: 0.649209  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.8%, Avg loss: 0.680603 \n\nEpoch 266\n-------------------------------\nloss: 0.591655  [   16/ 4910]\nloss: 0.674130  [ 1616/ 4910]\nloss: 0.554503  [ 3216/ 4910]\nloss: 0.551668  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.664415 \n\nEpoch 267\n-------------------------------\nloss: 0.741246  [   16/ 4910]\nloss: 0.562138  [ 1616/ 4910]\nloss: 0.614928  [ 3216/ 4910]\nloss: 0.614112  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.658792 \n\nEpoch 268\n-------------------------------\nloss: 0.551488  [   16/ 4910]\nloss: 0.815958  [ 1616/ 4910]\nloss: 0.677147  [ 3216/ 4910]\nloss: 0.610554  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.6%, Avg loss: 0.672673 \n\nEpoch 269\n-------------------------------\nloss: 0.552174  [   16/ 4910]\nloss: 0.626738  [ 1616/ 4910]\nloss: 0.676880  [ 3216/ 4910]\nloss: 0.676478  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.669123 \n\nEpoch 270\n-------------------------------\nloss: 0.551780  [   16/ 4910]\nloss: 0.614510  [ 1616/ 4910]\nloss: 0.562389  [ 3216/ 4910]\nloss: 0.552159  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.671346 \n\nEpoch 271\n-------------------------------\nloss: 0.685046  [   16/ 4910]\nloss: 0.676867  [ 1616/ 4910]\nloss: 0.673608  [ 3216/ 4910]\nloss: 0.676657  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.5%, Avg loss: 0.694191 \n\nEpoch 272\n-------------------------------\nloss: 0.569157  [   16/ 4910]\nloss: 0.551622  [ 1616/ 4910]\nloss: 0.552818  [ 3216/ 4910]\nloss: 0.619834  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.4%, Avg loss: 0.676848 \n\nEpoch 273\n-------------------------------\nloss: 0.614325  [   16/ 4910]\nloss: 0.558057  [ 1616/ 4910]\nloss: 0.552137  [ 3216/ 4910]\nloss: 0.613052  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.661340 \n\nEpoch 274\n-------------------------------\nloss: 0.738930  [   16/ 4910]\nloss: 0.802712  [ 1616/ 4910]\nloss: 0.680029  [ 3216/ 4910]\nloss: 0.677720  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.668189 \n\nEpoch 275\n-------------------------------\nloss: 0.551544  [   16/ 4910]\nloss: 0.614036  [ 1616/ 4910]\nloss: 0.681188  [ 3216/ 4910]\nloss: 0.626245  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.662448 \n\nEpoch 276\n-------------------------------\nloss: 0.614659  [   16/ 4910]\nloss: 0.613980  [ 1616/ 4910]\nloss: 0.551609  [ 3216/ 4910]\nloss: 0.677332  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661425 \n\nEpoch 277\n-------------------------------\nloss: 0.801740  [   16/ 4910]\nloss: 0.613973  [ 1616/ 4910]\nloss: 0.614425  [ 3216/ 4910]\nloss: 0.623243  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.659570 \n\nEpoch 278\n-------------------------------\nloss: 0.551697  [   16/ 4910]\nloss: 0.614271  [ 1616/ 4910]\nloss: 0.620071  [ 3216/ 4910]\nloss: 0.654122  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.676743 \n\nEpoch 279\n-------------------------------\nloss: 0.725900  [   16/ 4910]\nloss: 0.676612  [ 1616/ 4910]\nloss: 0.676625  [ 3216/ 4910]\nloss: 0.573442  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.9%, Avg loss: 0.680167 \n\nEpoch 280\n-------------------------------\nloss: 0.707548  [   16/ 4910]\nloss: 0.551590  [ 1616/ 4910]\nloss: 0.788446  [ 3216/ 4910]\nloss: 0.614007  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.666581 \n\nEpoch 281\n-------------------------------\nloss: 0.615807  [   16/ 4910]\nloss: 0.551987  [ 1616/ 4910]\nloss: 0.551543  [ 3216/ 4910]\nloss: 0.614067  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.663954 \n\nEpoch 282\n-------------------------------\nloss: 0.697120  [   16/ 4910]\nloss: 0.617210  [ 1616/ 4910]\nloss: 0.676777  [ 3216/ 4910]\nloss: 0.616667  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655013 \n\nEpoch 283\n-------------------------------\nloss: 0.739093  [   16/ 4910]\nloss: 0.628493  [ 1616/ 4910]\nloss: 0.622105  [ 3216/ 4910]\nloss: 0.701372  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.667722 \n\nEpoch 284\n-------------------------------\nloss: 0.675004  [   16/ 4910]\nloss: 0.551856  [ 1616/ 4910]\nloss: 0.614661  [ 3216/ 4910]\nloss: 0.614518  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655257 \n\nEpoch 285\n-------------------------------\nloss: 0.615296  [   16/ 4910]\nloss: 0.616107  [ 1616/ 4910]\nloss: 0.739604  [ 3216/ 4910]\nloss: 0.739366  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.675105 \n\nEpoch 286\n-------------------------------\nloss: 0.676284  [   16/ 4910]\nloss: 0.739182  [ 1616/ 4910]\nloss: 0.551514  [ 3216/ 4910]\nloss: 0.615270  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.663735 \n\nEpoch 287\n-------------------------------\nloss: 0.614721  [   16/ 4910]\nloss: 0.614438  [ 1616/ 4910]\nloss: 0.614303  [ 3216/ 4910]\nloss: 0.551585  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.7%, Avg loss: 0.667868 \n\nEpoch 288\n-------------------------------\nloss: 0.551667  [   16/ 4910]\nloss: 0.739092  [ 1616/ 4910]\nloss: 0.698585  [ 3216/ 4910]\nloss: 0.613978  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.662457 \n\nEpoch 289\n-------------------------------\nloss: 0.678363  [   16/ 4910]\nloss: 0.739802  [ 1616/ 4910]\nloss: 0.613988  [ 3216/ 4910]\nloss: 0.555078  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.663651 \n\nEpoch 290\n-------------------------------\nloss: 0.552090  [   16/ 4910]\nloss: 0.742322  [ 1616/ 4910]\nloss: 0.551711  [ 3216/ 4910]\nloss: 0.619973  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.654531 \n\nEpoch 291\n-------------------------------\nloss: 0.551540  [   16/ 4910]\nloss: 0.656274  [ 1616/ 4910]\nloss: 0.677967  [ 3216/ 4910]\nloss: 0.629439  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.670368 \n\nEpoch 292\n-------------------------------\nloss: 0.678410  [   16/ 4910]\nloss: 0.627234  [ 1616/ 4910]\nloss: 0.614048  [ 3216/ 4910]\nloss: 0.551481  [ 4816/ 4910]\nTest Error: \n Accuracy: 83.5%, Avg loss: 0.712506 \n\nEpoch 293\n-------------------------------\nloss: 0.791346  [   16/ 4910]\nloss: 0.692231  [ 1616/ 4910]\nloss: 0.614208  [ 3216/ 4910]\nloss: 0.623343  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.4%, Avg loss: 0.685550 \n\nEpoch 294\n-------------------------------\nloss: 0.650441  [   16/ 4910]\nloss: 0.614119  [ 1616/ 4910]\nloss: 0.614221  [ 3216/ 4910]\nloss: 0.676464  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.4%, Avg loss: 0.677347 \n\nEpoch 295\n-------------------------------\nloss: 0.552774  [   16/ 4910]\nloss: 0.615079  [ 1616/ 4910]\nloss: 0.551468  [ 3216/ 4910]\nloss: 0.641804  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655503 \n\nEpoch 296\n-------------------------------\nloss: 0.608311  [   16/ 4910]\nloss: 0.614119  [ 1616/ 4910]\nloss: 0.620396  [ 3216/ 4910]\nloss: 0.552812  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.654523 \n\nEpoch 297\n-------------------------------\nloss: 0.615345  [   16/ 4910]\nloss: 0.601157  [ 1616/ 4910]\nloss: 0.616479  [ 3216/ 4910]\nloss: 0.551561  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.675334 \n\nEpoch 298\n-------------------------------\nloss: 0.615195  [   16/ 4910]\nloss: 0.563369  [ 1616/ 4910]\nloss: 0.552995  [ 3216/ 4910]\nloss: 0.678737  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.667727 \n\nEpoch 299\n-------------------------------\nloss: 0.679375  [   16/ 4910]\nloss: 0.551788  [ 1616/ 4910]\nloss: 0.559818  [ 3216/ 4910]\nloss: 0.552706  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.6%, Avg loss: 0.672314 \n\nEpoch 300\n-------------------------------\nloss: 0.596017  [   16/ 4910]\nloss: 0.552767  [ 1616/ 4910]\nloss: 0.641761  [ 3216/ 4910]\nloss: 0.613995  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.663590 \n\nEpoch 301\n-------------------------------\nloss: 0.551472  [   16/ 4910]\nloss: 0.618563  [ 1616/ 4910]\nloss: 0.551724  [ 3216/ 4910]\nloss: 0.752367  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.661761 \n\nEpoch 302\n-------------------------------\nloss: 0.653689  [   16/ 4910]\nloss: 0.614313  [ 1616/ 4910]\nloss: 0.551498  [ 3216/ 4910]\nloss: 0.614949  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.7%, Avg loss: 0.664167 \n\nEpoch 303\n-------------------------------\nloss: 0.676464  [   16/ 4910]\nloss: 0.801074  [ 1616/ 4910]\nloss: 0.567833  [ 3216/ 4910]\nloss: 0.620195  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.7%, Avg loss: 0.678382 \n\nEpoch 304\n-------------------------------\nloss: 0.552982  [   16/ 4910]\nloss: 0.551677  [ 1616/ 4910]\nloss: 0.620353  [ 3216/ 4910]\nloss: 0.680835  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.650171 \n\nEpoch 305\n-------------------------------\nloss: 0.678655  [   16/ 4910]\nloss: 0.739286  [ 1616/ 4910]\nloss: 0.614186  [ 3216/ 4910]\nloss: 0.551481  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.667824 \n\nEpoch 306\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.709723  [ 1616/ 4910]\nloss: 0.551977  [ 3216/ 4910]\nloss: 0.677227  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.670865 \n\nEpoch 307\n-------------------------------\nloss: 0.614157  [   16/ 4910]\nloss: 0.613077  [ 1616/ 4910]\nloss: 0.619634  [ 3216/ 4910]\nloss: 0.551958  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.662443 \n\nEpoch 308\n-------------------------------\nloss: 0.635198  [   16/ 4910]\nloss: 0.555887  [ 1616/ 4910]\nloss: 0.738967  [ 3216/ 4910]\nloss: 0.801497  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.669857 \n\nEpoch 309\n-------------------------------\nloss: 0.680405  [   16/ 4910]\nloss: 0.556794  [ 1616/ 4910]\nloss: 0.741170  [ 3216/ 4910]\nloss: 0.743395  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.665108 \n\nEpoch 310\n-------------------------------\nloss: 0.551664  [   16/ 4910]\nloss: 0.676714  [ 1616/ 4910]\nloss: 0.739566  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.661339 \n\nEpoch 311\n-------------------------------\nloss: 0.551483  [   16/ 4910]\nloss: 0.551551  [ 1616/ 4910]\nloss: 0.742067  [ 3216/ 4910]\nloss: 0.677887  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660277 \n\nEpoch 312\n-------------------------------\nloss: 0.610043  [   16/ 4910]\nloss: 0.616263  [ 1616/ 4910]\nloss: 0.555324  [ 3216/ 4910]\nloss: 0.676466  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.660282 \n\nEpoch 313\n-------------------------------\nloss: 0.551671  [   16/ 4910]\nloss: 0.554762  [ 1616/ 4910]\nloss: 0.618217  [ 3216/ 4910]\nloss: 0.620300  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661771 \n\nEpoch 314\n-------------------------------\nloss: 0.621604  [   16/ 4910]\nloss: 0.551461  [ 1616/ 4910]\nloss: 0.802401  [ 3216/ 4910]\nloss: 0.689255  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.2%, Avg loss: 0.680301 \n\nEpoch 315\n-------------------------------\nloss: 0.614461  [   16/ 4910]\nloss: 0.559415  [ 1616/ 4910]\nloss: 0.552320  [ 3216/ 4910]\nloss: 0.665742  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.664219 \n\nEpoch 316\n-------------------------------\nloss: 0.614809  [   16/ 4910]\nloss: 0.552109  [ 1616/ 4910]\nloss: 0.613977  [ 3216/ 4910]\nloss: 0.613986  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.662480 \n\nEpoch 317\n-------------------------------\nloss: 0.738959  [   16/ 4910]\nloss: 0.614259  [ 1616/ 4910]\nloss: 0.677674  [ 3216/ 4910]\nloss: 0.614057  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658003 \n\nEpoch 318\n-------------------------------\nloss: 0.552881  [   16/ 4910]\nloss: 0.572134  [ 1616/ 4910]\nloss: 0.676783  [ 3216/ 4910]\nloss: 0.551539  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.6%, Avg loss: 0.671874 \n\nEpoch 319\n-------------------------------\nloss: 0.615597  [   16/ 4910]\nloss: 0.620334  [ 1616/ 4910]\nloss: 0.676775  [ 3216/ 4910]\nloss: 0.613953  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652758 \n\nEpoch 320\n-------------------------------\nloss: 0.614202  [   16/ 4910]\nloss: 0.616505  [ 1616/ 4910]\nloss: 0.614332  [ 3216/ 4910]\nloss: 0.552303  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661099 \n\nEpoch 321\n-------------------------------\nloss: 0.613982  [   16/ 4910]\nloss: 0.623241  [ 1616/ 4910]\nloss: 0.551570  [ 3216/ 4910]\nloss: 0.614290  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.660666 \n\nEpoch 322\n-------------------------------\nloss: 0.617133  [   16/ 4910]\nloss: 0.615743  [ 1616/ 4910]\nloss: 0.551477  [ 3216/ 4910]\nloss: 0.552199  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.661304 \n\nEpoch 323\n-------------------------------\nloss: 0.738959  [   16/ 4910]\nloss: 0.603405  [ 1616/ 4910]\nloss: 0.746992  [ 3216/ 4910]\nloss: 0.672771  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.670345 \n\nEpoch 324\n-------------------------------\nloss: 0.612481  [   16/ 4910]\nloss: 0.614054  [ 1616/ 4910]\nloss: 0.614145  [ 3216/ 4910]\nloss: 0.614030  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.659324 \n\nEpoch 325\n-------------------------------\nloss: 0.551759  [   16/ 4910]\nloss: 0.676461  [ 1616/ 4910]\nloss: 0.615793  [ 3216/ 4910]\nloss: 0.614358  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656144 \n\nEpoch 326\n-------------------------------\nloss: 0.676545  [   16/ 4910]\nloss: 0.676728  [ 1616/ 4910]\nloss: 0.551581  [ 3216/ 4910]\nloss: 0.551604  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.669329 \n\nEpoch 327\n-------------------------------\nloss: 0.614018  [   16/ 4910]\nloss: 0.608487  [ 1616/ 4910]\nloss: 0.614139  [ 3216/ 4910]\nloss: 0.676627  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649855 \n\nEpoch 328\n-------------------------------\nloss: 0.614121  [   16/ 4910]\nloss: 0.608889  [ 1616/ 4910]\nloss: 0.559027  [ 3216/ 4910]\nloss: 0.551600  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658832 \n\nEpoch 329\n-------------------------------\nloss: 0.614565  [   16/ 4910]\nloss: 0.615274  [ 1616/ 4910]\nloss: 0.627846  [ 3216/ 4910]\nloss: 0.553333  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.660073 \n\nEpoch 330\n-------------------------------\nloss: 0.615312  [   16/ 4910]\nloss: 0.704591  [ 1616/ 4910]\nloss: 0.614453  [ 3216/ 4910]\nloss: 0.614967  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659063 \n\nEpoch 331\n-------------------------------\nloss: 0.552616  [   16/ 4910]\nloss: 0.553011  [ 1616/ 4910]\nloss: 0.613824  [ 3216/ 4910]\nloss: 0.727870  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.4%, Avg loss: 0.676646 \n\nEpoch 332\n-------------------------------\nloss: 0.676452  [   16/ 4910]\nloss: 0.735177  [ 1616/ 4910]\nloss: 0.614752  [ 3216/ 4910]\nloss: 0.615910  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658860 \n\nEpoch 333\n-------------------------------\nloss: 0.677428  [   16/ 4910]\nloss: 0.632285  [ 1616/ 4910]\nloss: 0.561267  [ 3216/ 4910]\nloss: 0.676671  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.650325 \n\nEpoch 334\n-------------------------------\nloss: 0.738972  [   16/ 4910]\nloss: 0.552119  [ 1616/ 4910]\nloss: 0.552200  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.662815 \n\nEpoch 335\n-------------------------------\nloss: 0.551491  [   16/ 4910]\nloss: 0.739330  [ 1616/ 4910]\nloss: 0.615852  [ 3216/ 4910]\nloss: 0.677225  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.657039 \n\nEpoch 336\n-------------------------------\nloss: 0.619469  [   16/ 4910]\nloss: 0.676682  [ 1616/ 4910]\nloss: 0.614674  [ 3216/ 4910]\nloss: 0.552136  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.665704 \n\nEpoch 337\n-------------------------------\nloss: 0.614090  [   16/ 4910]\nloss: 0.682453  [ 1616/ 4910]\nloss: 0.673663  [ 3216/ 4910]\nloss: 0.551477  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658011 \n\nEpoch 338\n-------------------------------\nloss: 0.614638  [   16/ 4910]\nloss: 0.614672  [ 1616/ 4910]\nloss: 0.614135  [ 3216/ 4910]\nloss: 0.614247  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655009 \n\nEpoch 339\n-------------------------------\nloss: 0.614057  [   16/ 4910]\nloss: 0.614498  [ 1616/ 4910]\nloss: 0.614048  [ 3216/ 4910]\nloss: 0.615689  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651454 \n\nEpoch 340\n-------------------------------\nloss: 0.679154  [   16/ 4910]\nloss: 0.614323  [ 1616/ 4910]\nloss: 0.614624  [ 3216/ 4910]\nloss: 0.676610  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.661082 \n\nEpoch 341\n-------------------------------\nloss: 0.618103  [   16/ 4910]\nloss: 0.615679  [ 1616/ 4910]\nloss: 0.614023  [ 3216/ 4910]\nloss: 0.614528  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656795 \n\nEpoch 342\n-------------------------------\nloss: 0.614409  [   16/ 4910]\nloss: 0.676642  [ 1616/ 4910]\nloss: 0.615626  [ 3216/ 4910]\nloss: 0.564807  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661876 \n\nEpoch 343\n-------------------------------\nloss: 0.577160  [   16/ 4910]\nloss: 0.553500  [ 1616/ 4910]\nloss: 0.676445  [ 3216/ 4910]\nloss: 0.555101  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655062 \n\nEpoch 344\n-------------------------------\nloss: 0.613507  [   16/ 4910]\nloss: 0.613617  [ 1616/ 4910]\nloss: 0.551505  [ 3216/ 4910]\nloss: 0.676755  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.662491 \n\nEpoch 345\n-------------------------------\nloss: 0.613946  [   16/ 4910]\nloss: 0.614013  [ 1616/ 4910]\nloss: 0.554220  [ 3216/ 4910]\nloss: 0.613983  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.670657 \n\nEpoch 346\n-------------------------------\nloss: 0.738969  [   16/ 4910]\nloss: 0.617099  [ 1616/ 4910]\nloss: 0.551698  [ 3216/ 4910]\nloss: 0.676655  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660527 \n\nEpoch 347\n-------------------------------\nloss: 0.736790  [   16/ 4910]\nloss: 0.812766  [ 1616/ 4910]\nloss: 0.614324  [ 3216/ 4910]\nloss: 0.551875  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.654386 \n\nEpoch 348\n-------------------------------\nloss: 0.740454  [   16/ 4910]\nloss: 0.551713  [ 1616/ 4910]\nloss: 0.552589  [ 3216/ 4910]\nloss: 0.613967  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.8%, Avg loss: 0.673437 \n\nEpoch 349\n-------------------------------\nloss: 0.676379  [   16/ 4910]\nloss: 0.613983  [ 1616/ 4910]\nloss: 0.614845  [ 3216/ 4910]\nloss: 0.677089  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.655898 \n\nEpoch 350\n-------------------------------\nloss: 0.688953  [   16/ 4910]\nloss: 0.710212  [ 1616/ 4910]\nloss: 0.675171  [ 3216/ 4910]\nloss: 0.615104  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.665851 \n\nEpoch 351\n-------------------------------\nloss: 0.680013  [   16/ 4910]\nloss: 0.739137  [ 1616/ 4910]\nloss: 0.614426  [ 3216/ 4910]\nloss: 0.738998  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.665150 \n\nEpoch 352\n-------------------------------\nloss: 0.602259  [   16/ 4910]\nloss: 0.551593  [ 1616/ 4910]\nloss: 0.615077  [ 3216/ 4910]\nloss: 0.676929  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.670769 \n\nEpoch 353\n-------------------------------\nloss: 0.620291  [   16/ 4910]\nloss: 0.678934  [ 1616/ 4910]\nloss: 0.551488  [ 3216/ 4910]\nloss: 0.553194  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656382 \n\nEpoch 354\n-------------------------------\nloss: 0.614007  [   16/ 4910]\nloss: 0.614013  [ 1616/ 4910]\nloss: 0.613962  [ 3216/ 4910]\nloss: 0.614079  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654568 \n\nEpoch 355\n-------------------------------\nloss: 0.551554  [   16/ 4910]\nloss: 0.618479  [ 1616/ 4910]\nloss: 0.552228  [ 3216/ 4910]\nloss: 0.676566  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656606 \n\nEpoch 356\n-------------------------------\nloss: 0.614077  [   16/ 4910]\nloss: 0.676118  [ 1616/ 4910]\nloss: 0.676481  [ 3216/ 4910]\nloss: 0.676695  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.670160 \n\nEpoch 357\n-------------------------------\nloss: 0.614163  [   16/ 4910]\nloss: 0.551622  [ 1616/ 4910]\nloss: 0.749759  [ 3216/ 4910]\nloss: 0.614068  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.665454 \n\nEpoch 358\n-------------------------------\nloss: 0.564898  [   16/ 4910]\nloss: 0.614008  [ 1616/ 4910]\nloss: 0.552092  [ 3216/ 4910]\nloss: 0.552972  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.649723 \n\nEpoch 359\n-------------------------------\nloss: 0.614907  [   16/ 4910]\nloss: 0.551964  [ 1616/ 4910]\nloss: 0.614058  [ 3216/ 4910]\nloss: 0.614245  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.677664 \n\nEpoch 360\n-------------------------------\nloss: 0.647043  [   16/ 4910]\nloss: 0.615449  [ 1616/ 4910]\nloss: 0.739722  [ 3216/ 4910]\nloss: 0.614987  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.661496 \n\nEpoch 361\n-------------------------------\nloss: 0.679499  [   16/ 4910]\nloss: 0.554487  [ 1616/ 4910]\nloss: 0.553848  [ 3216/ 4910]\nloss: 0.551716  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654973 \n\nEpoch 362\n-------------------------------\nloss: 0.676614  [   16/ 4910]\nloss: 0.801459  [ 1616/ 4910]\nloss: 0.644988  [ 3216/ 4910]\nloss: 0.616577  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.670124 \n\nEpoch 363\n-------------------------------\nloss: 0.551480  [   16/ 4910]\nloss: 0.613995  [ 1616/ 4910]\nloss: 0.676550  [ 3216/ 4910]\nloss: 0.833853  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.4%, Avg loss: 0.692048 \n\nEpoch 364\n-------------------------------\nloss: 0.553132  [   16/ 4910]\nloss: 0.739849  [ 1616/ 4910]\nloss: 0.676720  [ 3216/ 4910]\nloss: 0.676445  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653945 \n\nEpoch 365\n-------------------------------\nloss: 0.621697  [   16/ 4910]\nloss: 0.633131  [ 1616/ 4910]\nloss: 0.551502  [ 3216/ 4910]\nloss: 0.613988  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661558 \n\nEpoch 366\n-------------------------------\nloss: 0.676573  [   16/ 4910]\nloss: 0.684650  [ 1616/ 4910]\nloss: 0.551481  [ 3216/ 4910]\nloss: 0.608649  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649598 \n\nEpoch 367\n-------------------------------\nloss: 0.613976  [   16/ 4910]\nloss: 0.614004  [ 1616/ 4910]\nloss: 0.682585  [ 3216/ 4910]\nloss: 0.554651  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654402 \n\nEpoch 368\n-------------------------------\nloss: 0.551757  [   16/ 4910]\nloss: 0.553168  [ 1616/ 4910]\nloss: 0.678361  [ 3216/ 4910]\nloss: 0.618365  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.658227 \n\nEpoch 369\n-------------------------------\nloss: 0.676552  [   16/ 4910]\nloss: 0.551495  [ 1616/ 4910]\nloss: 0.621589  [ 3216/ 4910]\nloss: 0.614128  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650194 \n\nEpoch 370\n-------------------------------\nloss: 0.739116  [   16/ 4910]\nloss: 0.614260  [ 1616/ 4910]\nloss: 0.551897  [ 3216/ 4910]\nloss: 0.551709  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656262 \n\nEpoch 371\n-------------------------------\nloss: 0.614747  [   16/ 4910]\nloss: 0.551517  [ 1616/ 4910]\nloss: 0.551674  [ 3216/ 4910]\nloss: 0.615426  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.660048 \n\nEpoch 372\n-------------------------------\nloss: 0.614477  [   16/ 4910]\nloss: 0.624657  [ 1616/ 4910]\nloss: 0.614030  [ 3216/ 4910]\nloss: 0.576176  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.659408 \n\nEpoch 373\n-------------------------------\nloss: 0.676471  [   16/ 4910]\nloss: 0.613997  [ 1616/ 4910]\nloss: 0.678137  [ 3216/ 4910]\nloss: 0.615811  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.669208 \n\nEpoch 374\n-------------------------------\nloss: 0.642908  [   16/ 4910]\nloss: 0.676542  [ 1616/ 4910]\nloss: 0.555930  [ 3216/ 4910]\nloss: 0.614025  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654360 \n\nEpoch 375\n-------------------------------\nloss: 0.615483  [   16/ 4910]\nloss: 0.676648  [ 1616/ 4910]\nloss: 0.552066  [ 3216/ 4910]\nloss: 0.677596  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651219 \n\nEpoch 376\n-------------------------------\nloss: 0.612354  [   16/ 4910]\nloss: 0.552435  [ 1616/ 4910]\nloss: 0.551623  [ 3216/ 4910]\nloss: 0.614003  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653833 \n\nEpoch 377\n-------------------------------\nloss: 0.676463  [   16/ 4910]\nloss: 0.647361  [ 1616/ 4910]\nloss: 0.581314  [ 3216/ 4910]\nloss: 0.614366  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.658288 \n\nEpoch 378\n-------------------------------\nloss: 0.557412  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.552603  [ 3216/ 4910]\nloss: 0.613993  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.657557 \n\nEpoch 379\n-------------------------------\nloss: 0.551456  [   16/ 4910]\nloss: 0.614050  [ 1616/ 4910]\nloss: 0.615954  [ 3216/ 4910]\nloss: 0.671759  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656800 \n\nEpoch 380\n-------------------------------\nloss: 0.614935  [   16/ 4910]\nloss: 0.678533  [ 1616/ 4910]\nloss: 0.614268  [ 3216/ 4910]\nloss: 0.613991  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654322 \n\nEpoch 381\n-------------------------------\nloss: 0.613993  [   16/ 4910]\nloss: 0.551617  [ 1616/ 4910]\nloss: 0.617174  [ 3216/ 4910]\nloss: 0.618699  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.662317 \n\nEpoch 382\n-------------------------------\nloss: 0.801510  [   16/ 4910]\nloss: 0.614027  [ 1616/ 4910]\nloss: 0.615598  [ 3216/ 4910]\nloss: 0.618275  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655636 \n\nEpoch 383\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.676695  [ 1616/ 4910]\nloss: 0.554615  [ 3216/ 4910]\nloss: 0.551633  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657888 \n\nEpoch 384\n-------------------------------\nloss: 0.613974  [   16/ 4910]\nloss: 0.614005  [ 1616/ 4910]\nloss: 0.613961  [ 3216/ 4910]\nloss: 0.614091  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.666928 \n\nEpoch 385\n-------------------------------\nloss: 0.623932  [   16/ 4910]\nloss: 0.676591  [ 1616/ 4910]\nloss: 0.553560  [ 3216/ 4910]\nloss: 0.676802  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659320 \n\nEpoch 386\n-------------------------------\nloss: 0.615025  [   16/ 4910]\nloss: 0.666956  [ 1616/ 4910]\nloss: 0.676705  [ 3216/ 4910]\nloss: 0.551465  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.665510 \n\nEpoch 387\n-------------------------------\nloss: 0.613976  [   16/ 4910]\nloss: 0.559581  [ 1616/ 4910]\nloss: 0.551574  [ 3216/ 4910]\nloss: 0.614813  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.658950 \n\nEpoch 388\n-------------------------------\nloss: 0.575208  [   16/ 4910]\nloss: 0.551668  [ 1616/ 4910]\nloss: 0.614627  [ 3216/ 4910]\nloss: 0.614004  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656537 \n\nEpoch 389\n-------------------------------\nloss: 0.552254  [   16/ 4910]\nloss: 0.611807  [ 1616/ 4910]\nloss: 0.614008  [ 3216/ 4910]\nloss: 0.622285  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.668706 \n\nEpoch 390\n-------------------------------\nloss: 0.676583  [   16/ 4910]\nloss: 0.615474  [ 1616/ 4910]\nloss: 0.614238  [ 3216/ 4910]\nloss: 0.551781  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650317 \n\nEpoch 391\n-------------------------------\nloss: 0.614250  [   16/ 4910]\nloss: 0.739021  [ 1616/ 4910]\nloss: 0.614628  [ 3216/ 4910]\nloss: 0.676911  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.646867 \n\nEpoch 392\n-------------------------------\nloss: 0.614308  [   16/ 4910]\nloss: 0.551562  [ 1616/ 4910]\nloss: 0.614370  [ 3216/ 4910]\nloss: 0.614083  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.659520 \n\nEpoch 393\n-------------------------------\nloss: 0.613968  [   16/ 4910]\nloss: 0.561819  [ 1616/ 4910]\nloss: 0.612873  [ 3216/ 4910]\nloss: 0.613985  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.657090 \n\nEpoch 394\n-------------------------------\nloss: 0.637437  [   16/ 4910]\nloss: 0.614217  [ 1616/ 4910]\nloss: 0.551550  [ 3216/ 4910]\nloss: 0.614002  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650200 \n\nEpoch 395\n-------------------------------\nloss: 0.676525  [   16/ 4910]\nloss: 0.677295  [ 1616/ 4910]\nloss: 0.614068  [ 3216/ 4910]\nloss: 0.614005  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.659973 \n\nEpoch 396\n-------------------------------\nloss: 0.738970  [   16/ 4910]\nloss: 0.676517  [ 1616/ 4910]\nloss: 0.599873  [ 3216/ 4910]\nloss: 0.615554  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652532 \n\nEpoch 397\n-------------------------------\nloss: 0.672530  [   16/ 4910]\nloss: 0.676464  [ 1616/ 4910]\nloss: 0.551459  [ 3216/ 4910]\nloss: 0.614075  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650533 \n\nEpoch 398\n-------------------------------\nloss: 0.551496  [   16/ 4910]\nloss: 0.614329  [ 1616/ 4910]\nloss: 0.676484  [ 3216/ 4910]\nloss: 0.614714  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655232 \n\nEpoch 399\n-------------------------------\nloss: 0.551459  [   16/ 4910]\nloss: 0.552018  [ 1616/ 4910]\nloss: 0.683134  [ 3216/ 4910]\nloss: 0.613990  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.653196 \n\nEpoch 400\n-------------------------------\nloss: 0.618510  [   16/ 4910]\nloss: 0.614098  [ 1616/ 4910]\nloss: 0.676610  [ 3216/ 4910]\nloss: 0.614015  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.658435 \n\nEpoch 401\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.614265  [ 1616/ 4910]\nloss: 0.676899  [ 3216/ 4910]\nloss: 0.613979  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.654526 \n\nEpoch 402\n-------------------------------\nloss: 0.613966  [   16/ 4910]\nloss: 0.551476  [ 1616/ 4910]\nloss: 0.613981  [ 3216/ 4910]\nloss: 0.676524  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.655709 \n\nEpoch 403\n-------------------------------\nloss: 0.676452  [   16/ 4910]\nloss: 0.551564  [ 1616/ 4910]\nloss: 0.551518  [ 3216/ 4910]\nloss: 0.613953  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655501 \n\nEpoch 404\n-------------------------------\nloss: 0.551563  [   16/ 4910]\nloss: 0.551557  [ 1616/ 4910]\nloss: 0.551456  [ 3216/ 4910]\nloss: 0.551514  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652977 \n\nEpoch 405\n-------------------------------\nloss: 0.677685  [   16/ 4910]\nloss: 0.614049  [ 1616/ 4910]\nloss: 0.614027  [ 3216/ 4910]\nloss: 0.747437  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.646615 \n\nEpoch 406\n-------------------------------\nloss: 0.614733  [   16/ 4910]\nloss: 0.615014  [ 1616/ 4910]\nloss: 0.613948  [ 3216/ 4910]\nloss: 0.559319  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.661994 \n\nEpoch 407\n-------------------------------\nloss: 0.552340  [   16/ 4910]\nloss: 0.676460  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.676608  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654581 \n\nEpoch 408\n-------------------------------\nloss: 0.676718  [   16/ 4910]\nloss: 0.617755  [ 1616/ 4910]\nloss: 0.551574  [ 3216/ 4910]\nloss: 0.614053  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655391 \n\nEpoch 409\n-------------------------------\nloss: 0.613685  [   16/ 4910]\nloss: 0.551460  [ 1616/ 4910]\nloss: 0.551750  [ 3216/ 4910]\nloss: 0.551597  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.662077 \n\nEpoch 410\n-------------------------------\nloss: 0.551687  [   16/ 4910]\nloss: 0.739068  [ 1616/ 4910]\nloss: 0.801554  [ 3216/ 4910]\nloss: 0.614640  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649751 \n\nEpoch 411\n-------------------------------\nloss: 0.676712  [   16/ 4910]\nloss: 0.677176  [ 1616/ 4910]\nloss: 0.551610  [ 3216/ 4910]\nloss: 0.551563  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652550 \n\nEpoch 412\n-------------------------------\nloss: 0.610721  [   16/ 4910]\nloss: 0.556585  [ 1616/ 4910]\nloss: 0.739125  [ 3216/ 4910]\nloss: 0.613960  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.664069 \n\nEpoch 413\n-------------------------------\nloss: 0.614029  [   16/ 4910]\nloss: 0.615138  [ 1616/ 4910]\nloss: 0.551500  [ 3216/ 4910]\nloss: 0.614754  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657575 \n\nEpoch 414\n-------------------------------\nloss: 0.608722  [   16/ 4910]\nloss: 0.551610  [ 1616/ 4910]\nloss: 0.615849  [ 3216/ 4910]\nloss: 0.676597  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651467 \n\nEpoch 415\n-------------------------------\nloss: 0.554444  [   16/ 4910]\nloss: 0.561510  [ 1616/ 4910]\nloss: 0.551837  [ 3216/ 4910]\nloss: 0.551480  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650397 \n\nEpoch 416\n-------------------------------\nloss: 0.738994  [   16/ 4910]\nloss: 0.551605  [ 1616/ 4910]\nloss: 0.562304  [ 3216/ 4910]\nloss: 0.676458  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652651 \n\nEpoch 417\n-------------------------------\nloss: 0.738947  [   16/ 4910]\nloss: 0.551600  [ 1616/ 4910]\nloss: 0.614015  [ 3216/ 4910]\nloss: 0.551486  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.651694 \n\nEpoch 418\n-------------------------------\nloss: 0.676078  [   16/ 4910]\nloss: 0.551588  [ 1616/ 4910]\nloss: 0.613960  [ 3216/ 4910]\nloss: 0.676488  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.660733 \n\nEpoch 419\n-------------------------------\nloss: 0.676573  [   16/ 4910]\nloss: 0.614280  [ 1616/ 4910]\nloss: 0.614809  [ 3216/ 4910]\nloss: 0.614002  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649926 \n\nEpoch 420\n-------------------------------\nloss: 0.613950  [   16/ 4910]\nloss: 0.672320  [ 1616/ 4910]\nloss: 0.613936  [ 3216/ 4910]\nloss: 0.613969  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652313 \n\nEpoch 421\n-------------------------------\nloss: 0.676465  [   16/ 4910]\nloss: 0.737009  [ 1616/ 4910]\nloss: 0.551544  [ 3216/ 4910]\nloss: 0.551470  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651162 \n\nEpoch 422\n-------------------------------\nloss: 0.614109  [   16/ 4910]\nloss: 0.676481  [ 1616/ 4910]\nloss: 0.551490  [ 3216/ 4910]\nloss: 0.551452  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650754 \n\nEpoch 423\n-------------------------------\nloss: 0.613963  [   16/ 4910]\nloss: 0.551520  [ 1616/ 4910]\nloss: 0.596969  [ 3216/ 4910]\nloss: 0.624288  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651467 \n\nEpoch 424\n-------------------------------\nloss: 0.551503  [   16/ 4910]\nloss: 0.552611  [ 1616/ 4910]\nloss: 0.613979  [ 3216/ 4910]\nloss: 0.553175  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651494 \n\nEpoch 425\n-------------------------------\nloss: 0.677177  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.614225  [ 3216/ 4910]\nloss: 0.676509  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654505 \n\nEpoch 426\n-------------------------------\nloss: 0.552001  [   16/ 4910]\nloss: 0.551475  [ 1616/ 4910]\nloss: 0.551508  [ 3216/ 4910]\nloss: 0.613955  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.649587 \n\nEpoch 427\n-------------------------------\nloss: 0.551584  [   16/ 4910]\nloss: 0.676455  [ 1616/ 4910]\nloss: 0.614007  [ 3216/ 4910]\nloss: 0.677981  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652990 \n\nEpoch 428\n-------------------------------\nloss: 0.611725  [   16/ 4910]\nloss: 0.613960  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.551487  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656972 \n\nEpoch 429\n-------------------------------\nloss: 0.615984  [   16/ 4910]\nloss: 0.617607  [ 1616/ 4910]\nloss: 0.739620  [ 3216/ 4910]\nloss: 0.551628  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652117 \n\nEpoch 430\n-------------------------------\nloss: 0.676488  [   16/ 4910]\nloss: 0.613964  [ 1616/ 4910]\nloss: 0.551462  [ 3216/ 4910]\nloss: 0.739664  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656636 \n\nEpoch 431\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.678201  [ 1616/ 4910]\nloss: 0.614154  [ 3216/ 4910]\nloss: 0.613978  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.659205 \n\nEpoch 432\n-------------------------------\nloss: 0.608921  [   16/ 4910]\nloss: 0.551578  [ 1616/ 4910]\nloss: 0.617364  [ 3216/ 4910]\nloss: 0.614584  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.654189 \n\nEpoch 433\n-------------------------------\nloss: 0.674104  [   16/ 4910]\nloss: 0.551736  [ 1616/ 4910]\nloss: 0.676449  [ 3216/ 4910]\nloss: 0.551589  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656045 \n\nEpoch 434\n-------------------------------\nloss: 0.555761  [   16/ 4910]\nloss: 0.672452  [ 1616/ 4910]\nloss: 0.676500  [ 3216/ 4910]\nloss: 0.614777  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.661871 \n\nEpoch 435\n-------------------------------\nloss: 0.638676  [   16/ 4910]\nloss: 0.555230  [ 1616/ 4910]\nloss: 0.676597  [ 3216/ 4910]\nloss: 0.864102  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.667717 \n\nEpoch 436\n-------------------------------\nloss: 0.677430  [   16/ 4910]\nloss: 0.615207  [ 1616/ 4910]\nloss: 0.559124  [ 3216/ 4910]\nloss: 0.676475  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.652074 \n\nEpoch 437\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.551513  [ 1616/ 4910]\nloss: 0.614000  [ 3216/ 4910]\nloss: 0.551550  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651617 \n\nEpoch 438\n-------------------------------\nloss: 0.801556  [   16/ 4910]\nloss: 0.676814  [ 1616/ 4910]\nloss: 0.629563  [ 3216/ 4910]\nloss: 0.676776  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.659510 \n\nEpoch 439\n-------------------------------\nloss: 0.638418  [   16/ 4910]\nloss: 0.551467  [ 1616/ 4910]\nloss: 0.679307  [ 3216/ 4910]\nloss: 0.614377  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.8%, Avg loss: 0.672048 \n\nEpoch 440\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.613959  [ 1616/ 4910]\nloss: 0.614042  [ 3216/ 4910]\nloss: 0.676452  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651683 \n\nEpoch 441\n-------------------------------\nloss: 0.551491  [   16/ 4910]\nloss: 0.676465  [ 1616/ 4910]\nloss: 0.613968  [ 3216/ 4910]\nloss: 0.614493  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649232 \n\nEpoch 442\n-------------------------------\nloss: 0.551555  [   16/ 4910]\nloss: 0.551534  [ 1616/ 4910]\nloss: 0.676657  [ 3216/ 4910]\nloss: 0.551460  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.1%, Avg loss: 0.669188 \n\nEpoch 443\n-------------------------------\nloss: 0.676830  [   16/ 4910]\nloss: 0.551543  [ 1616/ 4910]\nloss: 0.676490  [ 3216/ 4910]\nloss: 0.610036  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653967 \n\nEpoch 444\n-------------------------------\nloss: 0.551595  [   16/ 4910]\nloss: 0.631788  [ 1616/ 4910]\nloss: 0.551481  [ 3216/ 4910]\nloss: 0.553397  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.657966 \n\nEpoch 445\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.614623  [ 1616/ 4910]\nloss: 0.551534  [ 3216/ 4910]\nloss: 0.614370  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649020 \n\nEpoch 446\n-------------------------------\nloss: 0.614629  [   16/ 4910]\nloss: 0.614025  [ 1616/ 4910]\nloss: 0.657454  [ 3216/ 4910]\nloss: 0.551622  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654374 \n\nEpoch 447\n-------------------------------\nloss: 0.614119  [   16/ 4910]\nloss: 0.614010  [ 1616/ 4910]\nloss: 0.614072  [ 3216/ 4910]\nloss: 0.676456  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.650854 \n\nEpoch 448\n-------------------------------\nloss: 0.551481  [   16/ 4910]\nloss: 0.613975  [ 1616/ 4910]\nloss: 0.614014  [ 3216/ 4910]\nloss: 0.614115  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653090 \n\nEpoch 449\n-------------------------------\nloss: 0.551471  [   16/ 4910]\nloss: 0.614076  [ 1616/ 4910]\nloss: 0.551476  [ 3216/ 4910]\nloss: 0.676419  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650816 \n\nEpoch 450\n-------------------------------\nloss: 0.614102  [   16/ 4910]\nloss: 0.676638  [ 1616/ 4910]\nloss: 0.614421  [ 3216/ 4910]\nloss: 0.676476  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651108 \n\nEpoch 451\n-------------------------------\nloss: 0.608736  [   16/ 4910]\nloss: 0.614004  [ 1616/ 4910]\nloss: 0.676607  [ 3216/ 4910]\nloss: 0.614009  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648077 \n\nEpoch 452\n-------------------------------\nloss: 0.551534  [   16/ 4910]\nloss: 0.613975  [ 1616/ 4910]\nloss: 0.614005  [ 3216/ 4910]\nloss: 0.613972  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.657381 \n\nEpoch 453\n-------------------------------\nloss: 0.614049  [   16/ 4910]\nloss: 0.614079  [ 1616/ 4910]\nloss: 0.551790  [ 3216/ 4910]\nloss: 0.613982  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.655940 \n\nEpoch 454\n-------------------------------\nloss: 0.551473  [   16/ 4910]\nloss: 0.569438  [ 1616/ 4910]\nloss: 0.551491  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655170 \n\nEpoch 455\n-------------------------------\nloss: 0.613975  [   16/ 4910]\nloss: 0.676532  [ 1616/ 4910]\nloss: 0.551454  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653992 \n\nEpoch 456\n-------------------------------\nloss: 0.613991  [   16/ 4910]\nloss: 0.551910  [ 1616/ 4910]\nloss: 0.551464  [ 3216/ 4910]\nloss: 0.614197  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661500 \n\nEpoch 457\n-------------------------------\nloss: 0.551468  [   16/ 4910]\nloss: 0.551472  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.613950  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656933 \n\nEpoch 458\n-------------------------------\nloss: 0.676450  [   16/ 4910]\nloss: 0.676534  [ 1616/ 4910]\nloss: 0.613968  [ 3216/ 4910]\nloss: 0.613983  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654591 \n\nEpoch 459\n-------------------------------\nloss: 0.738995  [   16/ 4910]\nloss: 0.613951  [ 1616/ 4910]\nloss: 0.614162  [ 3216/ 4910]\nloss: 0.551630  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656510 \n\nEpoch 460\n-------------------------------\nloss: 0.551956  [   16/ 4910]\nloss: 0.551512  [ 1616/ 4910]\nloss: 0.613953  [ 3216/ 4910]\nloss: 0.552128  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650677 \n\nEpoch 461\n-------------------------------\nloss: 0.613989  [   16/ 4910]\nloss: 0.676457  [ 1616/ 4910]\nloss: 0.609117  [ 3216/ 4910]\nloss: 0.671365  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653565 \n\nEpoch 462\n-------------------------------\nloss: 0.551455  [   16/ 4910]\nloss: 0.676459  [ 1616/ 4910]\nloss: 0.613984  [ 3216/ 4910]\nloss: 0.672593  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655064 \n\nEpoch 463\n-------------------------------\nloss: 0.609324  [   16/ 4910]\nloss: 0.551451  [ 1616/ 4910]\nloss: 0.738974  [ 3216/ 4910]\nloss: 0.551638  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648271 \n\nEpoch 464\n-------------------------------\nloss: 0.676649  [   16/ 4910]\nloss: 0.738959  [ 1616/ 4910]\nloss: 0.613977  [ 3216/ 4910]\nloss: 0.613964  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650034 \n\nEpoch 465\n-------------------------------\nloss: 0.613970  [   16/ 4910]\nloss: 0.551821  [ 1616/ 4910]\nloss: 0.613978  [ 3216/ 4910]\nloss: 0.801452  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653616 \n\nEpoch 466\n-------------------------------\nloss: 0.614077  [   16/ 4910]\nloss: 0.677106  [ 1616/ 4910]\nloss: 0.614026  [ 3216/ 4910]\nloss: 0.615024  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651113 \n\nEpoch 467\n-------------------------------\nloss: 0.738954  [   16/ 4910]\nloss: 0.676492  [ 1616/ 4910]\nloss: 0.613983  [ 3216/ 4910]\nloss: 0.551459  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651164 \n\nEpoch 468\n-------------------------------\nloss: 0.614021  [   16/ 4910]\nloss: 0.613968  [ 1616/ 4910]\nloss: 0.609514  [ 3216/ 4910]\nloss: 0.676510  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.655306 \n\nEpoch 469\n-------------------------------\nloss: 0.551554  [   16/ 4910]\nloss: 0.676478  [ 1616/ 4910]\nloss: 0.614937  [ 3216/ 4910]\nloss: 0.551458  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653370 \n\nEpoch 470\n-------------------------------\nloss: 0.613954  [   16/ 4910]\nloss: 0.613953  [ 1616/ 4910]\nloss: 0.613962  [ 3216/ 4910]\nloss: 0.613549  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658031 \n\nEpoch 471\n-------------------------------\nloss: 0.863943  [   16/ 4910]\nloss: 0.551495  [ 1616/ 4910]\nloss: 0.614049  [ 3216/ 4910]\nloss: 0.551531  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648482 \n\nEpoch 472\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.614020  [ 1616/ 4910]\nloss: 0.551462  [ 3216/ 4910]\nloss: 0.614344  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649638 \n\nEpoch 473\n-------------------------------\nloss: 0.613951  [   16/ 4910]\nloss: 0.739016  [ 1616/ 4910]\nloss: 0.614006  [ 3216/ 4910]\nloss: 0.801449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650872 \n\nEpoch 474\n-------------------------------\nloss: 0.613972  [   16/ 4910]\nloss: 0.622575  [ 1616/ 4910]\nloss: 0.654520  [ 3216/ 4910]\nloss: 0.620384  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651211 \n\nEpoch 475\n-------------------------------\nloss: 0.677534  [   16/ 4910]\nloss: 0.613963  [ 1616/ 4910]\nloss: 0.614407  [ 3216/ 4910]\nloss: 0.613957  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651865 \n\nEpoch 476\n-------------------------------\nloss: 0.551466  [   16/ 4910]\nloss: 0.614084  [ 1616/ 4910]\nloss: 0.709140  [ 3216/ 4910]\nloss: 0.551485  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.3%, Avg loss: 0.667202 \n\nEpoch 477\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.733615  [ 1616/ 4910]\nloss: 0.614002  [ 3216/ 4910]\nloss: 0.616450  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652341 \n\nEpoch 478\n-------------------------------\nloss: 0.551482  [   16/ 4910]\nloss: 0.551593  [ 1616/ 4910]\nloss: 0.676447  [ 3216/ 4910]\nloss: 0.551463  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651149 \n\nEpoch 479\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.611180  [ 1616/ 4910]\nloss: 0.614069  [ 3216/ 4910]\nloss: 0.614008  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.652022 \n\nEpoch 480\n-------------------------------\nloss: 0.613962  [   16/ 4910]\nloss: 0.613983  [ 1616/ 4910]\nloss: 0.614048  [ 3216/ 4910]\nloss: 0.551511  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654045 \n\nEpoch 481\n-------------------------------\nloss: 0.609273  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.613981  [ 3216/ 4910]\nloss: 0.738984  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652849 \n\nEpoch 482\n-------------------------------\nloss: 0.614090  [   16/ 4910]\nloss: 0.551880  [ 1616/ 4910]\nloss: 0.613953  [ 3216/ 4910]\nloss: 0.551476  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652631 \n\nEpoch 483\n-------------------------------\nloss: 0.801476  [   16/ 4910]\nloss: 0.551535  [ 1616/ 4910]\nloss: 0.614201  [ 3216/ 4910]\nloss: 0.613991  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.652098 \n\nEpoch 484\n-------------------------------\nloss: 0.676481  [   16/ 4910]\nloss: 0.551471  [ 1616/ 4910]\nloss: 0.615532  [ 3216/ 4910]\nloss: 0.551520  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654103 \n\nEpoch 485\n-------------------------------\nloss: 0.551677  [   16/ 4910]\nloss: 0.613967  [ 1616/ 4910]\nloss: 0.676567  [ 3216/ 4910]\nloss: 0.551608  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653036 \n\nEpoch 486\n-------------------------------\nloss: 0.614111  [   16/ 4910]\nloss: 0.609403  [ 1616/ 4910]\nloss: 0.676564  [ 3216/ 4910]\nloss: 0.551539  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652625 \n\nEpoch 487\n-------------------------------\nloss: 0.676486  [   16/ 4910]\nloss: 0.614768  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.613996  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651728 \n\nEpoch 488\n-------------------------------\nloss: 0.613993  [   16/ 4910]\nloss: 0.614019  [ 1616/ 4910]\nloss: 0.551624  [ 3216/ 4910]\nloss: 0.799043  [ 4816/ 4910]\nTest Error: \n Accuracy: 86.7%, Avg loss: 0.681311 \n\nEpoch 489\n-------------------------------\nloss: 0.624020  [   16/ 4910]\nloss: 0.551627  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.613969  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651617 \n\nEpoch 490\n-------------------------------\nloss: 0.738986  [   16/ 4910]\nloss: 0.551588  [ 1616/ 4910]\nloss: 0.551678  [ 3216/ 4910]\nloss: 0.681174  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.693886 \n\nEpoch 491\n-------------------------------\nloss: 0.581659  [   16/ 4910]\nloss: 0.615132  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.676511  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.655731 \n\nEpoch 492\n-------------------------------\nloss: 0.676467  [   16/ 4910]\nloss: 0.676462  [ 1616/ 4910]\nloss: 0.551479  [ 3216/ 4910]\nloss: 0.551535  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652999 \n\nEpoch 493\n-------------------------------\nloss: 0.551567  [   16/ 4910]\nloss: 0.614013  [ 1616/ 4910]\nloss: 0.551523  [ 3216/ 4910]\nloss: 0.613960  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652986 \n\nEpoch 494\n-------------------------------\nloss: 0.671536  [   16/ 4910]\nloss: 0.613978  [ 1616/ 4910]\nloss: 0.613957  [ 3216/ 4910]\nloss: 0.676487  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653079 \n\nEpoch 495\n-------------------------------\nloss: 0.609196  [   16/ 4910]\nloss: 0.613949  [ 1616/ 4910]\nloss: 0.676584  [ 3216/ 4910]\nloss: 0.676492  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654121 \n\nEpoch 496\n-------------------------------\nloss: 0.551446  [   16/ 4910]\nloss: 0.614869  [ 1616/ 4910]\nloss: 0.676592  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.7%, Avg loss: 0.663373 \n\nEpoch 497\n-------------------------------\nloss: 0.551605  [   16/ 4910]\nloss: 0.551467  [ 1616/ 4910]\nloss: 0.676447  [ 3216/ 4910]\nloss: 0.552103  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658572 \n\nEpoch 498\n-------------------------------\nloss: 0.613970  [   16/ 4910]\nloss: 0.676504  [ 1616/ 4910]\nloss: 0.554251  [ 3216/ 4910]\nloss: 0.551505  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653822 \n\nEpoch 499\n-------------------------------\nloss: 0.552089  [   16/ 4910]\nloss: 0.551700  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.551472  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654951 \n\nEpoch 500\n-------------------------------\nloss: 0.551611  [   16/ 4910]\nloss: 0.613967  [ 1616/ 4910]\nloss: 0.614093  [ 3216/ 4910]\nloss: 0.613977  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651197 \n\nEpoch 501\n-------------------------------\nloss: 0.551679  [   16/ 4910]\nloss: 0.551520  [ 1616/ 4910]\nloss: 0.551524  [ 3216/ 4910]\nloss: 0.551552  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651388 \n\nEpoch 502\n-------------------------------\nloss: 0.551505  [   16/ 4910]\nloss: 0.551485  [ 1616/ 4910]\nloss: 0.801489  [ 3216/ 4910]\nloss: 0.597393  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653920 \n\nEpoch 503\n-------------------------------\nloss: 0.613959  [   16/ 4910]\nloss: 0.613989  [ 1616/ 4910]\nloss: 0.614007  [ 3216/ 4910]\nloss: 0.613980  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652416 \n\nEpoch 504\n-------------------------------\nloss: 0.738956  [   16/ 4910]\nloss: 0.551463  [ 1616/ 4910]\nloss: 0.676942  [ 3216/ 4910]\nloss: 0.676584  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.7%, Avg loss: 0.666863 \n\nEpoch 505\n-------------------------------\nloss: 0.745893  [   16/ 4910]\nloss: 0.613967  [ 1616/ 4910]\nloss: 0.551556  [ 3216/ 4910]\nloss: 0.613956  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.651182 \n\nEpoch 506\n-------------------------------\nloss: 0.613973  [   16/ 4910]\nloss: 0.738986  [ 1616/ 4910]\nloss: 0.551573  [ 3216/ 4910]\nloss: 0.552211  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657889 \n\nEpoch 507\n-------------------------------\nloss: 0.551574  [   16/ 4910]\nloss: 0.613950  [ 1616/ 4910]\nloss: 0.614013  [ 3216/ 4910]\nloss: 0.614068  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655059 \n\nEpoch 508\n-------------------------------\nloss: 0.676449  [   16/ 4910]\nloss: 0.551473  [ 1616/ 4910]\nloss: 0.552573  [ 3216/ 4910]\nloss: 0.676292  [ 4816/ 4910]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.695767 \n\nEpoch 509\n-------------------------------\nloss: 0.551847  [   16/ 4910]\nloss: 0.551563  [ 1616/ 4910]\nloss: 0.680999  [ 3216/ 4910]\nloss: 0.616125  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653259 \n\nEpoch 510\n-------------------------------\nloss: 0.551823  [   16/ 4910]\nloss: 0.613977  [ 1616/ 4910]\nloss: 0.614169  [ 3216/ 4910]\nloss: 0.613997  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.661974 \n\nEpoch 511\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.562612  [ 1616/ 4910]\nloss: 0.614695  [ 3216/ 4910]\nloss: 0.590744  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.675470 \n\nEpoch 512\n-------------------------------\nloss: 0.614119  [   16/ 4910]\nloss: 0.620382  [ 1616/ 4910]\nloss: 0.553565  [ 3216/ 4910]\nloss: 0.551480  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.652023 \n\nEpoch 513\n-------------------------------\nloss: 0.613988  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.551473  [ 3216/ 4910]\nloss: 0.629051  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.670835 \n\nEpoch 514\n-------------------------------\nloss: 0.676300  [   16/ 4910]\nloss: 0.551471  [ 1616/ 4910]\nloss: 0.614183  [ 3216/ 4910]\nloss: 0.676621  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.660128 \n\nEpoch 515\n-------------------------------\nloss: 0.551492  [   16/ 4910]\nloss: 0.551782  [ 1616/ 4910]\nloss: 0.614213  [ 3216/ 4910]\nloss: 0.614101  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650065 \n\nEpoch 516\n-------------------------------\nloss: 0.613960  [   16/ 4910]\nloss: 0.613441  [ 1616/ 4910]\nloss: 0.609084  [ 3216/ 4910]\nloss: 0.551468  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.658514 \n\nEpoch 517\n-------------------------------\nloss: 0.551476  [   16/ 4910]\nloss: 0.551568  [ 1616/ 4910]\nloss: 0.613686  [ 3216/ 4910]\nloss: 0.551735  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649908 \n\nEpoch 518\n-------------------------------\nloss: 0.551483  [   16/ 4910]\nloss: 0.551475  [ 1616/ 4910]\nloss: 0.551469  [ 3216/ 4910]\nloss: 0.552355  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651346 \n\nEpoch 519\n-------------------------------\nloss: 0.551485  [   16/ 4910]\nloss: 0.676468  [ 1616/ 4910]\nloss: 0.551621  [ 3216/ 4910]\nloss: 0.614009  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654918 \n\nEpoch 520\n-------------------------------\nloss: 0.609014  [   16/ 4910]\nloss: 0.551521  [ 1616/ 4910]\nloss: 0.738952  [ 3216/ 4910]\nloss: 0.551528  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.653085 \n\nEpoch 521\n-------------------------------\nloss: 0.614359  [   16/ 4910]\nloss: 0.613979  [ 1616/ 4910]\nloss: 0.613958  [ 3216/ 4910]\nloss: 0.551480  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653255 \n\nEpoch 522\n-------------------------------\nloss: 0.613960  [   16/ 4910]\nloss: 0.551560  [ 1616/ 4910]\nloss: 0.614048  [ 3216/ 4910]\nloss: 0.738982  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652144 \n\nEpoch 523\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.676440  [ 3216/ 4910]\nloss: 0.614004  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652421 \n\nEpoch 524\n-------------------------------\nloss: 0.551480  [   16/ 4910]\nloss: 0.676518  [ 1616/ 4910]\nloss: 0.676456  [ 3216/ 4910]\nloss: 0.551466  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.654485 \n\nEpoch 525\n-------------------------------\nloss: 0.676462  [   16/ 4910]\nloss: 0.551505  [ 1616/ 4910]\nloss: 0.614156  [ 3216/ 4910]\nloss: 0.551451  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655393 \n\nEpoch 526\n-------------------------------\nloss: 0.614127  [   16/ 4910]\nloss: 0.551679  [ 1616/ 4910]\nloss: 0.613956  [ 3216/ 4910]\nloss: 0.614605  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.648089 \n\nEpoch 527\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.613985  [ 1616/ 4910]\nloss: 0.676464  [ 3216/ 4910]\nloss: 0.676516  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650140 \n\nEpoch 528\n-------------------------------\nloss: 0.551451  [   16/ 4910]\nloss: 0.614066  [ 1616/ 4910]\nloss: 0.614018  [ 3216/ 4910]\nloss: 0.551501  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650240 \n\nEpoch 529\n-------------------------------\nloss: 0.551678  [   16/ 4910]\nloss: 0.551552  [ 1616/ 4910]\nloss: 0.613983  [ 3216/ 4910]\nloss: 0.676884  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651778 \n\nEpoch 530\n-------------------------------\nloss: 0.551531  [   16/ 4910]\nloss: 0.551486  [ 1616/ 4910]\nloss: 0.551536  [ 3216/ 4910]\nloss: 0.801528  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649756 \n\nEpoch 531\n-------------------------------\nloss: 0.551488  [   16/ 4910]\nloss: 0.738972  [ 1616/ 4910]\nloss: 0.551981  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650954 \n\nEpoch 532\n-------------------------------\nloss: 0.670873  [   16/ 4910]\nloss: 0.676449  [ 1616/ 4910]\nloss: 0.551696  [ 3216/ 4910]\nloss: 0.551490  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650457 \n\nEpoch 533\n-------------------------------\nloss: 0.676436  [   16/ 4910]\nloss: 0.614135  [ 1616/ 4910]\nloss: 0.551465  [ 3216/ 4910]\nloss: 0.739108  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652242 \n\nEpoch 534\n-------------------------------\nloss: 0.614038  [   16/ 4910]\nloss: 0.551474  [ 1616/ 4910]\nloss: 0.613956  [ 3216/ 4910]\nloss: 0.745206  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660120 \n\nEpoch 535\n-------------------------------\nloss: 0.551649  [   16/ 4910]\nloss: 0.551575  [ 1616/ 4910]\nloss: 0.551611  [ 3216/ 4910]\nloss: 0.737961  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653188 \n\nEpoch 536\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.676895  [ 1616/ 4910]\nloss: 0.614044  [ 3216/ 4910]\nloss: 0.551982  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.647827 \n\nEpoch 537\n-------------------------------\nloss: 0.739119  [   16/ 4910]\nloss: 0.672786  [ 1616/ 4910]\nloss: 0.614025  [ 3216/ 4910]\nloss: 0.613957  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658007 \n\nEpoch 538\n-------------------------------\nloss: 0.551799  [   16/ 4910]\nloss: 0.562097  [ 1616/ 4910]\nloss: 0.801500  [ 3216/ 4910]\nloss: 0.551457  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.659829 \n\nEpoch 539\n-------------------------------\nloss: 0.613965  [   16/ 4910]\nloss: 0.613966  [ 1616/ 4910]\nloss: 0.676453  [ 3216/ 4910]\nloss: 0.551531  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650268 \n\nEpoch 540\n-------------------------------\nloss: 0.551502  [   16/ 4910]\nloss: 0.551450  [ 1616/ 4910]\nloss: 0.676488  [ 3216/ 4910]\nloss: 0.614573  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655204 \n\nEpoch 541\n-------------------------------\nloss: 0.551592  [   16/ 4910]\nloss: 0.613960  [ 1616/ 4910]\nloss: 0.551553  [ 3216/ 4910]\nloss: 0.551542  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648409 \n\nEpoch 542\n-------------------------------\nloss: 0.551555  [   16/ 4910]\nloss: 0.613981  [ 1616/ 4910]\nloss: 0.589905  [ 3216/ 4910]\nloss: 0.614374  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660873 \n\nEpoch 543\n-------------------------------\nloss: 0.676682  [   16/ 4910]\nloss: 0.616256  [ 1616/ 4910]\nloss: 0.627472  [ 3216/ 4910]\nloss: 0.551595  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655431 \n\nEpoch 544\n-------------------------------\nloss: 0.552471  [   16/ 4910]\nloss: 0.613962  [ 1616/ 4910]\nloss: 0.613959  [ 3216/ 4910]\nloss: 0.613995  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656822 \n\nEpoch 545\n-------------------------------\nloss: 0.676478  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.613975  [ 3216/ 4910]\nloss: 0.676506  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649154 \n\nEpoch 546\n-------------------------------\nloss: 0.614091  [   16/ 4910]\nloss: 0.551447  [ 1616/ 4910]\nloss: 0.614226  [ 3216/ 4910]\nloss: 0.614199  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648988 \n\nEpoch 547\n-------------------------------\nloss: 0.676494  [   16/ 4910]\nloss: 0.551825  [ 1616/ 4910]\nloss: 0.551469  [ 3216/ 4910]\nloss: 0.613988  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649252 \n\nEpoch 548\n-------------------------------\nloss: 0.738957  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.676424  [ 3216/ 4910]\nloss: 0.613967  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649651 \n\nEpoch 549\n-------------------------------\nloss: 0.551498  [   16/ 4910]\nloss: 0.614030  [ 1616/ 4910]\nloss: 0.613998  [ 3216/ 4910]\nloss: 0.551522  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648911 \n\nEpoch 550\n-------------------------------\nloss: 0.551506  [   16/ 4910]\nloss: 0.676458  [ 1616/ 4910]\nloss: 0.676475  [ 3216/ 4910]\nloss: 0.738959  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651030 \n\nEpoch 551\n-------------------------------\nloss: 0.858498  [   16/ 4910]\nloss: 0.676465  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.643831  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653958 \n\nEpoch 552\n-------------------------------\nloss: 0.551459  [   16/ 4910]\nloss: 0.735473  [ 1616/ 4910]\nloss: 0.734979  [ 3216/ 4910]\nloss: 0.575232  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655052 \n\nEpoch 553\n-------------------------------\nloss: 0.614003  [   16/ 4910]\nloss: 0.551567  [ 1616/ 4910]\nloss: 0.739466  [ 3216/ 4910]\nloss: 0.614017  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654770 \n\nEpoch 554\n-------------------------------\nloss: 0.614340  [   16/ 4910]\nloss: 0.551597  [ 1616/ 4910]\nloss: 0.613980  [ 3216/ 4910]\nloss: 0.738983  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.658727 \n\nEpoch 555\n-------------------------------\nloss: 0.613962  [   16/ 4910]\nloss: 0.738950  [ 1616/ 4910]\nloss: 0.613989  [ 3216/ 4910]\nloss: 0.613986  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654750 \n\nEpoch 556\n-------------------------------\nloss: 0.676498  [   16/ 4910]\nloss: 0.614105  [ 1616/ 4910]\nloss: 0.676643  [ 3216/ 4910]\nloss: 0.676583  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652457 \n\nEpoch 557\n-------------------------------\nloss: 0.614041  [   16/ 4910]\nloss: 0.676500  [ 1616/ 4910]\nloss: 0.551469  [ 3216/ 4910]\nloss: 0.551590  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653568 \n\nEpoch 558\n-------------------------------\nloss: 0.614168  [   16/ 4910]\nloss: 0.614002  [ 1616/ 4910]\nloss: 0.676457  [ 3216/ 4910]\nloss: 0.552358  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.652468 \n\nEpoch 559\n-------------------------------\nloss: 0.552140  [   16/ 4910]\nloss: 0.551463  [ 1616/ 4910]\nloss: 0.551483  [ 3216/ 4910]\nloss: 0.613998  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.654720 \n\nEpoch 560\n-------------------------------\nloss: 0.613991  [   16/ 4910]\nloss: 0.614143  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.735060  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649771 \n\nEpoch 561\n-------------------------------\nloss: 0.551474  [   16/ 4910]\nloss: 0.551596  [ 1616/ 4910]\nloss: 0.613972  [ 3216/ 4910]\nloss: 0.713406  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655531 \n\nEpoch 562\n-------------------------------\nloss: 0.551967  [   16/ 4910]\nloss: 0.676488  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.676457  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.656184 \n\nEpoch 563\n-------------------------------\nloss: 0.551450  [   16/ 4910]\nloss: 0.551451  [ 1616/ 4910]\nloss: 0.676456  [ 3216/ 4910]\nloss: 0.614010  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653090 \n\nEpoch 564\n-------------------------------\nloss: 0.551481  [   16/ 4910]\nloss: 0.663046  [ 1616/ 4910]\nloss: 0.747235  [ 3216/ 4910]\nloss: 0.676610  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.658251 \n\nEpoch 565\n-------------------------------\nloss: 0.676586  [   16/ 4910]\nloss: 0.551478  [ 1616/ 4910]\nloss: 0.614156  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655031 \n\nEpoch 566\n-------------------------------\nloss: 0.554455  [   16/ 4910]\nloss: 0.739542  [ 1616/ 4910]\nloss: 0.674962  [ 3216/ 4910]\nloss: 0.615453  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658163 \n\nEpoch 567\n-------------------------------\nloss: 0.614034  [   16/ 4910]\nloss: 0.551470  [ 1616/ 4910]\nloss: 0.665690  [ 3216/ 4910]\nloss: 0.551446  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656774 \n\nEpoch 568\n-------------------------------\nloss: 0.676516  [   16/ 4910]\nloss: 0.551453  [ 1616/ 4910]\nloss: 0.551467  [ 3216/ 4910]\nloss: 0.551959  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.652514 \n\nEpoch 569\n-------------------------------\nloss: 0.614095  [   16/ 4910]\nloss: 0.671688  [ 1616/ 4910]\nloss: 0.552277  [ 3216/ 4910]\nloss: 0.613970  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.663703 \n\nEpoch 570\n-------------------------------\nloss: 0.551446  [   16/ 4910]\nloss: 0.614257  [ 1616/ 4910]\nloss: 0.551490  [ 3216/ 4910]\nloss: 0.676494  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.652903 \n\nEpoch 571\n-------------------------------\nloss: 0.676680  [   16/ 4910]\nloss: 0.613985  [ 1616/ 4910]\nloss: 0.551517  [ 3216/ 4910]\nloss: 0.676506  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.657014 \n\nEpoch 572\n-------------------------------\nloss: 0.553635  [   16/ 4910]\nloss: 0.551523  [ 1616/ 4910]\nloss: 0.613974  [ 3216/ 4910]\nloss: 0.614150  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657651 \n\nEpoch 573\n-------------------------------\nloss: 0.551536  [   16/ 4910]\nloss: 0.676889  [ 1616/ 4910]\nloss: 0.614344  [ 3216/ 4910]\nloss: 0.551614  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656579 \n\nEpoch 574\n-------------------------------\nloss: 0.551459  [   16/ 4910]\nloss: 0.551876  [ 1616/ 4910]\nloss: 0.613998  [ 3216/ 4910]\nloss: 0.560535  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660354 \n\nEpoch 575\n-------------------------------\nloss: 0.614624  [   16/ 4910]\nloss: 0.737353  [ 1616/ 4910]\nloss: 0.578781  [ 3216/ 4910]\nloss: 0.616735  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652557 \n\nEpoch 576\n-------------------------------\nloss: 0.675405  [   16/ 4910]\nloss: 0.615737  [ 1616/ 4910]\nloss: 0.613992  [ 3216/ 4910]\nloss: 0.551535  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650445 \n\nEpoch 577\n-------------------------------\nloss: 0.553236  [   16/ 4910]\nloss: 0.614051  [ 1616/ 4910]\nloss: 0.613958  [ 3216/ 4910]\nloss: 0.614966  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656141 \n\nEpoch 578\n-------------------------------\nloss: 0.551577  [   16/ 4910]\nloss: 0.551502  [ 1616/ 4910]\nloss: 0.551479  [ 3216/ 4910]\nloss: 0.739057  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.660314 \n\nEpoch 579\n-------------------------------\nloss: 0.613954  [   16/ 4910]\nloss: 0.613992  [ 1616/ 4910]\nloss: 0.551480  [ 3216/ 4910]\nloss: 0.551579  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653986 \n\nEpoch 580\n-------------------------------\nloss: 0.551493  [   16/ 4910]\nloss: 0.614067  [ 1616/ 4910]\nloss: 0.614031  [ 3216/ 4910]\nloss: 0.552279  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649656 \n\nEpoch 581\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.614137  [ 1616/ 4910]\nloss: 0.551494  [ 3216/ 4910]\nloss: 0.551465  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.650230 \n\nEpoch 582\n-------------------------------\nloss: 0.614012  [   16/ 4910]\nloss: 0.551458  [ 1616/ 4910]\nloss: 0.735198  [ 3216/ 4910]\nloss: 0.551493  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.649711 \n\nEpoch 583\n-------------------------------\nloss: 0.734598  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.551482  [ 3216/ 4910]\nloss: 0.551474  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650669 \n\nEpoch 584\n-------------------------------\nloss: 0.614116  [   16/ 4910]\nloss: 0.676364  [ 1616/ 4910]\nloss: 0.551532  [ 3216/ 4910]\nloss: 0.614786  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651394 \n\nEpoch 585\n-------------------------------\nloss: 0.632768  [   16/ 4910]\nloss: 0.614006  [ 1616/ 4910]\nloss: 0.614297  [ 3216/ 4910]\nloss: 0.551458  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654107 \n\nEpoch 586\n-------------------------------\nloss: 0.672854  [   16/ 4910]\nloss: 0.614675  [ 1616/ 4910]\nloss: 0.614030  [ 3216/ 4910]\nloss: 0.613995  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.647268 \n\nEpoch 587\n-------------------------------\nloss: 0.551556  [   16/ 4910]\nloss: 0.551657  [ 1616/ 4910]\nloss: 0.613998  [ 3216/ 4910]\nloss: 0.566642  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653366 \n\nEpoch 588\n-------------------------------\nloss: 0.614909  [   16/ 4910]\nloss: 0.613961  [ 1616/ 4910]\nloss: 0.556824  [ 3216/ 4910]\nloss: 0.735901  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.649834 \n\nEpoch 589\n-------------------------------\nloss: 0.738986  [   16/ 4910]\nloss: 0.675132  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.554090  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.9%, Avg loss: 0.670907 \n\nEpoch 590\n-------------------------------\nloss: 0.611092  [   16/ 4910]\nloss: 0.617741  [ 1616/ 4910]\nloss: 0.551625  [ 3216/ 4910]\nloss: 0.551476  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.657690 \n\nEpoch 591\n-------------------------------\nloss: 0.551539  [   16/ 4910]\nloss: 0.613972  [ 1616/ 4910]\nloss: 0.551501  [ 3216/ 4910]\nloss: 0.614074  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646743 \n\nEpoch 592\n-------------------------------\nloss: 0.551540  [   16/ 4910]\nloss: 0.673712  [ 1616/ 4910]\nloss: 0.551974  [ 3216/ 4910]\nloss: 0.674505  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651763 \n\nEpoch 593\n-------------------------------\nloss: 0.551484  [   16/ 4910]\nloss: 0.613977  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.614115  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646951 \n\nEpoch 594\n-------------------------------\nloss: 0.813313  [   16/ 4910]\nloss: 0.614026  [ 1616/ 4910]\nloss: 0.614345  [ 3216/ 4910]\nloss: 0.608641  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652464 \n\nEpoch 595\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.676455  [ 3216/ 4910]\nloss: 0.613983  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650235 \n\nEpoch 596\n-------------------------------\nloss: 0.676452  [   16/ 4910]\nloss: 0.613964  [ 1616/ 4910]\nloss: 0.551624  [ 3216/ 4910]\nloss: 0.613992  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651802 \n\nEpoch 597\n-------------------------------\nloss: 0.676517  [   16/ 4910]\nloss: 0.613990  [ 1616/ 4910]\nloss: 0.676467  [ 3216/ 4910]\nloss: 0.614024  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653558 \n\nEpoch 598\n-------------------------------\nloss: 0.551466  [   16/ 4910]\nloss: 0.614193  [ 1616/ 4910]\nloss: 0.613962  [ 3216/ 4910]\nloss: 0.613614  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653344 \n\nEpoch 599\n-------------------------------\nloss: 0.676770  [   16/ 4910]\nloss: 0.613969  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.801500  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656580 \n\nEpoch 600\n-------------------------------\nloss: 0.613962  [   16/ 4910]\nloss: 0.676517  [ 1616/ 4910]\nloss: 0.551636  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.659339 \n\nEpoch 601\n-------------------------------\nloss: 0.739685  [   16/ 4910]\nloss: 0.614000  [ 1616/ 4910]\nloss: 0.613971  [ 3216/ 4910]\nloss: 0.551532  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653101 \n\nEpoch 602\n-------------------------------\nloss: 0.551467  [   16/ 4910]\nloss: 0.551487  [ 1616/ 4910]\nloss: 0.552868  [ 3216/ 4910]\nloss: 0.676570  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.647105 \n\nEpoch 603\n-------------------------------\nloss: 0.551616  [   16/ 4910]\nloss: 0.613985  [ 1616/ 4910]\nloss: 0.555537  [ 3216/ 4910]\nloss: 0.614017  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651278 \n\nEpoch 604\n-------------------------------\nloss: 0.613951  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.613985  [ 3216/ 4910]\nloss: 0.676743  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648020 \n\nEpoch 605\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.613993  [ 1616/ 4910]\nloss: 0.670848  [ 3216/ 4910]\nloss: 0.614030  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.647812 \n\nEpoch 606\n-------------------------------\nloss: 0.551478  [   16/ 4910]\nloss: 0.738946  [ 1616/ 4910]\nloss: 0.676461  [ 3216/ 4910]\nloss: 0.555220  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651298 \n\nEpoch 607\n-------------------------------\nloss: 0.552014  [   16/ 4910]\nloss: 0.551537  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.676461  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651876 \n\nEpoch 608\n-------------------------------\nloss: 0.551486  [   16/ 4910]\nloss: 0.614102  [ 1616/ 4910]\nloss: 0.551703  [ 3216/ 4910]\nloss: 0.551453  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651874 \n\nEpoch 609\n-------------------------------\nloss: 0.614037  [   16/ 4910]\nloss: 0.614005  [ 1616/ 4910]\nloss: 0.551462  [ 3216/ 4910]\nloss: 0.553162  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655408 \n\nEpoch 610\n-------------------------------\nloss: 0.551516  [   16/ 4910]\nloss: 0.614078  [ 1616/ 4910]\nloss: 0.677934  [ 3216/ 4910]\nloss: 0.614098  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654028 \n\nEpoch 611\n-------------------------------\nloss: 0.551702  [   16/ 4910]\nloss: 0.672082  [ 1616/ 4910]\nloss: 0.614028  [ 3216/ 4910]\nloss: 0.551507  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650319 \n\nEpoch 612\n-------------------------------\nloss: 0.739147  [   16/ 4910]\nloss: 0.676452  [ 1616/ 4910]\nloss: 0.614030  [ 3216/ 4910]\nloss: 0.551542  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651428 \n\nEpoch 613\n-------------------------------\nloss: 0.613959  [   16/ 4910]\nloss: 0.551919  [ 1616/ 4910]\nloss: 0.614148  [ 3216/ 4910]\nloss: 0.614088  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647273 \n\nEpoch 614\n-------------------------------\nloss: 0.676482  [   16/ 4910]\nloss: 0.614425  [ 1616/ 4910]\nloss: 0.676475  [ 3216/ 4910]\nloss: 0.738950  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653286 \n\nEpoch 615\n-------------------------------\nloss: 0.551451  [   16/ 4910]\nloss: 0.613973  [ 1616/ 4910]\nloss: 0.551607  [ 3216/ 4910]\nloss: 0.551907  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648524 \n\nEpoch 616\n-------------------------------\nloss: 0.614026  [   16/ 4910]\nloss: 0.801452  [ 1616/ 4910]\nloss: 0.676538  [ 3216/ 4910]\nloss: 0.613964  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649578 \n\nEpoch 617\n-------------------------------\nloss: 0.609057  [   16/ 4910]\nloss: 0.614028  [ 1616/ 4910]\nloss: 0.551576  [ 3216/ 4910]\nloss: 0.551591  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.650890 \n\nEpoch 618\n-------------------------------\nloss: 0.552828  [   16/ 4910]\nloss: 0.613992  [ 1616/ 4910]\nloss: 0.738947  [ 3216/ 4910]\nloss: 0.608834  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.659685 \n\nEpoch 619\n-------------------------------\nloss: 0.636120  [   16/ 4910]\nloss: 0.613960  [ 1616/ 4910]\nloss: 0.551456  [ 3216/ 4910]\nloss: 0.614054  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652246 \n\nEpoch 620\n-------------------------------\nloss: 0.738886  [   16/ 4910]\nloss: 0.614008  [ 1616/ 4910]\nloss: 0.676566  [ 3216/ 4910]\nloss: 0.609512  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650713 \n\nEpoch 621\n-------------------------------\nloss: 0.676467  [   16/ 4910]\nloss: 0.614176  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.613983  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.648254 \n\nEpoch 622\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.736629  [ 1616/ 4910]\nloss: 0.551533  [ 3216/ 4910]\nloss: 0.551546  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649097 \n\nEpoch 623\n-------------------------------\nloss: 0.551450  [   16/ 4910]\nloss: 0.613984  [ 1616/ 4910]\nloss: 0.613969  [ 3216/ 4910]\nloss: 0.551452  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.647684 \n\nEpoch 624\n-------------------------------\nloss: 0.551835  [   16/ 4910]\nloss: 0.613959  [ 1616/ 4910]\nloss: 0.551476  [ 3216/ 4910]\nloss: 0.553484  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.648454 \n\nEpoch 625\n-------------------------------\nloss: 0.615631  [   16/ 4910]\nloss: 0.551458  [ 1616/ 4910]\nloss: 0.609175  [ 3216/ 4910]\nloss: 0.608239  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652423 \n\nEpoch 626\n-------------------------------\nloss: 0.564581  [   16/ 4910]\nloss: 0.552533  [ 1616/ 4910]\nloss: 0.614332  [ 3216/ 4910]\nloss: 0.613976  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649585 \n\nEpoch 627\n-------------------------------\nloss: 0.613988  [   16/ 4910]\nloss: 0.551455  [ 1616/ 4910]\nloss: 0.551698  [ 3216/ 4910]\nloss: 0.614226  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.646252 \n\nEpoch 628\n-------------------------------\nloss: 0.551460  [   16/ 4910]\nloss: 0.551479  [ 1616/ 4910]\nloss: 0.551452  [ 3216/ 4910]\nloss: 0.613954  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.649931 \n\nEpoch 629\n-------------------------------\nloss: 0.551493  [   16/ 4910]\nloss: 0.614028  [ 1616/ 4910]\nloss: 0.613952  [ 3216/ 4910]\nloss: 0.676515  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.7%, Avg loss: 0.643655 \n\nEpoch 630\n-------------------------------\nloss: 0.733356  [   16/ 4910]\nloss: 0.614005  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.551488  [ 4816/ 4910]\nTest Error: \n Accuracy: 91.0%, Avg loss: 0.642614 \n\nEpoch 631\n-------------------------------\nloss: 0.552954  [   16/ 4910]\nloss: 0.551460  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.551464  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.666717 \n\nEpoch 632\n-------------------------------\nloss: 0.676448  [   16/ 4910]\nloss: 0.552141  [ 1616/ 4910]\nloss: 0.551539  [ 3216/ 4910]\nloss: 0.551550  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646876 \n\nEpoch 633\n-------------------------------\nloss: 0.613980  [   16/ 4910]\nloss: 0.614056  [ 1616/ 4910]\nloss: 0.613971  [ 3216/ 4910]\nloss: 0.614057  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647805 \n\nEpoch 634\n-------------------------------\nloss: 0.739073  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.613995  [ 3216/ 4910]\nloss: 0.613956  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646617 \n\nEpoch 635\n-------------------------------\nloss: 0.551665  [   16/ 4910]\nloss: 0.614723  [ 1616/ 4910]\nloss: 0.613968  [ 3216/ 4910]\nloss: 0.613959  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649280 \n\nEpoch 636\n-------------------------------\nloss: 0.613981  [   16/ 4910]\nloss: 0.738945  [ 1616/ 4910]\nloss: 0.551673  [ 3216/ 4910]\nloss: 0.552008  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.645847 \n\nEpoch 637\n-------------------------------\nloss: 0.552373  [   16/ 4910]\nloss: 0.613975  [ 1616/ 4910]\nloss: 0.676563  [ 3216/ 4910]\nloss: 0.613968  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649900 \n\nEpoch 638\n-------------------------------\nloss: 0.613991  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.551487  [ 3216/ 4910]\nloss: 0.614183  [ 4816/ 4910]\nTest Error: \n Accuracy: 87.5%, Avg loss: 0.676140 \n\nEpoch 639\n-------------------------------\nloss: 0.551455  [   16/ 4910]\nloss: 0.552533  [ 1616/ 4910]\nloss: 0.614996  [ 3216/ 4910]\nloss: 0.613989  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653150 \n\nEpoch 640\n-------------------------------\nloss: 0.614008  [   16/ 4910]\nloss: 0.614205  [ 1616/ 4910]\nloss: 0.614886  [ 3216/ 4910]\nloss: 0.551454  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.652024 \n\nEpoch 641\n-------------------------------\nloss: 0.551597  [   16/ 4910]\nloss: 0.614033  [ 1616/ 4910]\nloss: 0.677034  [ 3216/ 4910]\nloss: 0.614014  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652516 \n\nEpoch 642\n-------------------------------\nloss: 0.551474  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.614205  [ 3216/ 4910]\nloss: 0.614056  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.648954 \n\nEpoch 643\n-------------------------------\nloss: 0.551675  [   16/ 4910]\nloss: 0.551474  [ 1616/ 4910]\nloss: 0.613959  [ 3216/ 4910]\nloss: 0.676504  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649143 \n\nEpoch 644\n-------------------------------\nloss: 0.614033  [   16/ 4910]\nloss: 0.676452  [ 1616/ 4910]\nloss: 0.551456  [ 3216/ 4910]\nloss: 0.676683  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659448 \n\nEpoch 645\n-------------------------------\nloss: 0.552070  [   16/ 4910]\nloss: 0.551495  [ 1616/ 4910]\nloss: 0.551499  [ 3216/ 4910]\nloss: 0.551473  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.665845 \n\nEpoch 646\n-------------------------------\nloss: 0.674425  [   16/ 4910]\nloss: 0.551472  [ 1616/ 4910]\nloss: 0.738964  [ 3216/ 4910]\nloss: 0.559755  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.667137 \n\nEpoch 647\n-------------------------------\nloss: 0.553234  [   16/ 4910]\nloss: 0.739093  [ 1616/ 4910]\nloss: 0.552769  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653510 \n\nEpoch 648\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.627875  [ 1616/ 4910]\nloss: 0.551560  [ 3216/ 4910]\nloss: 0.614267  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649935 \n\nEpoch 649\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.644336  [ 1616/ 4910]\nloss: 0.551457  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653965 \n\nEpoch 650\n-------------------------------\nloss: 0.613971  [   16/ 4910]\nloss: 0.552110  [ 1616/ 4910]\nloss: 0.551472  [ 3216/ 4910]\nloss: 0.614086  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654562 \n\nEpoch 651\n-------------------------------\nloss: 0.556018  [   16/ 4910]\nloss: 0.613961  [ 1616/ 4910]\nloss: 0.738974  [ 3216/ 4910]\nloss: 0.613979  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.665719 \n\nEpoch 652\n-------------------------------\nloss: 0.551457  [   16/ 4910]\nloss: 0.552814  [ 1616/ 4910]\nloss: 0.614163  [ 3216/ 4910]\nloss: 0.676510  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.647654 \n\nEpoch 653\n-------------------------------\nloss: 0.551514  [   16/ 4910]\nloss: 0.551489  [ 1616/ 4910]\nloss: 0.613959  [ 3216/ 4910]\nloss: 0.551457  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650019 \n\nEpoch 654\n-------------------------------\nloss: 0.614073  [   16/ 4910]\nloss: 0.626336  [ 1616/ 4910]\nloss: 0.614175  [ 3216/ 4910]\nloss: 0.551458  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.647452 \n\nEpoch 655\n-------------------------------\nloss: 0.551553  [   16/ 4910]\nloss: 0.676459  [ 1616/ 4910]\nloss: 0.551474  [ 3216/ 4910]\nloss: 0.676581  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.648762 \n\nEpoch 656\n-------------------------------\nloss: 0.551560  [   16/ 4910]\nloss: 0.676458  [ 1616/ 4910]\nloss: 0.551476  [ 3216/ 4910]\nloss: 0.614451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.646330 \n\nEpoch 657\n-------------------------------\nloss: 0.739111  [   16/ 4910]\nloss: 0.676544  [ 1616/ 4910]\nloss: 0.680602  [ 3216/ 4910]\nloss: 0.614344  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649309 \n\nEpoch 658\n-------------------------------\nloss: 0.614499  [   16/ 4910]\nloss: 0.676470  [ 1616/ 4910]\nloss: 0.613969  [ 3216/ 4910]\nloss: 0.613975  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649519 \n\nEpoch 659\n-------------------------------\nloss: 0.551450  [   16/ 4910]\nloss: 0.613969  [ 1616/ 4910]\nloss: 0.614049  [ 3216/ 4910]\nloss: 0.676447  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649482 \n\nEpoch 660\n-------------------------------\nloss: 0.551610  [   16/ 4910]\nloss: 0.733147  [ 1616/ 4910]\nloss: 0.613967  [ 3216/ 4910]\nloss: 0.551515  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.648317 \n\nEpoch 661\n-------------------------------\nloss: 0.613986  [   16/ 4910]\nloss: 0.551490  [ 1616/ 4910]\nloss: 0.551448  [ 3216/ 4910]\nloss: 0.613974  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.662519 \n\nEpoch 662\n-------------------------------\nloss: 0.801460  [   16/ 4910]\nloss: 0.613951  [ 1616/ 4910]\nloss: 0.676558  [ 3216/ 4910]\nloss: 0.567399  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.654973 \n\nEpoch 663\n-------------------------------\nloss: 0.614177  [   16/ 4910]\nloss: 0.614016  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.613946  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.9%, Avg loss: 0.660641 \n\nEpoch 664\n-------------------------------\nloss: 0.551451  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.613961  [ 3216/ 4910]\nloss: 0.551485  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660024 \n\nEpoch 665\n-------------------------------\nloss: 0.738956  [   16/ 4910]\nloss: 0.613988  [ 1616/ 4910]\nloss: 0.613974  [ 3216/ 4910]\nloss: 0.691288  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656972 \n\nEpoch 666\n-------------------------------\nloss: 0.551736  [   16/ 4910]\nloss: 0.614018  [ 1616/ 4910]\nloss: 0.672767  [ 3216/ 4910]\nloss: 0.613956  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656137 \n\nEpoch 667\n-------------------------------\nloss: 0.676447  [   16/ 4910]\nloss: 0.552129  [ 1616/ 4910]\nloss: 0.551481  [ 3216/ 4910]\nloss: 0.676449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.652024 \n\nEpoch 668\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.551502  [ 1616/ 4910]\nloss: 0.551513  [ 3216/ 4910]\nloss: 0.551482  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650077 \n\nEpoch 669\n-------------------------------\nloss: 0.551467  [   16/ 4910]\nloss: 0.551461  [ 1616/ 4910]\nloss: 0.551510  [ 3216/ 4910]\nloss: 0.613956  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647583 \n\nEpoch 670\n-------------------------------\nloss: 0.551471  [   16/ 4910]\nloss: 0.614149  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.614275  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648476 \n\nEpoch 671\n-------------------------------\nloss: 0.551579  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.551476  [ 3216/ 4910]\nloss: 0.551449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.650355 \n\nEpoch 672\n-------------------------------\nloss: 0.676453  [   16/ 4910]\nloss: 0.676523  [ 1616/ 4910]\nloss: 0.551454  [ 3216/ 4910]\nloss: 0.676479  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648082 \n\nEpoch 673\n-------------------------------\nloss: 0.551482  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.614020  [ 3216/ 4910]\nloss: 0.551446  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652168 \n\nEpoch 674\n-------------------------------\nloss: 0.613972  [   16/ 4910]\nloss: 0.676502  [ 1616/ 4910]\nloss: 0.551555  [ 3216/ 4910]\nloss: 0.613948  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650928 \n\nEpoch 675\n-------------------------------\nloss: 0.613953  [   16/ 4910]\nloss: 0.613977  [ 1616/ 4910]\nloss: 0.676453  [ 3216/ 4910]\nloss: 0.676648  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649232 \n\nEpoch 676\n-------------------------------\nloss: 0.676565  [   16/ 4910]\nloss: 0.614057  [ 1616/ 4910]\nloss: 0.551466  [ 3216/ 4910]\nloss: 0.613969  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653409 \n\nEpoch 677\n-------------------------------\nloss: 0.551479  [   16/ 4910]\nloss: 0.614250  [ 1616/ 4910]\nloss: 0.614021  [ 3216/ 4910]\nloss: 0.551461  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.653080 \n\nEpoch 678\n-------------------------------\nloss: 0.614000  [   16/ 4910]\nloss: 0.738949  [ 1616/ 4910]\nloss: 0.613984  [ 3216/ 4910]\nloss: 0.551466  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652693 \n\nEpoch 679\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.551513  [ 1616/ 4910]\nloss: 0.551691  [ 3216/ 4910]\nloss: 0.613955  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652510 \n\nEpoch 680\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.552511  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650677 \n\nEpoch 681\n-------------------------------\nloss: 0.551498  [   16/ 4910]\nloss: 0.551499  [ 1616/ 4910]\nloss: 0.551465  [ 3216/ 4910]\nloss: 0.613981  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651385 \n\nEpoch 682\n-------------------------------\nloss: 0.738959  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.613954  [ 3216/ 4910]\nloss: 0.738946  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651399 \n\nEpoch 683\n-------------------------------\nloss: 0.551456  [   16/ 4910]\nloss: 0.551481  [ 1616/ 4910]\nloss: 0.551448  [ 3216/ 4910]\nloss: 0.551449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650073 \n\nEpoch 684\n-------------------------------\nloss: 0.551453  [   16/ 4910]\nloss: 0.613958  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651146 \n\nEpoch 685\n-------------------------------\nloss: 0.676453  [   16/ 4910]\nloss: 0.551454  [ 1616/ 4910]\nloss: 0.551468  [ 3216/ 4910]\nloss: 0.676462  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654821 \n\nEpoch 686\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.551503  [ 1616/ 4910]\nloss: 0.676454  [ 3216/ 4910]\nloss: 0.676460  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651025 \n\nEpoch 687\n-------------------------------\nloss: 0.551447  [   16/ 4910]\nloss: 0.551458  [ 1616/ 4910]\nloss: 0.551564  [ 3216/ 4910]\nloss: 0.551478  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.647291 \n\nEpoch 688\n-------------------------------\nloss: 0.613984  [   16/ 4910]\nloss: 0.551501  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.551479  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647684 \n\nEpoch 689\n-------------------------------\nloss: 0.613951  [   16/ 4910]\nloss: 0.551611  [ 1616/ 4910]\nloss: 0.551918  [ 3216/ 4910]\nloss: 0.676457  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647668 \n\nEpoch 690\n-------------------------------\nloss: 0.614107  [   16/ 4910]\nloss: 0.613956  [ 1616/ 4910]\nloss: 0.613978  [ 3216/ 4910]\nloss: 0.551471  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648633 \n\nEpoch 691\n-------------------------------\nloss: 0.608130  [   16/ 4910]\nloss: 0.676485  [ 1616/ 4910]\nloss: 0.551452  [ 3216/ 4910]\nloss: 0.551449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648095 \n\nEpoch 692\n-------------------------------\nloss: 0.676459  [   16/ 4910]\nloss: 0.551460  [ 1616/ 4910]\nloss: 0.551451  [ 3216/ 4910]\nloss: 0.551462  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648146 \n\nEpoch 693\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.676471  [ 3216/ 4910]\nloss: 0.676470  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647729 \n\nEpoch 694\n-------------------------------\nloss: 0.676453  [   16/ 4910]\nloss: 0.551521  [ 1616/ 4910]\nloss: 0.676487  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649436 \n\nEpoch 695\n-------------------------------\nloss: 0.551466  [   16/ 4910]\nloss: 0.739084  [ 1616/ 4910]\nloss: 0.614002  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.647475 \n\nEpoch 696\n-------------------------------\nloss: 0.676466  [   16/ 4910]\nloss: 0.613965  [ 1616/ 4910]\nloss: 0.551504  [ 3216/ 4910]\nloss: 0.551449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.645960 \n\nEpoch 697\n-------------------------------\nloss: 0.614038  [   16/ 4910]\nloss: 0.613946  [ 1616/ 4910]\nloss: 0.613949  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648215 \n\nEpoch 698\n-------------------------------\nloss: 0.551548  [   16/ 4910]\nloss: 0.676449  [ 1616/ 4910]\nloss: 0.676469  [ 3216/ 4910]\nloss: 0.551472  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.649059 \n\nEpoch 699\n-------------------------------\nloss: 0.551449  [   16/ 4910]\nloss: 0.676453  [ 1616/ 4910]\nloss: 0.551448  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649289 \n\nEpoch 700\n-------------------------------\nloss: 0.613950  [   16/ 4910]\nloss: 0.676467  [ 1616/ 4910]\nloss: 0.676458  [ 3216/ 4910]\nloss: 0.613948  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.649127 \n\nEpoch 701\n-------------------------------\nloss: 0.551482  [   16/ 4910]\nloss: 0.613951  [ 1616/ 4910]\nloss: 0.613954  [ 3216/ 4910]\nloss: 0.551447  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.649031 \n\nEpoch 702\n-------------------------------\nloss: 0.738971  [   16/ 4910]\nloss: 0.608720  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.608310  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648983 \n\nEpoch 703\n-------------------------------\nloss: 0.676469  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.676478  [ 3216/ 4910]\nloss: 0.613981  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.648869 \n\nEpoch 704\n-------------------------------\nloss: 0.613962  [   16/ 4910]\nloss: 0.609830  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.614005  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.650003 \n\nEpoch 705\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.551458  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.613950  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647487 \n\nEpoch 706\n-------------------------------\nloss: 0.551551  [   16/ 4910]\nloss: 0.733328  [ 1616/ 4910]\nloss: 0.676492  [ 3216/ 4910]\nloss: 0.613953  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649355 \n\nEpoch 707\n-------------------------------\nloss: 0.614020  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.551469  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649375 \n\nEpoch 708\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.738954  [ 1616/ 4910]\nloss: 0.676478  [ 3216/ 4910]\nloss: 0.613946  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649305 \n\nEpoch 709\n-------------------------------\nloss: 0.613977  [   16/ 4910]\nloss: 0.613946  [ 1616/ 4910]\nloss: 0.613975  [ 3216/ 4910]\nloss: 0.551483  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.649332 \n\nEpoch 710\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.613987  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.676459  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.648268 \n\nEpoch 711\n-------------------------------\nloss: 0.613974  [   16/ 4910]\nloss: 0.551521  [ 1616/ 4910]\nloss: 0.676448  [ 3216/ 4910]\nloss: 0.551455  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.649030 \n\nEpoch 712\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.551459  [ 1616/ 4910]\nloss: 0.676434  [ 3216/ 4910]\nloss: 0.551454  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649206 \n\nEpoch 713\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.613991  [ 1616/ 4910]\nloss: 0.676474  [ 3216/ 4910]\nloss: 0.551490  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649172 \n\nEpoch 714\n-------------------------------\nloss: 0.551470  [   16/ 4910]\nloss: 0.676449  [ 1616/ 4910]\nloss: 0.738950  [ 3216/ 4910]\nloss: 0.551458  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.648101 \n\nEpoch 715\n-------------------------------\nloss: 0.551451  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.676479  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648231 \n\nEpoch 716\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.551571  [ 1616/ 4910]\nloss: 0.670631  [ 3216/ 4910]\nloss: 0.610561  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656560 \n\nEpoch 717\n-------------------------------\nloss: 0.676447  [   16/ 4910]\nloss: 0.672155  [ 1616/ 4910]\nloss: 0.693553  [ 3216/ 4910]\nloss: 0.616850  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.657154 \n\nEpoch 718\n-------------------------------\nloss: 0.676564  [   16/ 4910]\nloss: 0.614018  [ 1616/ 4910]\nloss: 0.614432  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659554 \n\nEpoch 719\n-------------------------------\nloss: 0.551564  [   16/ 4910]\nloss: 0.614029  [ 1616/ 4910]\nloss: 0.551525  [ 3216/ 4910]\nloss: 0.551575  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653168 \n\nEpoch 720\n-------------------------------\nloss: 0.676461  [   16/ 4910]\nloss: 0.670783  [ 1616/ 4910]\nloss: 0.609225  [ 3216/ 4910]\nloss: 0.614091  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652593 \n\nEpoch 721\n-------------------------------\nloss: 0.551459  [   16/ 4910]\nloss: 0.676509  [ 1616/ 4910]\nloss: 0.551473  [ 3216/ 4910]\nloss: 0.615162  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.648004 \n\nEpoch 722\n-------------------------------\nloss: 0.551565  [   16/ 4910]\nloss: 0.676487  [ 1616/ 4910]\nloss: 0.613977  [ 3216/ 4910]\nloss: 0.613976  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653065 \n\nEpoch 723\n-------------------------------\nloss: 0.738949  [   16/ 4910]\nloss: 0.614011  [ 1616/ 4910]\nloss: 0.552070  [ 3216/ 4910]\nloss: 0.551473  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649531 \n\nEpoch 724\n-------------------------------\nloss: 0.613987  [   16/ 4910]\nloss: 0.614411  [ 1616/ 4910]\nloss: 0.613965  [ 3216/ 4910]\nloss: 0.551469  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646915 \n\nEpoch 725\n-------------------------------\nloss: 0.551520  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.738949  [ 3216/ 4910]\nloss: 0.613969  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649808 \n\nEpoch 726\n-------------------------------\nloss: 0.670610  [   16/ 4910]\nloss: 0.676467  [ 1616/ 4910]\nloss: 0.676531  [ 3216/ 4910]\nloss: 0.614028  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649803 \n\nEpoch 727\n-------------------------------\nloss: 0.551446  [   16/ 4910]\nloss: 0.551551  [ 1616/ 4910]\nloss: 0.613994  [ 3216/ 4910]\nloss: 0.551484  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.647651 \n\nEpoch 728\n-------------------------------\nloss: 0.551511  [   16/ 4910]\nloss: 0.551462  [ 1616/ 4910]\nloss: 0.738968  [ 3216/ 4910]\nloss: 0.613993  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647781 \n\nEpoch 729\n-------------------------------\nloss: 0.551455  [   16/ 4910]\nloss: 0.676452  [ 1616/ 4910]\nloss: 0.676452  [ 3216/ 4910]\nloss: 0.676529  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648565 \n\nEpoch 730\n-------------------------------\nloss: 0.551464  [   16/ 4910]\nloss: 0.551456  [ 1616/ 4910]\nloss: 0.551470  [ 3216/ 4910]\nloss: 0.675860  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.658252 \n\nEpoch 731\n-------------------------------\nloss: 0.616442  [   16/ 4910]\nloss: 0.551467  [ 1616/ 4910]\nloss: 0.551460  [ 3216/ 4910]\nloss: 0.670753  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648674 \n\nEpoch 732\n-------------------------------\nloss: 0.738960  [   16/ 4910]\nloss: 0.676775  [ 1616/ 4910]\nloss: 0.613979  [ 3216/ 4910]\nloss: 0.613988  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653037 \n\nEpoch 733\n-------------------------------\nloss: 0.613967  [   16/ 4910]\nloss: 0.551493  [ 1616/ 4910]\nloss: 0.551511  [ 3216/ 4910]\nloss: 0.614169  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648566 \n\nEpoch 734\n-------------------------------\nloss: 0.551763  [   16/ 4910]\nloss: 0.677575  [ 1616/ 4910]\nloss: 0.613958  [ 3216/ 4910]\nloss: 0.801461  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649974 \n\nEpoch 735\n-------------------------------\nloss: 0.553116  [   16/ 4910]\nloss: 0.551480  [ 1616/ 4910]\nloss: 0.613964  [ 3216/ 4910]\nloss: 0.614120  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653477 \n\nEpoch 736\n-------------------------------\nloss: 0.551460  [   16/ 4910]\nloss: 0.676978  [ 1616/ 4910]\nloss: 0.676473  [ 3216/ 4910]\nloss: 0.614004  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651372 \n\nEpoch 737\n-------------------------------\nloss: 0.613945  [   16/ 4910]\nloss: 0.614067  [ 1616/ 4910]\nloss: 0.614016  [ 3216/ 4910]\nloss: 0.676452  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648186 \n\nEpoch 738\n-------------------------------\nloss: 0.613979  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.676454  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649453 \n\nEpoch 739\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.613960  [ 1616/ 4910]\nloss: 0.551455  [ 3216/ 4910]\nloss: 0.738951  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650579 \n\nEpoch 740\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.613956  [ 1616/ 4910]\nloss: 0.551461  [ 3216/ 4910]\nloss: 0.739001  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651805 \n\nEpoch 741\n-------------------------------\nloss: 0.551524  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.551487  [ 3216/ 4910]\nloss: 0.613945  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.647931 \n\nEpoch 742\n-------------------------------\nloss: 0.551457  [   16/ 4910]\nloss: 0.613948  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650110 \n\nEpoch 743\n-------------------------------\nloss: 0.613956  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.551463  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.648127 \n\nEpoch 744\n-------------------------------\nloss: 0.801452  [   16/ 4910]\nloss: 0.613966  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648056 \n\nEpoch 745\n-------------------------------\nloss: 0.738977  [   16/ 4910]\nloss: 0.676456  [ 1616/ 4910]\nloss: 0.551462  [ 3216/ 4910]\nloss: 0.613954  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.653944 \n\nEpoch 746\n-------------------------------\nloss: 0.613957  [   16/ 4910]\nloss: 0.613988  [ 1616/ 4910]\nloss: 0.676478  [ 3216/ 4910]\nloss: 0.680400  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652915 \n\nEpoch 747\n-------------------------------\nloss: 0.738990  [   16/ 4910]\nloss: 0.551502  [ 1616/ 4910]\nloss: 0.676534  [ 3216/ 4910]\nloss: 0.551473  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649253 \n\nEpoch 748\n-------------------------------\nloss: 0.738876  [   16/ 4910]\nloss: 0.551472  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.551482  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650149 \n\nEpoch 749\n-------------------------------\nloss: 0.676462  [   16/ 4910]\nloss: 0.738931  [ 1616/ 4910]\nloss: 0.551475  [ 3216/ 4910]\nloss: 0.614414  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650234 \n\nEpoch 750\n-------------------------------\nloss: 0.613953  [   16/ 4910]\nloss: 0.552500  [ 1616/ 4910]\nloss: 0.551470  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650825 \n\nEpoch 751\n-------------------------------\nloss: 0.671003  [   16/ 4910]\nloss: 0.551483  [ 1616/ 4910]\nloss: 0.551466  [ 3216/ 4910]\nloss: 0.613972  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649766 \n\nEpoch 752\n-------------------------------\nloss: 0.613946  [   16/ 4910]\nloss: 0.676466  [ 1616/ 4910]\nloss: 0.614130  [ 3216/ 4910]\nloss: 0.613984  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649971 \n\nEpoch 753\n-------------------------------\nloss: 0.613954  [   16/ 4910]\nloss: 0.551446  [ 1616/ 4910]\nloss: 0.551477  [ 3216/ 4910]\nloss: 0.676448  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649980 \n\nEpoch 754\n-------------------------------\nloss: 0.551500  [   16/ 4910]\nloss: 0.739120  [ 1616/ 4910]\nloss: 0.551528  [ 3216/ 4910]\nloss: 0.614027  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653288 \n\nEpoch 755\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.613950  [ 1616/ 4910]\nloss: 0.613957  [ 3216/ 4910]\nloss: 0.677446  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.656125 \n\nEpoch 756\n-------------------------------\nloss: 0.551477  [   16/ 4910]\nloss: 0.676520  [ 1616/ 4910]\nloss: 0.738951  [ 3216/ 4910]\nloss: 0.614071  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654741 \n\nEpoch 757\n-------------------------------\nloss: 0.613966  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.614061  [ 3216/ 4910]\nloss: 0.613965  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649792 \n\nEpoch 758\n-------------------------------\nloss: 0.551563  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.551743  [ 3216/ 4910]\nloss: 0.676668  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.646724 \n\nEpoch 759\n-------------------------------\nloss: 0.551494  [   16/ 4910]\nloss: 0.676464  [ 1616/ 4910]\nloss: 0.551498  [ 3216/ 4910]\nloss: 0.551480  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651928 \n\nEpoch 760\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.614743  [ 1616/ 4910]\nloss: 0.676534  [ 3216/ 4910]\nloss: 0.614039  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649767 \n\nEpoch 761\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.614050  [ 1616/ 4910]\nloss: 0.613952  [ 3216/ 4910]\nloss: 0.738985  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651109 \n\nEpoch 762\n-------------------------------\nloss: 0.676485  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.614212  [ 3216/ 4910]\nloss: 0.676451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.648451 \n\nEpoch 763\n-------------------------------\nloss: 0.614224  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.551536  [ 3216/ 4910]\nloss: 0.676445  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652483 \n\nEpoch 764\n-------------------------------\nloss: 0.616976  [   16/ 4910]\nloss: 0.614088  [ 1616/ 4910]\nloss: 0.551467  [ 3216/ 4910]\nloss: 0.551629  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.645960 \n\nEpoch 765\n-------------------------------\nloss: 0.739548  [   16/ 4910]\nloss: 0.551462  [ 1616/ 4910]\nloss: 0.614085  [ 3216/ 4910]\nloss: 0.551464  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.646576 \n\nEpoch 766\n-------------------------------\nloss: 0.551493  [   16/ 4910]\nloss: 0.613961  [ 1616/ 4910]\nloss: 0.613957  [ 3216/ 4910]\nloss: 0.551490  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648757 \n\nEpoch 767\n-------------------------------\nloss: 0.613972  [   16/ 4910]\nloss: 0.551492  [ 1616/ 4910]\nloss: 0.551615  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.647246 \n\nEpoch 768\n-------------------------------\nloss: 0.613973  [   16/ 4910]\nloss: 0.608133  [ 1616/ 4910]\nloss: 0.613983  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653868 \n\nEpoch 769\n-------------------------------\nloss: 0.613985  [   16/ 4910]\nloss: 0.613968  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.619123  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654171 \n\nEpoch 770\n-------------------------------\nloss: 0.609490  [   16/ 4910]\nloss: 0.611859  [ 1616/ 4910]\nloss: 0.613995  [ 3216/ 4910]\nloss: 0.609779  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.656660 \n\nEpoch 771\n-------------------------------\nloss: 0.551540  [   16/ 4910]\nloss: 0.551853  [ 1616/ 4910]\nloss: 0.676201  [ 3216/ 4910]\nloss: 0.551465  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651460 \n\nEpoch 772\n-------------------------------\nloss: 0.551463  [   16/ 4910]\nloss: 0.613966  [ 1616/ 4910]\nloss: 0.614130  [ 3216/ 4910]\nloss: 0.613949  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655303 \n\nEpoch 773\n-------------------------------\nloss: 0.551497  [   16/ 4910]\nloss: 0.551491  [ 1616/ 4910]\nloss: 0.613954  [ 3216/ 4910]\nloss: 0.614301  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652966 \n\nEpoch 774\n-------------------------------\nloss: 0.551460  [   16/ 4910]\nloss: 0.676943  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.551523  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654265 \n\nEpoch 775\n-------------------------------\nloss: 0.677998  [   16/ 4910]\nloss: 0.551451  [ 1616/ 4910]\nloss: 0.551462  [ 3216/ 4910]\nloss: 0.613995  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653565 \n\nEpoch 776\n-------------------------------\nloss: 0.551534  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.551516  [ 3216/ 4910]\nloss: 0.614163  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658174 \n\nEpoch 777\n-------------------------------\nloss: 0.575254  [   16/ 4910]\nloss: 0.551689  [ 1616/ 4910]\nloss: 0.551581  [ 3216/ 4910]\nloss: 0.551478  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655088 \n\nEpoch 778\n-------------------------------\nloss: 0.551464  [   16/ 4910]\nloss: 0.614121  [ 1616/ 4910]\nloss: 0.616641  [ 3216/ 4910]\nloss: 0.614124  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652531 \n\nEpoch 779\n-------------------------------\nloss: 0.738948  [   16/ 4910]\nloss: 0.614001  [ 1616/ 4910]\nloss: 0.613961  [ 3216/ 4910]\nloss: 0.738962  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650720 \n\nEpoch 780\n-------------------------------\nloss: 0.613969  [   16/ 4910]\nloss: 0.613977  [ 1616/ 4910]\nloss: 0.551480  [ 3216/ 4910]\nloss: 0.551450  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650137 \n\nEpoch 781\n-------------------------------\nloss: 0.613933  [   16/ 4910]\nloss: 0.726569  [ 1616/ 4910]\nloss: 0.676447  [ 3216/ 4910]\nloss: 0.676391  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656105 \n\nEpoch 782\n-------------------------------\nloss: 0.676600  [   16/ 4910]\nloss: 0.551461  [ 1616/ 4910]\nloss: 0.613959  [ 3216/ 4910]\nloss: 0.676454  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.652321 \n\nEpoch 783\n-------------------------------\nloss: 0.613996  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.676486  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650131 \n\nEpoch 784\n-------------------------------\nloss: 0.552185  [   16/ 4910]\nloss: 0.613947  [ 1616/ 4910]\nloss: 0.613966  [ 3216/ 4910]\nloss: 0.614036  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648074 \n\nEpoch 785\n-------------------------------\nloss: 0.551498  [   16/ 4910]\nloss: 0.626136  [ 1616/ 4910]\nloss: 0.676454  [ 3216/ 4910]\nloss: 0.676496  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.647985 \n\nEpoch 786\n-------------------------------\nloss: 0.551641  [   16/ 4910]\nloss: 0.614057  [ 1616/ 4910]\nloss: 0.613978  [ 3216/ 4910]\nloss: 0.552741  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649554 \n\nEpoch 787\n-------------------------------\nloss: 0.551447  [   16/ 4910]\nloss: 0.551471  [ 1616/ 4910]\nloss: 0.738969  [ 3216/ 4910]\nloss: 0.552049  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.659230 \n\nEpoch 788\n-------------------------------\nloss: 0.650911  [   16/ 4910]\nloss: 0.613967  [ 1616/ 4910]\nloss: 0.614064  [ 3216/ 4910]\nloss: 0.613951  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.662118 \n\nEpoch 789\n-------------------------------\nloss: 0.551496  [   16/ 4910]\nloss: 0.613991  [ 1616/ 4910]\nloss: 0.629068  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654900 \n\nEpoch 790\n-------------------------------\nloss: 0.551484  [   16/ 4910]\nloss: 0.551456  [ 1616/ 4910]\nloss: 0.553361  [ 3216/ 4910]\nloss: 0.671598  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.661412 \n\nEpoch 791\n-------------------------------\nloss: 0.551924  [   16/ 4910]\nloss: 0.676336  [ 1616/ 4910]\nloss: 0.613957  [ 3216/ 4910]\nloss: 0.785059  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.660760 \n\nEpoch 792\n-------------------------------\nloss: 0.551465  [   16/ 4910]\nloss: 0.613950  [ 1616/ 4910]\nloss: 0.561241  [ 3216/ 4910]\nloss: 0.553134  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.659142 \n\nEpoch 793\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.676445  [ 1616/ 4910]\nloss: 0.551463  [ 3216/ 4910]\nloss: 0.614077  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.667043 \n\nEpoch 794\n-------------------------------\nloss: 0.614114  [   16/ 4910]\nloss: 0.614005  [ 1616/ 4910]\nloss: 0.676447  [ 3216/ 4910]\nloss: 0.609655  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651838 \n\nEpoch 795\n-------------------------------\nloss: 0.614450  [   16/ 4910]\nloss: 0.551466  [ 1616/ 4910]\nloss: 0.614516  [ 3216/ 4910]\nloss: 0.614221  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.652283 \n\nEpoch 796\n-------------------------------\nloss: 0.622223  [   16/ 4910]\nloss: 0.728822  [ 1616/ 4910]\nloss: 0.615321  [ 3216/ 4910]\nloss: 0.617833  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.656182 \n\nEpoch 797\n-------------------------------\nloss: 0.676446  [   16/ 4910]\nloss: 0.613976  [ 1616/ 4910]\nloss: 0.614678  [ 3216/ 4910]\nloss: 0.551818  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.668869 \n\nEpoch 798\n-------------------------------\nloss: 0.651733  [   16/ 4910]\nloss: 0.551548  [ 1616/ 4910]\nloss: 0.614017  [ 3216/ 4910]\nloss: 0.614034  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656862 \n\nEpoch 799\n-------------------------------\nloss: 0.613952  [   16/ 4910]\nloss: 0.614367  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.738726  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.7%, Avg loss: 0.662474 \n\nEpoch 800\n-------------------------------\nloss: 0.676527  [   16/ 4910]\nloss: 0.613969  [ 1616/ 4910]\nloss: 0.676487  [ 3216/ 4910]\nloss: 0.676618  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652881 \n\nEpoch 801\n-------------------------------\nloss: 0.618634  [   16/ 4910]\nloss: 0.551824  [ 1616/ 4910]\nloss: 0.551496  [ 3216/ 4910]\nloss: 0.676662  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.661195 \n\nEpoch 802\n-------------------------------\nloss: 0.676496  [   16/ 4910]\nloss: 0.551547  [ 1616/ 4910]\nloss: 0.613994  [ 3216/ 4910]\nloss: 0.613945  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654288 \n\nEpoch 803\n-------------------------------\nloss: 0.628325  [   16/ 4910]\nloss: 0.551590  [ 1616/ 4910]\nloss: 0.676448  [ 3216/ 4910]\nloss: 0.551475  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654756 \n\nEpoch 804\n-------------------------------\nloss: 0.676455  [   16/ 4910]\nloss: 0.551565  [ 1616/ 4910]\nloss: 0.613969  [ 3216/ 4910]\nloss: 0.561364  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657586 \n\nEpoch 805\n-------------------------------\nloss: 0.676537  [   16/ 4910]\nloss: 0.613957  [ 1616/ 4910]\nloss: 0.551749  [ 3216/ 4910]\nloss: 0.551464  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652588 \n\nEpoch 806\n-------------------------------\nloss: 0.635608  [   16/ 4910]\nloss: 0.613975  [ 1616/ 4910]\nloss: 0.614261  [ 3216/ 4910]\nloss: 0.551575  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.657553 \n\nEpoch 807\n-------------------------------\nloss: 0.629878  [   16/ 4910]\nloss: 0.614194  [ 1616/ 4910]\nloss: 0.676468  [ 3216/ 4910]\nloss: 0.676450  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651271 \n\nEpoch 808\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.551499  [ 1616/ 4910]\nloss: 0.599420  [ 3216/ 4910]\nloss: 0.551454  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.8%, Avg loss: 0.662578 \n\nEpoch 809\n-------------------------------\nloss: 0.551468  [   16/ 4910]\nloss: 0.614629  [ 1616/ 4910]\nloss: 0.676500  [ 3216/ 4910]\nloss: 0.678865  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651033 \n\nEpoch 810\n-------------------------------\nloss: 0.551520  [   16/ 4910]\nloss: 0.613947  [ 1616/ 4910]\nloss: 0.676449  [ 3216/ 4910]\nloss: 0.616880  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.647573 \n\nEpoch 811\n-------------------------------\nloss: 0.613964  [   16/ 4910]\nloss: 0.551823  [ 1616/ 4910]\nloss: 0.676502  [ 3216/ 4910]\nloss: 0.615532  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656022 \n\nEpoch 812\n-------------------------------\nloss: 0.615898  [   16/ 4910]\nloss: 0.739046  [ 1616/ 4910]\nloss: 0.551537  [ 3216/ 4910]\nloss: 0.614072  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.654364 \n\nEpoch 813\n-------------------------------\nloss: 0.613948  [   16/ 4910]\nloss: 0.676612  [ 1616/ 4910]\nloss: 0.613954  [ 3216/ 4910]\nloss: 0.551470  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.6%, Avg loss: 0.664808 \n\nEpoch 814\n-------------------------------\nloss: 0.738944  [   16/ 4910]\nloss: 0.551455  [ 1616/ 4910]\nloss: 0.613994  [ 3216/ 4910]\nloss: 0.551515  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649887 \n\nEpoch 815\n-------------------------------\nloss: 0.551488  [   16/ 4910]\nloss: 0.615008  [ 1616/ 4910]\nloss: 0.738961  [ 3216/ 4910]\nloss: 0.676446  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649099 \n\nEpoch 816\n-------------------------------\nloss: 0.614216  [   16/ 4910]\nloss: 0.558516  [ 1616/ 4910]\nloss: 0.551496  [ 3216/ 4910]\nloss: 0.553815  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.648597 \n\nEpoch 817\n-------------------------------\nloss: 0.801404  [   16/ 4910]\nloss: 0.555903  [ 1616/ 4910]\nloss: 0.613968  [ 3216/ 4910]\nloss: 0.613946  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.660871 \n\nEpoch 818\n-------------------------------\nloss: 0.551506  [   16/ 4910]\nloss: 0.677943  [ 1616/ 4910]\nloss: 0.597853  [ 3216/ 4910]\nloss: 0.613974  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.654791 \n\nEpoch 819\n-------------------------------\nloss: 0.614064  [   16/ 4910]\nloss: 0.551523  [ 1616/ 4910]\nloss: 0.676506  [ 3216/ 4910]\nloss: 0.551531  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652269 \n\nEpoch 820\n-------------------------------\nloss: 0.613988  [   16/ 4910]\nloss: 0.558368  [ 1616/ 4910]\nloss: 0.551487  [ 3216/ 4910]\nloss: 0.614091  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.664831 \n\nEpoch 821\n-------------------------------\nloss: 0.616025  [   16/ 4910]\nloss: 0.561289  [ 1616/ 4910]\nloss: 0.555815  [ 3216/ 4910]\nloss: 0.676474  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653054 \n\nEpoch 822\n-------------------------------\nloss: 0.676452  [   16/ 4910]\nloss: 0.613962  [ 1616/ 4910]\nloss: 0.568377  [ 3216/ 4910]\nloss: 0.551470  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652962 \n\nEpoch 823\n-------------------------------\nloss: 0.613977  [   16/ 4910]\nloss: 0.610144  [ 1616/ 4910]\nloss: 0.613960  [ 3216/ 4910]\nloss: 0.614077  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.660135 \n\nEpoch 824\n-------------------------------\nloss: 0.613963  [   16/ 4910]\nloss: 0.551728  [ 1616/ 4910]\nloss: 0.676448  [ 3216/ 4910]\nloss: 0.551494  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656410 \n\nEpoch 825\n-------------------------------\nloss: 0.614052  [   16/ 4910]\nloss: 0.615281  [ 1616/ 4910]\nloss: 0.555960  [ 3216/ 4910]\nloss: 0.552162  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654215 \n\nEpoch 826\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.614706  [ 1616/ 4910]\nloss: 0.613954  [ 3216/ 4910]\nloss: 0.613912  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652211 \n\nEpoch 827\n-------------------------------\nloss: 0.676447  [   16/ 4910]\nloss: 0.640002  [ 1616/ 4910]\nloss: 0.551778  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.668416 \n\nEpoch 828\n-------------------------------\nloss: 0.619926  [   16/ 4910]\nloss: 0.656055  [ 1616/ 4910]\nloss: 0.551445  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.667036 \n\nEpoch 829\n-------------------------------\nloss: 0.606524  [   16/ 4910]\nloss: 0.613950  [ 1616/ 4910]\nloss: 0.630479  [ 3216/ 4910]\nloss: 0.676451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651009 \n\nEpoch 830\n-------------------------------\nloss: 0.551473  [   16/ 4910]\nloss: 0.864100  [ 1616/ 4910]\nloss: 0.614001  [ 3216/ 4910]\nloss: 0.613970  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658882 \n\nEpoch 831\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.551466  [ 1616/ 4910]\nloss: 0.613987  [ 3216/ 4910]\nloss: 0.680642  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651542 \n\nEpoch 832\n-------------------------------\nloss: 0.676615  [   16/ 4910]\nloss: 0.551466  [ 1616/ 4910]\nloss: 0.613968  [ 3216/ 4910]\nloss: 0.551494  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.655723 \n\nEpoch 833\n-------------------------------\nloss: 0.675321  [   16/ 4910]\nloss: 0.676451  [ 1616/ 4910]\nloss: 0.551640  [ 3216/ 4910]\nloss: 0.551500  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654494 \n\nEpoch 834\n-------------------------------\nloss: 0.676649  [   16/ 4910]\nloss: 0.613967  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.551498  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654674 \n\nEpoch 835\n-------------------------------\nloss: 0.613961  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.614036  [ 3216/ 4910]\nloss: 0.614015  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651002 \n\nEpoch 836\n-------------------------------\nloss: 0.613952  [   16/ 4910]\nloss: 0.551612  [ 1616/ 4910]\nloss: 0.551990  [ 3216/ 4910]\nloss: 0.551451  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652356 \n\nEpoch 837\n-------------------------------\nloss: 0.551474  [   16/ 4910]\nloss: 0.676464  [ 1616/ 4910]\nloss: 0.614012  [ 3216/ 4910]\nloss: 0.738946  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651367 \n\nEpoch 838\n-------------------------------\nloss: 0.614043  [   16/ 4910]\nloss: 0.614138  [ 1616/ 4910]\nloss: 0.613960  [ 3216/ 4910]\nloss: 0.614035  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650030 \n\nEpoch 839\n-------------------------------\nloss: 0.676489  [   16/ 4910]\nloss: 0.613433  [ 1616/ 4910]\nloss: 0.551507  [ 3216/ 4910]\nloss: 0.551494  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647094 \n\nEpoch 840\n-------------------------------\nloss: 0.613990  [   16/ 4910]\nloss: 0.551446  [ 1616/ 4910]\nloss: 0.613976  [ 3216/ 4910]\nloss: 0.551462  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653658 \n\nEpoch 841\n-------------------------------\nloss: 0.614015  [   16/ 4910]\nloss: 0.613955  [ 1616/ 4910]\nloss: 0.613975  [ 3216/ 4910]\nloss: 0.552354  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.666617 \n\nEpoch 842\n-------------------------------\nloss: 0.614043  [   16/ 4910]\nloss: 0.677647  [ 1616/ 4910]\nloss: 0.676618  [ 3216/ 4910]\nloss: 0.613990  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649594 \n\nEpoch 843\n-------------------------------\nloss: 0.616653  [   16/ 4910]\nloss: 0.676825  [ 1616/ 4910]\nloss: 0.613980  [ 3216/ 4910]\nloss: 0.614002  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650552 \n\nEpoch 844\n-------------------------------\nloss: 0.677067  [   16/ 4910]\nloss: 0.613953  [ 1616/ 4910]\nloss: 0.551821  [ 3216/ 4910]\nloss: 0.551541  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.0%, Avg loss: 0.668853 \n\nEpoch 845\n-------------------------------\nloss: 0.560446  [   16/ 4910]\nloss: 0.614055  [ 1616/ 4910]\nloss: 0.613959  [ 3216/ 4910]\nloss: 0.551494  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656182 \n\nEpoch 846\n-------------------------------\nloss: 0.671441  [   16/ 4910]\nloss: 0.551463  [ 1616/ 4910]\nloss: 0.613969  [ 3216/ 4910]\nloss: 0.739138  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.647862 \n\nEpoch 847\n-------------------------------\nloss: 0.551472  [   16/ 4910]\nloss: 0.613959  [ 1616/ 4910]\nloss: 0.614249  [ 3216/ 4910]\nloss: 0.551521  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.5%, Avg loss: 0.664302 \n\nEpoch 848\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.552158  [ 1616/ 4910]\nloss: 0.551491  [ 3216/ 4910]\nloss: 0.551465  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653123 \n\nEpoch 849\n-------------------------------\nloss: 0.614054  [   16/ 4910]\nloss: 0.676454  [ 1616/ 4910]\nloss: 0.618924  [ 3216/ 4910]\nloss: 0.613995  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.655552 \n\nEpoch 850\n-------------------------------\nloss: 0.614037  [   16/ 4910]\nloss: 0.551654  [ 1616/ 4910]\nloss: 0.676495  [ 3216/ 4910]\nloss: 0.613965  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653727 \n\nEpoch 851\n-------------------------------\nloss: 0.551460  [   16/ 4910]\nloss: 0.551465  [ 1616/ 4910]\nloss: 0.553341  [ 3216/ 4910]\nloss: 0.613979  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.657748 \n\nEpoch 852\n-------------------------------\nloss: 0.734014  [   16/ 4910]\nloss: 0.551481  [ 1616/ 4910]\nloss: 0.676458  [ 3216/ 4910]\nloss: 0.551467  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652977 \n\nEpoch 853\n-------------------------------\nloss: 0.551796  [   16/ 4910]\nloss: 0.569177  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.676448  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.664005 \n\nEpoch 854\n-------------------------------\nloss: 0.613948  [   16/ 4910]\nloss: 0.551868  [ 1616/ 4910]\nloss: 0.614102  [ 3216/ 4910]\nloss: 0.740335  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.2%, Avg loss: 0.666095 \n\nEpoch 855\n-------------------------------\nloss: 0.614071  [   16/ 4910]\nloss: 0.677566  [ 1616/ 4910]\nloss: 0.613996  [ 3216/ 4910]\nloss: 0.676557  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653995 \n\nEpoch 856\n-------------------------------\nloss: 0.672536  [   16/ 4910]\nloss: 0.618203  [ 1616/ 4910]\nloss: 0.551954  [ 3216/ 4910]\nloss: 0.617137  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654654 \n\nEpoch 857\n-------------------------------\nloss: 0.676466  [   16/ 4910]\nloss: 0.676498  [ 1616/ 4910]\nloss: 0.795702  [ 3216/ 4910]\nloss: 0.551663  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654739 \n\nEpoch 858\n-------------------------------\nloss: 0.738793  [   16/ 4910]\nloss: 0.551888  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.614337  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.653276 \n\nEpoch 859\n-------------------------------\nloss: 0.609665  [   16/ 4910]\nloss: 0.614117  [ 1616/ 4910]\nloss: 0.677479  [ 3216/ 4910]\nloss: 0.551558  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.657318 \n\nEpoch 860\n-------------------------------\nloss: 0.676451  [   16/ 4910]\nloss: 0.614015  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.670680  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651847 \n\nEpoch 861\n-------------------------------\nloss: 0.676513  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.613970  [ 3216/ 4910]\nloss: 0.614187  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654116 \n\nEpoch 862\n-------------------------------\nloss: 0.602446  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.551461  [ 3216/ 4910]\nloss: 0.613944  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648003 \n\nEpoch 863\n-------------------------------\nloss: 0.613966  [   16/ 4910]\nloss: 0.676457  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.614029  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.658841 \n\nEpoch 864\n-------------------------------\nloss: 0.614021  [   16/ 4910]\nloss: 0.614076  [ 1616/ 4910]\nloss: 0.613964  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652848 \n\nEpoch 865\n-------------------------------\nloss: 0.614013  [   16/ 4910]\nloss: 0.613956  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.551473  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649629 \n\nEpoch 866\n-------------------------------\nloss: 0.551821  [   16/ 4910]\nloss: 0.614084  [ 1616/ 4910]\nloss: 0.551575  [ 3216/ 4910]\nloss: 0.551447  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.658967 \n\nEpoch 867\n-------------------------------\nloss: 0.551750  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.613952  [ 3216/ 4910]\nloss: 0.551534  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651880 \n\nEpoch 868\n-------------------------------\nloss: 0.614932  [   16/ 4910]\nloss: 0.738946  [ 1616/ 4910]\nloss: 0.676760  [ 3216/ 4910]\nloss: 0.614043  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653339 \n\nEpoch 869\n-------------------------------\nloss: 0.551527  [   16/ 4910]\nloss: 0.613985  [ 1616/ 4910]\nloss: 0.733183  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649483 \n\nEpoch 870\n-------------------------------\nloss: 0.552252  [   16/ 4910]\nloss: 0.551451  [ 1616/ 4910]\nloss: 0.551448  [ 3216/ 4910]\nloss: 0.614585  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649270 \n\nEpoch 871\n-------------------------------\nloss: 0.605210  [   16/ 4910]\nloss: 0.679443  [ 1616/ 4910]\nloss: 0.551452  [ 3216/ 4910]\nloss: 0.613986  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651724 \n\nEpoch 872\n-------------------------------\nloss: 0.614215  [   16/ 4910]\nloss: 0.613956  [ 1616/ 4910]\nloss: 0.676471  [ 3216/ 4910]\nloss: 0.551551  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650578 \n\nEpoch 873\n-------------------------------\nloss: 0.613956  [   16/ 4910]\nloss: 0.613964  [ 1616/ 4910]\nloss: 0.551470  [ 3216/ 4910]\nloss: 0.614017  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.647291 \n\nEpoch 874\n-------------------------------\nloss: 0.551731  [   16/ 4910]\nloss: 0.676495  [ 1616/ 4910]\nloss: 0.551468  [ 3216/ 4910]\nloss: 0.614037  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.645796 \n\nEpoch 875\n-------------------------------\nloss: 0.614350  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.676695  [ 3216/ 4910]\nloss: 0.551548  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651342 \n\nEpoch 876\n-------------------------------\nloss: 0.614234  [   16/ 4910]\nloss: 0.613953  [ 1616/ 4910]\nloss: 0.613961  [ 3216/ 4910]\nloss: 0.613973  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650239 \n\nEpoch 877\n-------------------------------\nloss: 0.614867  [   16/ 4910]\nloss: 0.613950  [ 1616/ 4910]\nloss: 0.551456  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651653 \n\nEpoch 878\n-------------------------------\nloss: 0.551447  [   16/ 4910]\nloss: 0.613964  [ 1616/ 4910]\nloss: 0.676874  [ 3216/ 4910]\nloss: 0.614012  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652394 \n\nEpoch 879\n-------------------------------\nloss: 0.613947  [   16/ 4910]\nloss: 0.613974  [ 1616/ 4910]\nloss: 0.551446  [ 3216/ 4910]\nloss: 0.614034  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652193 \n\nEpoch 880\n-------------------------------\nloss: 0.552113  [   16/ 4910]\nloss: 0.551487  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.551474  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650341 \n\nEpoch 881\n-------------------------------\nloss: 0.551490  [   16/ 4910]\nloss: 0.614269  [ 1616/ 4910]\nloss: 0.551454  [ 3216/ 4910]\nloss: 0.551453  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650813 \n\nEpoch 882\n-------------------------------\nloss: 0.738954  [   16/ 4910]\nloss: 0.676958  [ 1616/ 4910]\nloss: 0.613949  [ 3216/ 4910]\nloss: 0.613950  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650269 \n\nEpoch 883\n-------------------------------\nloss: 0.614012  [   16/ 4910]\nloss: 0.613964  [ 1616/ 4910]\nloss: 0.635866  [ 3216/ 4910]\nloss: 0.676453  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.645884 \n\nEpoch 884\n-------------------------------\nloss: 0.614080  [   16/ 4910]\nloss: 0.676497  [ 1616/ 4910]\nloss: 0.671641  [ 3216/ 4910]\nloss: 0.615247  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652458 \n\nEpoch 885\n-------------------------------\nloss: 0.551541  [   16/ 4910]\nloss: 0.614093  [ 1616/ 4910]\nloss: 0.551492  [ 3216/ 4910]\nloss: 0.551460  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.660062 \n\nEpoch 886\n-------------------------------\nloss: 0.557265  [   16/ 4910]\nloss: 0.551510  [ 1616/ 4910]\nloss: 0.551485  [ 3216/ 4910]\nloss: 0.551450  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648687 \n\nEpoch 887\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.614493  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.670781  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.656575 \n\nEpoch 888\n-------------------------------\nloss: 0.608674  [   16/ 4910]\nloss: 0.551478  [ 1616/ 4910]\nloss: 0.613982  [ 3216/ 4910]\nloss: 0.608354  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652494 \n\nEpoch 889\n-------------------------------\nloss: 0.613962  [   16/ 4910]\nloss: 0.613972  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.676450  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650933 \n\nEpoch 890\n-------------------------------\nloss: 0.613953  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.613966  [ 3216/ 4910]\nloss: 0.614024  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648453 \n\nEpoch 891\n-------------------------------\nloss: 0.551538  [   16/ 4910]\nloss: 0.614067  [ 1616/ 4910]\nloss: 0.551451  [ 3216/ 4910]\nloss: 0.551509  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.3%, Avg loss: 0.648132 \n\nEpoch 892\n-------------------------------\nloss: 0.739159  [   16/ 4910]\nloss: 0.613953  [ 1616/ 4910]\nloss: 0.613960  [ 3216/ 4910]\nloss: 0.676451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648482 \n\nEpoch 893\n-------------------------------\nloss: 0.551487  [   16/ 4910]\nloss: 0.670845  [ 1616/ 4910]\nloss: 0.613948  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649159 \n\nEpoch 894\n-------------------------------\nloss: 0.613948  [   16/ 4910]\nloss: 0.739034  [ 1616/ 4910]\nloss: 0.551507  [ 3216/ 4910]\nloss: 0.551450  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646945 \n\nEpoch 895\n-------------------------------\nloss: 0.551473  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.613945  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650060 \n\nEpoch 896\n-------------------------------\nloss: 0.613992  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.551452  [ 3216/ 4910]\nloss: 0.551480  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.5%, Avg loss: 0.646699 \n\nEpoch 897\n-------------------------------\nloss: 0.551451  [   16/ 4910]\nloss: 0.676749  [ 1616/ 4910]\nloss: 0.739002  [ 3216/ 4910]\nloss: 0.614311  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651758 \n\nEpoch 898\n-------------------------------\nloss: 0.739055  [   16/ 4910]\nloss: 0.551493  [ 1616/ 4910]\nloss: 0.613947  [ 3216/ 4910]\nloss: 0.551493  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653207 \n\nEpoch 899\n-------------------------------\nloss: 0.614219  [   16/ 4910]\nloss: 0.551466  [ 1616/ 4910]\nloss: 0.614015  [ 3216/ 4910]\nloss: 0.613971  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.655128 \n\nEpoch 900\n-------------------------------\nloss: 0.613973  [   16/ 4910]\nloss: 0.613945  [ 1616/ 4910]\nloss: 0.614011  [ 3216/ 4910]\nloss: 0.676609  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.654933 \n\nEpoch 901\n-------------------------------\nloss: 0.613981  [   16/ 4910]\nloss: 0.613972  [ 1616/ 4910]\nloss: 0.676448  [ 3216/ 4910]\nloss: 0.625117  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648066 \n\nEpoch 902\n-------------------------------\nloss: 0.551468  [   16/ 4910]\nloss: 0.551476  [ 1616/ 4910]\nloss: 0.551530  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650864 \n\nEpoch 903\n-------------------------------\nloss: 0.551447  [   16/ 4910]\nloss: 0.551503  [ 1616/ 4910]\nloss: 0.676446  [ 3216/ 4910]\nloss: 0.677959  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.1%, Avg loss: 0.657986 \n\nEpoch 904\n-------------------------------\nloss: 0.614016  [   16/ 4910]\nloss: 0.676473  [ 1616/ 4910]\nloss: 0.551464  [ 3216/ 4910]\nloss: 0.613951  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.656335 \n\nEpoch 905\n-------------------------------\nloss: 0.613957  [   16/ 4910]\nloss: 0.551453  [ 1616/ 4910]\nloss: 0.551456  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.658025 \n\nEpoch 906\n-------------------------------\nloss: 0.613953  [   16/ 4910]\nloss: 0.739106  [ 1616/ 4910]\nloss: 0.591748  [ 3216/ 4910]\nloss: 0.551451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.649079 \n\nEpoch 907\n-------------------------------\nloss: 0.676518  [   16/ 4910]\nloss: 0.551454  [ 1616/ 4910]\nloss: 0.613950  [ 3216/ 4910]\nloss: 0.613975  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.645836 \n\nEpoch 908\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.613990  [ 1616/ 4910]\nloss: 0.613962  [ 3216/ 4910]\nloss: 0.613963  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.649078 \n\nEpoch 909\n-------------------------------\nloss: 0.551827  [   16/ 4910]\nloss: 0.676467  [ 1616/ 4910]\nloss: 0.676537  [ 3216/ 4910]\nloss: 0.676454  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650026 \n\nEpoch 910\n-------------------------------\nloss: 0.551470  [   16/ 4910]\nloss: 0.551473  [ 1616/ 4910]\nloss: 0.551453  [ 3216/ 4910]\nloss: 0.739010  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.655668 \n\nEpoch 911\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.551445  [ 1616/ 4910]\nloss: 0.676508  [ 3216/ 4910]\nloss: 0.676470  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650956 \n\nEpoch 912\n-------------------------------\nloss: 0.676447  [   16/ 4910]\nloss: 0.551447  [ 1616/ 4910]\nloss: 0.551502  [ 3216/ 4910]\nloss: 0.676478  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.0%, Avg loss: 0.659051 \n\nEpoch 913\n-------------------------------\nloss: 0.738957  [   16/ 4910]\nloss: 0.646351  [ 1616/ 4910]\nloss: 0.552715  [ 3216/ 4910]\nloss: 0.614002  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.2%, Avg loss: 0.660348 \n\nEpoch 914\n-------------------------------\nloss: 0.555579  [   16/ 4910]\nloss: 0.551523  [ 1616/ 4910]\nloss: 0.551526  [ 3216/ 4910]\nloss: 0.614114  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648611 \n\nEpoch 915\n-------------------------------\nloss: 0.616570  [   16/ 4910]\nloss: 0.551445  [ 1616/ 4910]\nloss: 0.614453  [ 3216/ 4910]\nloss: 0.671371  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.653137 \n\nEpoch 916\n-------------------------------\nloss: 0.676448  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.551461  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.650812 \n\nEpoch 917\n-------------------------------\nloss: 0.613995  [   16/ 4910]\nloss: 0.613963  [ 1616/ 4910]\nloss: 0.551458  [ 3216/ 4910]\nloss: 0.551501  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648060 \n\nEpoch 918\n-------------------------------\nloss: 0.677445  [   16/ 4910]\nloss: 0.613989  [ 1616/ 4910]\nloss: 0.613980  [ 3216/ 4910]\nloss: 0.551451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650456 \n\nEpoch 919\n-------------------------------\nloss: 0.673628  [   16/ 4910]\nloss: 0.613971  [ 1616/ 4910]\nloss: 0.676575  [ 3216/ 4910]\nloss: 0.668861  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.657031 \n\nEpoch 920\n-------------------------------\nloss: 0.615499  [   16/ 4910]\nloss: 0.613949  [ 1616/ 4910]\nloss: 0.676511  [ 3216/ 4910]\nloss: 0.552252  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.656220 \n\nEpoch 921\n-------------------------------\nloss: 0.551455  [   16/ 4910]\nloss: 0.613960  [ 1616/ 4910]\nloss: 0.551801  [ 3216/ 4910]\nloss: 0.614643  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.652700 \n\nEpoch 922\n-------------------------------\nloss: 0.613966  [   16/ 4910]\nloss: 0.613990  [ 1616/ 4910]\nloss: 0.551461  [ 3216/ 4910]\nloss: 0.676451  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.6%, Avg loss: 0.646361 \n\nEpoch 923\n-------------------------------\nloss: 0.551447  [   16/ 4910]\nloss: 0.551458  [ 1616/ 4910]\nloss: 0.676519  [ 3216/ 4910]\nloss: 0.613946  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649993 \n\nEpoch 924\n-------------------------------\nloss: 0.676446  [   16/ 4910]\nloss: 0.608224  [ 1616/ 4910]\nloss: 0.608262  [ 3216/ 4910]\nloss: 0.676490  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649185 \n\nEpoch 925\n-------------------------------\nloss: 0.739004  [   16/ 4910]\nloss: 0.676458  [ 1616/ 4910]\nloss: 0.551445  [ 3216/ 4910]\nloss: 0.552100  [ 4816/ 4910]\nTest Error: \n Accuracy: 88.4%, Avg loss: 0.664526 \n\nEpoch 926\n-------------------------------\nloss: 0.551452  [   16/ 4910]\nloss: 0.613954  [ 1616/ 4910]\nloss: 0.613979  [ 3216/ 4910]\nloss: 0.614244  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648374 \n\nEpoch 927\n-------------------------------\nloss: 0.733727  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.551475  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649593 \n\nEpoch 928\n-------------------------------\nloss: 0.738952  [   16/ 4910]\nloss: 0.613966  [ 1616/ 4910]\nloss: 0.738945  [ 3216/ 4910]\nloss: 0.551452  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652505 \n\nEpoch 929\n-------------------------------\nloss: 0.551539  [   16/ 4910]\nloss: 0.613982  [ 1616/ 4910]\nloss: 0.551472  [ 3216/ 4910]\nloss: 0.551448  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.652007 \n\nEpoch 930\n-------------------------------\nloss: 0.676450  [   16/ 4910]\nloss: 0.614503  [ 1616/ 4910]\nloss: 0.676512  [ 3216/ 4910]\nloss: 0.553614  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.8%, Avg loss: 0.642861 \n\nEpoch 931\n-------------------------------\nloss: 0.551505  [   16/ 4910]\nloss: 0.613951  [ 1616/ 4910]\nloss: 0.551575  [ 3216/ 4910]\nloss: 0.551475  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648668 \n\nEpoch 932\n-------------------------------\nloss: 0.614067  [   16/ 4910]\nloss: 0.551454  [ 1616/ 4910]\nloss: 0.551527  [ 3216/ 4910]\nloss: 0.551445  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.659508 \n\nEpoch 933\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.613963  [ 1616/ 4910]\nloss: 0.551642  [ 3216/ 4910]\nloss: 0.551483  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.649135 \n\nEpoch 934\n-------------------------------\nloss: 0.676552  [   16/ 4910]\nloss: 0.676457  [ 1616/ 4910]\nloss: 0.676452  [ 3216/ 4910]\nloss: 0.676456  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.647719 \n\nEpoch 935\n-------------------------------\nloss: 0.613966  [   16/ 4910]\nloss: 0.676454  [ 1616/ 4910]\nloss: 0.613957  [ 3216/ 4910]\nloss: 0.615057  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653039 \n\nEpoch 936\n-------------------------------\nloss: 0.613961  [   16/ 4910]\nloss: 0.676450  [ 1616/ 4910]\nloss: 0.613963  [ 3216/ 4910]\nloss: 0.613905  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652544 \n\nEpoch 937\n-------------------------------\nloss: 0.614001  [   16/ 4910]\nloss: 0.613948  [ 1616/ 4910]\nloss: 0.551628  [ 3216/ 4910]\nloss: 0.613948  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651744 \n\nEpoch 938\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.551505  [ 1616/ 4910]\nloss: 0.613958  [ 3216/ 4910]\nloss: 0.613966  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650455 \n\nEpoch 939\n-------------------------------\nloss: 0.614135  [   16/ 4910]\nloss: 0.676447  [ 1616/ 4910]\nloss: 0.738959  [ 3216/ 4910]\nloss: 0.670617  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.656836 \n\nEpoch 940\n-------------------------------\nloss: 0.551793  [   16/ 4910]\nloss: 0.676451  [ 1616/ 4910]\nloss: 0.613982  [ 3216/ 4910]\nloss: 0.551446  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650651 \n\nEpoch 941\n-------------------------------\nloss: 0.551492  [   16/ 4910]\nloss: 0.613947  [ 1616/ 4910]\nloss: 0.613994  [ 3216/ 4910]\nloss: 0.738959  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651089 \n\nEpoch 942\n-------------------------------\nloss: 0.551480  [   16/ 4910]\nloss: 0.551468  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.551462  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648640 \n\nEpoch 943\n-------------------------------\nloss: 0.676448  [   16/ 4910]\nloss: 0.551481  [ 1616/ 4910]\nloss: 0.676597  [ 3216/ 4910]\nloss: 0.613947  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649104 \n\nEpoch 944\n-------------------------------\nloss: 0.613945  [   16/ 4910]\nloss: 0.676456  [ 1616/ 4910]\nloss: 0.613948  [ 3216/ 4910]\nloss: 0.676449  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650210 \n\nEpoch 945\n-------------------------------\nloss: 0.551453  [   16/ 4910]\nloss: 0.551446  [ 1616/ 4910]\nloss: 0.551460  [ 3216/ 4910]\nloss: 0.551465  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.650634 \n\nEpoch 946\n-------------------------------\nloss: 0.551454  [   16/ 4910]\nloss: 0.608571  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.676447  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.650399 \n\nEpoch 947\n-------------------------------\nloss: 0.676451  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.551464  [ 3216/ 4910]\nloss: 0.613948  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.3%, Avg loss: 0.657363 \n\nEpoch 948\n-------------------------------\nloss: 0.738948  [   16/ 4910]\nloss: 0.551476  [ 1616/ 4910]\nloss: 0.551459  [ 3216/ 4910]\nloss: 0.738899  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651705 \n\nEpoch 949\n-------------------------------\nloss: 0.551480  [   16/ 4910]\nloss: 0.551483  [ 1616/ 4910]\nloss: 0.608686  [ 3216/ 4910]\nloss: 0.551454  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.9%, Avg loss: 0.651848 \n\nEpoch 950\n-------------------------------\nloss: 0.613958  [   16/ 4910]\nloss: 0.552024  [ 1616/ 4910]\nloss: 0.551461  [ 3216/ 4910]\nloss: 0.676448  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.0%, Avg loss: 0.651367 \n\nEpoch 951\n-------------------------------\nloss: 0.551556  [   16/ 4910]\nloss: 0.551454  [ 1616/ 4910]\nloss: 0.551510  [ 3216/ 4910]\nloss: 0.608334  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.650408 \n\nEpoch 952\n-------------------------------\nloss: 0.551453  [   16/ 4910]\nloss: 0.551451  [ 1616/ 4910]\nloss: 0.613969  [ 3216/ 4910]\nloss: 0.741372  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.648645 \n\nEpoch 953\n-------------------------------\nloss: 0.613964  [   16/ 4910]\nloss: 0.679058  [ 1616/ 4910]\nloss: 0.614136  [ 3216/ 4910]\nloss: 0.612003  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654189 \n\nEpoch 954\n-------------------------------\nloss: 0.553316  [   16/ 4910]\nloss: 0.552056  [ 1616/ 4910]\nloss: 0.658157  [ 3216/ 4910]\nloss: 0.551490  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.4%, Avg loss: 0.648351 \n\nEpoch 955\n-------------------------------\nloss: 0.613969  [   16/ 4910]\nloss: 0.608487  [ 1616/ 4910]\nloss: 0.676514  [ 3216/ 4910]\nloss: 0.676491  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648894 \n\nEpoch 956\n-------------------------------\nloss: 0.551469  [   16/ 4910]\nloss: 0.676507  [ 1616/ 4910]\nloss: 0.613987  [ 3216/ 4910]\nloss: 0.670928  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.648291 \n\nEpoch 957\n-------------------------------\nloss: 0.613945  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.613956  [ 3216/ 4910]\nloss: 0.738973  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.651548 \n\nEpoch 958\n-------------------------------\nloss: 0.551464  [   16/ 4910]\nloss: 0.551452  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.676453  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652556 \n\nEpoch 959\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.613948  [ 1616/ 4910]\nloss: 0.551771  [ 3216/ 4910]\nloss: 0.551461  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652914 \n\nEpoch 960\n-------------------------------\nloss: 0.738949  [   16/ 4910]\nloss: 0.613977  [ 1616/ 4910]\nloss: 0.551455  [ 3216/ 4910]\nloss: 0.614043  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653024 \n\nEpoch 961\n-------------------------------\nloss: 0.551484  [   16/ 4910]\nloss: 0.676459  [ 1616/ 4910]\nloss: 0.676475  [ 3216/ 4910]\nloss: 0.551449  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653904 \n\nEpoch 962\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.676447  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.551513  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653833 \n\nEpoch 963\n-------------------------------\nloss: 0.551450  [   16/ 4910]\nloss: 0.613947  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.551445  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653230 \n\nEpoch 964\n-------------------------------\nloss: 0.675602  [   16/ 4910]\nloss: 0.613953  [ 1616/ 4910]\nloss: 0.613950  [ 3216/ 4910]\nloss: 0.551447  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653174 \n\nEpoch 965\n-------------------------------\nloss: 0.613954  [   16/ 4910]\nloss: 0.613946  [ 1616/ 4910]\nloss: 0.551455  [ 3216/ 4910]\nloss: 0.613981  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653153 \n\nEpoch 966\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.608117  [ 1616/ 4910]\nloss: 0.551447  [ 3216/ 4910]\nloss: 0.738954  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652568 \n\nEpoch 967\n-------------------------------\nloss: 0.676447  [   16/ 4910]\nloss: 0.613957  [ 1616/ 4910]\nloss: 0.676473  [ 3216/ 4910]\nloss: 0.676449  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.652829 \n\nEpoch 968\n-------------------------------\nloss: 0.613994  [   16/ 4910]\nloss: 0.551446  [ 1616/ 4910]\nloss: 0.551483  [ 3216/ 4910]\nloss: 0.613997  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.4%, Avg loss: 0.654234 \n\nEpoch 969\n-------------------------------\nloss: 0.796571  [   16/ 4910]\nloss: 0.551452  [ 1616/ 4910]\nloss: 0.551452  [ 3216/ 4910]\nloss: 0.670665  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654048 \n\nEpoch 970\n-------------------------------\nloss: 0.551462  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.551446  [ 3216/ 4910]\nloss: 0.676447  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654901 \n\nEpoch 971\n-------------------------------\nloss: 0.613953  [   16/ 4910]\nloss: 0.551452  [ 1616/ 4910]\nloss: 0.551484  [ 3216/ 4910]\nloss: 0.551500  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.2%, Avg loss: 0.649233 \n\nEpoch 972\n-------------------------------\nloss: 0.638205  [   16/ 4910]\nloss: 0.614218  [ 1616/ 4910]\nloss: 0.613955  [ 3216/ 4910]\nloss: 0.614065  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.656282 \n\nEpoch 973\n-------------------------------\nloss: 0.614668  [   16/ 4910]\nloss: 0.613980  [ 1616/ 4910]\nloss: 0.676463  [ 3216/ 4910]\nloss: 0.670624  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.650907 \n\nEpoch 974\n-------------------------------\nloss: 0.670624  [   16/ 4910]\nloss: 0.551464  [ 1616/ 4910]\nloss: 0.613948  [ 3216/ 4910]\nloss: 0.613964  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.650996 \n\nEpoch 975\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.739028  [ 1616/ 4910]\nloss: 0.613974  [ 3216/ 4910]\nloss: 0.739040  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.654479 \n\nEpoch 976\n-------------------------------\nloss: 0.551460  [   16/ 4910]\nloss: 0.613997  [ 1616/ 4910]\nloss: 0.676450  [ 3216/ 4910]\nloss: 0.613961  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653393 \n\nEpoch 977\n-------------------------------\nloss: 0.676451  [   16/ 4910]\nloss: 0.551450  [ 1616/ 4910]\nloss: 0.614040  [ 3216/ 4910]\nloss: 0.613964  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649789 \n\nEpoch 978\n-------------------------------\nloss: 0.613979  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.613952  [ 3216/ 4910]\nloss: 0.551452  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653810 \n\nEpoch 979\n-------------------------------\nloss: 0.551446  [   16/ 4910]\nloss: 0.614057  [ 1616/ 4910]\nloss: 0.614105  [ 3216/ 4910]\nloss: 0.613966  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652818 \n\nEpoch 980\n-------------------------------\nloss: 0.551456  [   16/ 4910]\nloss: 0.551476  [ 1616/ 4910]\nloss: 0.551446  [ 3216/ 4910]\nloss: 0.676449  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.5%, Avg loss: 0.654547 \n\nEpoch 981\n-------------------------------\nloss: 0.613947  [   16/ 4910]\nloss: 0.551455  [ 1616/ 4910]\nloss: 0.613950  [ 3216/ 4910]\nloss: 0.613952  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654128 \n\nEpoch 982\n-------------------------------\nloss: 0.613948  [   16/ 4910]\nloss: 0.613952  [ 1616/ 4910]\nloss: 0.613973  [ 3216/ 4910]\nloss: 0.676462  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.654050 \n\nEpoch 983\n-------------------------------\nloss: 0.551448  [   16/ 4910]\nloss: 0.551447  [ 1616/ 4910]\nloss: 0.613949  [ 3216/ 4910]\nloss: 0.614018  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653916 \n\nEpoch 984\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.551448  [ 1616/ 4910]\nloss: 0.613951  [ 3216/ 4910]\nloss: 0.613951  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652293 \n\nEpoch 985\n-------------------------------\nloss: 0.613949  [   16/ 4910]\nloss: 0.551457  [ 1616/ 4910]\nloss: 0.613950  [ 3216/ 4910]\nloss: 0.676447  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653899 \n\nEpoch 986\n-------------------------------\nloss: 0.551449  [   16/ 4910]\nloss: 0.609057  [ 1616/ 4910]\nloss: 0.676446  [ 3216/ 4910]\nloss: 0.613951  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653216 \n\nEpoch 987\n-------------------------------\nloss: 0.613955  [   16/ 4910]\nloss: 0.551449  [ 1616/ 4910]\nloss: 0.551450  [ 3216/ 4910]\nloss: 0.551454  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653599 \n\nEpoch 988\n-------------------------------\nloss: 0.551449  [   16/ 4910]\nloss: 0.676463  [ 1616/ 4910]\nloss: 0.738947  [ 3216/ 4910]\nloss: 0.738950  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652566 \n\nEpoch 989\n-------------------------------\nloss: 0.551475  [   16/ 4910]\nloss: 0.613966  [ 1616/ 4910]\nloss: 0.613948  [ 3216/ 4910]\nloss: 0.551494  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.651972 \n\nEpoch 990\n-------------------------------\nloss: 0.613952  [   16/ 4910]\nloss: 0.551473  [ 1616/ 4910]\nloss: 0.551454  [ 3216/ 4910]\nloss: 0.676447  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.652757 \n\nEpoch 991\n-------------------------------\nloss: 0.551445  [   16/ 4910]\nloss: 0.613972  [ 1616/ 4910]\nloss: 0.614020  [ 3216/ 4910]\nloss: 0.676457  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.651294 \n\nEpoch 992\n-------------------------------\nloss: 0.613958  [   16/ 4910]\nloss: 0.551478  [ 1616/ 4910]\nloss: 0.551457  [ 3216/ 4910]\nloss: 0.676453  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652606 \n\nEpoch 993\n-------------------------------\nloss: 0.551463  [   16/ 4910]\nloss: 0.676509  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.551466  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.651115 \n\nEpoch 994\n-------------------------------\nloss: 0.551446  [   16/ 4910]\nloss: 0.613958  [ 1616/ 4910]\nloss: 0.676484  [ 3216/ 4910]\nloss: 0.676469  [ 4816/ 4910]\nTest Error: \n Accuracy: 90.1%, Avg loss: 0.649885 \n\nEpoch 995\n-------------------------------\nloss: 0.614100  [   16/ 4910]\nloss: 0.676468  [ 1616/ 4910]\nloss: 0.613949  [ 3216/ 4910]\nloss: 0.551463  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.6%, Avg loss: 0.653911 \n\nEpoch 996\n-------------------------------\nloss: 0.613959  [   16/ 4910]\nloss: 0.676507  [ 1616/ 4910]\nloss: 0.551449  [ 3216/ 4910]\nloss: 0.613945  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652543 \n\nEpoch 997\n-------------------------------\nloss: 0.551459  [   16/ 4910]\nloss: 0.551460  [ 1616/ 4910]\nloss: 0.551448  [ 3216/ 4910]\nloss: 0.551506  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.653023 \n\nEpoch 998\n-------------------------------\nloss: 0.551458  [   16/ 4910]\nloss: 0.554921  [ 1616/ 4910]\nloss: 0.613964  [ 3216/ 4910]\nloss: 0.676457  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.7%, Avg loss: 0.652423 \n\nEpoch 999\n-------------------------------\nloss: 0.551449  [   16/ 4910]\nloss: 0.613979  [ 1616/ 4910]\nloss: 0.552555  [ 3216/ 4910]\nloss: 0.613950  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.652727 \n\nEpoch 1000\n-------------------------------\nloss: 0.551457  [   16/ 4910]\nloss: 0.551468  [ 1616/ 4910]\nloss: 0.613953  [ 3216/ 4910]\nloss: 0.551457  [ 4816/ 4910]\nTest Error: \n Accuracy: 89.8%, Avg loss: 0.653079 \n\nDone!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix after Training on Resampled Dataset"
      ],
      "metadata": {
        "id": "qevkShxWMoEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_y_pred = []\n",
        "res_y_true = []\n",
        "\n",
        "for inputs, labels in res_test_loader:\n",
        "\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        output = (torch.max(output, 1)[1]).data.cpu().numpy()\n",
        "        res_y_pred.extend(output)\n",
        "\n",
        "        labels = labels.data.cpu().numpy()\n",
        "        res_y_true.extend(labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T19:29:02.100636Z",
          "iopub.execute_input": "2024-06-19T19:29:02.101329Z",
          "iopub.status.idle": "2024-06-19T19:29:02.259967Z",
          "shell.execute_reply.started": "2024-06-19T19:29:02.101290Z",
          "shell.execute_reply": "2024-06-19T19:29:02.259170Z"
        },
        "trusted": true,
        "id": "xCCbechnMoEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = (0, 1, 2)\n",
        "res_cf_matrix = confusion_matrix(res_y_true, res_y_pred)\n",
        "res_cmd = ConfusionMatrixDisplay(res_cf_matrix)\n",
        "res_cmd.plot()\n",
        "plt.title(\"Confusion Matrix after Training on Resampled Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T19:32:59.670752Z",
          "iopub.execute_input": "2024-06-19T19:32:59.671153Z",
          "iopub.status.idle": "2024-06-19T19:33:00.019810Z",
          "shell.execute_reply.started": "2024-06-19T19:32:59.671107Z",
          "shell.execute_reply": "2024-06-19T19:33:00.018922Z"
        },
        "trusted": true,
        "id": "OnZfkJ5uMoEN",
        "outputId": "07168575-f5f1-42c7-d119-e78c6b747c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KCv6zKO9MoEN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}